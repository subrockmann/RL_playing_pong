{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'wrappers' from 'h:\\\\IUBH_Master_AI\\\\RL_playing_pong\\\\wrappers.py'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Reshape, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber, MeanSquaredError\n",
    "#import tensorflow.keras.losses.huber as huber\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from time import sleep\n",
    "from collections import deque\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import importlib\n",
    "\n",
    "import wrappers\n",
    "importlib.reload(wrappers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# To get smooth animations\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_envs = gym.envs.registry.values()\n",
    "# env_ids = [env_spec.id for env_spec in all_envs]\n",
    "# print(sorted(env_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvSpec(id='ALE/Pong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong', version=5)\n",
      "\n",
      "EnvSpec(id='ALE/Pong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong-ram', version=5)\n",
      "\n",
      "EnvSpec(id='Pong-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=0)\n",
      "\n",
      "EnvSpec(id='PongDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=0)\n",
      "\n",
      "EnvSpec(id='PongNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=4)\n",
      "\n",
      "EnvSpec(id='PongDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=4)\n",
      "\n",
      "EnvSpec(id='PongNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=4)\n",
      "\n",
      "EnvSpec(id='Pong-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=4)\n",
      "\n",
      "EnvSpec(id='Pong-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=4)\n",
      "\n",
      "EnvSpec(id='Pong-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=4)\n",
      "\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "count_pong = 0\n",
    "for env_spec in gym.envs.registry.values():\n",
    "\n",
    "    if \"Pong\" in str(env_spec.id):\n",
    "        print(str(env_spec) + \"\\n\")\n",
    "        count_pong +=1\n",
    "    \n",
    "print(count_pong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvSpec(id='Pong-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=0)\n",
      "\n",
      "EnvSpec(id='PongDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=0)\n",
      "\n",
      "EnvSpec(id='PongNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=4)\n",
      "\n",
      "EnvSpec(id='PongDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=4)\n",
      "\n",
      "EnvSpec(id='PongNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=4)\n",
      "\n",
      "EnvSpec(id='Pong-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=0)\n",
      "\n",
      "EnvSpec(id='Pong-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=4)\n",
      "\n",
      "EnvSpec(id='Pong-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=4)\n",
      "\n",
      "EnvSpec(id='Pong-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=4)\n",
      "\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "count_pong = 0\n",
    "for env_spec in gym.envs.registry.values():\n",
    "\n",
    "    if str(env_spec.id).startswith(\"Pong\"):\n",
    "        print(str(env_spec) + \"\\n\")\n",
    "        count_pong +=1\n",
    "    \n",
    "print(count_pong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "# EnvSpec(id='PongNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, \n",
    "# max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, \n",
    "# kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, \n",
    "# namespace=None, name='PongNoFrameskip', version=4)\n",
    "\n",
    "#ENV_NAME = \"Pong-v4\"\n",
    "\n",
    "ENV_NAME = \"ALE/Pong-v5\"\n",
    "# EnvSpec(id='ALE/Pong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, \n",
    "# max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, \n",
    "# kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong', version=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]]\n",
      "[[[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "# create the environment \n",
    "env = gym.make(ENV_NAME, render_mode='human',full_action_space= False )\n",
    "env = wrappers.PreProcessPongFrame(env)\n",
    "env = wrappers.FrameStack(env, 4)\n",
    "env.action_space.seed(42)\n",
    "obs = env.reset()\n",
    "#print(env.observation_space)\n",
    "print(env.observation_space.low)\n",
    "print(env.observation_space.high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 4)\n",
      "Discrete(6)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.shape)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, inf)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lives': 0, 'episode_frame_number': 4, 'frame_number': 4} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 8, 'frame_number': 8} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF700>\n",
      "{'lives': 0, 'episode_frame_number': 12, 'frame_number': 12} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 16, 'frame_number': 16} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 20, 'frame_number': 20} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 24, 'frame_number': 24} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 28, 'frame_number': 28} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCFC10>\n",
      "{'lives': 0, 'episode_frame_number': 32, 'frame_number': 32} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF1C0>\n",
      "{'lives': 0, 'episode_frame_number': 36, 'frame_number': 36} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 40, 'frame_number': 40} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF6D0>\n",
      "{'lives': 0, 'episode_frame_number': 44, 'frame_number': 44} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF700>\n",
      "{'lives': 0, 'episode_frame_number': 48, 'frame_number': 48} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 52, 'frame_number': 52} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 56, 'frame_number': 56} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 60, 'frame_number': 60} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 64, 'frame_number': 64} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 68, 'frame_number': 68} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 72, 'frame_number': 72} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 76, 'frame_number': 76} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 80, 'frame_number': 80} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 84, 'frame_number': 84} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 88, 'frame_number': 88} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 92, 'frame_number': 92} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 96, 'frame_number': 96} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF880>\n",
      "{'lives': 0, 'episode_frame_number': 100, 'frame_number': 100} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 104, 'frame_number': 104} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 108, 'frame_number': 108} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 112, 'frame_number': 112} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 116, 'frame_number': 116} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 120, 'frame_number': 120} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 124, 'frame_number': 124} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 128, 'frame_number': 128} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 132, 'frame_number': 132} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 136, 'frame_number': 136} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 140, 'frame_number': 140} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCFC40>\n",
      "{'lives': 0, 'episode_frame_number': 144, 'frame_number': 144} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 148, 'frame_number': 148} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 152, 'frame_number': 152} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 156, 'frame_number': 156} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 160, 'frame_number': 160} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 164, 'frame_number': 164} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 168, 'frame_number': 168} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCFFD0>\n",
      "{'lives': 0, 'episode_frame_number': 172, 'frame_number': 172} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCE340>\n",
      "{'lives': 0, 'episode_frame_number': 176, 'frame_number': 176} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 180, 'frame_number': 180} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 184, 'frame_number': 184} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 188, 'frame_number': 188} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 192, 'frame_number': 192} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCFFD0>\n",
      "{'lives': 0, 'episode_frame_number': 196, 'frame_number': 196} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 200, 'frame_number': 200} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 204, 'frame_number': 204} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 208, 'frame_number': 208} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 212, 'frame_number': 212} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 216, 'frame_number': 216} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 220, 'frame_number': 220} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF250>\n",
      "{'lives': 0, 'episode_frame_number': 224, 'frame_number': 224} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF355C5AF0>\n",
      "{'lives': 0, 'episode_frame_number': 228, 'frame_number': 228} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 232, 'frame_number': 232} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCFCA0>\n",
      "{'lives': 0, 'episode_frame_number': 236, 'frame_number': 236} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 240, 'frame_number': 240} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF6D0>\n",
      "{'lives': 0, 'episode_frame_number': 244, 'frame_number': 244} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 248, 'frame_number': 248} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 252, 'frame_number': 252} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 256, 'frame_number': 256} -1.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 260, 'frame_number': 260} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 264, 'frame_number': 264} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 268, 'frame_number': 268} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 272, 'frame_number': 272} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 276, 'frame_number': 276} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 280, 'frame_number': 280} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 284, 'frame_number': 284} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 288, 'frame_number': 288} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 292, 'frame_number': 292} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 296, 'frame_number': 296} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 300, 'frame_number': 300} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF355C5AF0>\n",
      "{'lives': 0, 'episode_frame_number': 304, 'frame_number': 304} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF160>\n",
      "{'lives': 0, 'episode_frame_number': 308, 'frame_number': 308} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCEFD0>\n",
      "{'lives': 0, 'episode_frame_number': 312, 'frame_number': 312} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 316, 'frame_number': 316} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 320, 'frame_number': 320} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 324, 'frame_number': 324} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 328, 'frame_number': 328} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 332, 'frame_number': 332} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 336, 'frame_number': 336} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 340, 'frame_number': 340} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF35995820>\n",
      "{'lives': 0, 'episode_frame_number': 344, 'frame_number': 344} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 348, 'frame_number': 348} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF190>\n",
      "{'lives': 0, 'episode_frame_number': 352, 'frame_number': 352} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 356, 'frame_number': 356} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF220>\n",
      "{'lives': 0, 'episode_frame_number': 360, 'frame_number': 360} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 364, 'frame_number': 364} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C840EE20>\n",
      "{'lives': 0, 'episode_frame_number': 368, 'frame_number': 368} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF355C5AF0>\n",
      "{'lives': 0, 'episode_frame_number': 372, 'frame_number': 372} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF160>\n",
      "{'lives': 0, 'episode_frame_number': 376, 'frame_number': 376} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 380, 'frame_number': 380} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C9CCF820>\n",
      "{'lives': 0, 'episode_frame_number': 384, 'frame_number': 384} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF355C5AF0>\n",
      "{'lives': 0, 'episode_frame_number': 388, 'frame_number': 388} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n",
      "{'lives': 0, 'episode_frame_number': 392, 'frame_number': 392} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001C0C1D136A0>\n",
      "{'lives': 0, 'episode_frame_number': 396, 'frame_number': 396} -1.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF359722E0>\n",
      "{'lives': 0, 'episode_frame_number': 400, 'frame_number': 400} 0.0 False\n",
      "<class 'wrappers.LazyFrames'>\n",
      "<wrappers.LazyFrames object at 0x000001BF40A1EC10>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    #observation, reward, done, info = env.step(3)\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    print(info, reward, done)\n",
    "    print(type(observation))\n",
    "    print(observation)    \n",
    "    #print(observation._force()) # using ._force() on LazyFrames \n",
    "    # pil_image=Image.fromarray(observation)\n",
    "    # pil_image.show()\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# actions: \n",
    "# 0 -> \n",
    "# 2 -> up\n",
    "# 3 -> down\n",
    "# 4 -> up\n",
    "# 5 -> down\n",
    "\n",
    "\n",
    "# env = gym.make(ENV_NAME, render_mode='human',full_action_space= False )\n",
    "# env.action_space.seed(42)\n",
    "# obs, info = env.reset(seed=42, return_info=True)\n",
    "# for _ in range(4):\n",
    "#     observation, reward, done, info = env.step(3)\n",
    "#     #observation, reward, done, info = env.step(env.action_space.sample())\n",
    "#     print(info, reward, done)\n",
    "\n",
    "#     if done:\n",
    "#         pass\n",
    "#         observation, info = env.reset(return_info=True)\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_mse(y_true, y_pred):\n",
    "    mse = MeanSquaredError()\n",
    "    loss = mse(y_true, y_pred)\n",
    "    loss = tf.clip_by_value(loss, -1, 1)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/a/68739696\n",
    "# custom tensorflow error functions\n",
    "\n",
    "# new_arr = keras.losses.MSE(new_true, new_prediction) # keras example that needs to be ported to tensorflow\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "  msle = MeanSquaredLogarithmicError()\n",
    "  return K.sqrt(msle(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "REPLAY_BUFFER_SIZE = 10_000 # according to Maxim Lapan\n",
    "REPLAY_START_SIZE = 1_000 # \n",
    "REWARD_REPLAY_BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 32\n",
    "EPISODES = 2\n",
    "EPSILON_START = 1\n",
    "EPSILON_DECAY = 0.001\n",
    "ESPILON_MIN = 0.01\n",
    "\n",
    "\n",
    "input_shape=(84, 84, 1)\n",
    "learning_rate=1e-2 # from Aurélien Geron better than 1e-3 https://github.com/ageron/handson-ml2/blob/master/18_reinforcement_learning.ipynb, Maxim Lapan: 1e-4\n",
    "optimizer = Adam\n",
    "huber_loss = Huber(reduction=tf.keras.losses.Reduction.SUM) # check the reduction!\n",
    "loss = clipped_mse\n",
    "#loss = huber_loss\n",
    "#loss = \"mse\"   # check also \"rmse\"\n",
    "gamma = 0.99 # used for Bellman approximation\n",
    "AVG_SCORE_STEP = 100 # smoothed average over number of episodes\n",
    "SYNC_TARGET_FREQ = 1000 # frequency for syncing model weights from the training to the target model \n",
    "LOGGING_FREQ = 100 # frequency of print statements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "print(env.unwrapped.get_action_meanings())\n",
    "# print(env.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "useful_actions = (0, 2 , 3, 4, 5) # action 1 does not ssem to be used\n",
    "action = random.choice(useful_actions)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(batch_actions, batch_rewards, batch_dones):\n",
    "    buffer_data = list(zip(batch_actions, batch_rewards, batch_dones))\n",
    "    df = pd.DataFrame(buffer_data, columns =[\"action\", \"reward\", \"done\"])\n",
    "    num_neg_rewards = len(df[df[\"reward\"] == -1])\n",
    "    num_zero_rewards = len(df[df[\"reward\"] == 0])\n",
    "    num_pos_rewards = len(df[df[\"reward\"] == 1])\n",
    "    print(f\"{num_neg_rewards + num_pos_rewards+ num_zero_rewards} rewards: positive rewards: {num_pos_rewards}, negative rewards: {num_neg_rewards}\")\n",
    "\n",
    "    return df, num_neg_rewards, num_zero_rewards, num_pos_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DQN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,984\n",
      "Trainable params: 77,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_actions = 6\n",
    "input_size = (84,84,4)\n",
    "model = Sequential(name= \"DQN\")\n",
    "# model.add(keras.Input(shape=(4,)))   # required for calling model.summary()\n",
    "# model.add(keras.Input(shape=(84, 84, 1)))  # 250x250 RGB images\n",
    "model.add(Input(shape=input_size))\n",
    "#model.add(Reshape((input_size))) #    expected shape=(None, 84, 84, 4), found shape=(84, 84, 4)\n",
    "model.add(Conv2D(32, (8, 8), strides=(4, 4)))#, input_shape=input_size))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (4, 4), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(512))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dense(n_actions))\n",
    "#model.add(Activation('linear'))\n",
    "\n",
    "model.build()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepQNetwork(input_size, n_actions, learning_rate, optimizer, loss):\n",
    "    model = Sequential(name= \"DQN\")\n",
    "    # model.add(keras.Input(shape=(4,)))   # required for calling model.summary()\n",
    "    # model.add(keras.Input(shape=(84, 84, 1)))  # 250x250 RGB images\n",
    "    model.add(Input(shape=input_size))  # input_size\n",
    "    #model.add(Reshape((input_size))) #    expected shape=(None, 84, 84, 4), found shape=(84, 84, 4)\n",
    "    model.add(Conv2D(32, (8, 8), strides=(4, 4)))#, input_shape=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Input(shape=(3136))) # important additional input layer before the Dense layer\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(n_actions))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.build()\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer= optimizer(learning_rate=learning_rate), loss=loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class DoubleDQNAgent:\n",
    "    def __init__(self, state_size, action_space):\n",
    "        self.input_size = state_size\n",
    "        self.action_space = action_space\n",
    "        self.n_actions = len(action_space)\n",
    "        self.q_net = DeepQNetwork(self.input_size, self.n_actions, learning_rate, optimizer, loss)\n",
    "        self.target_q_net = DeepQNetwork(self.input_size, self.n_actions, learning_rate, optimizer, loss)\n",
    "        self.replay_buffer = deque(maxlen=REPLAY_BUFFER_SIZE)\n",
    "        self.reward_replay_buffer = deque(maxlen=REWARD_REPLAY_BUFFER_SIZE)\n",
    "        self.buffer_filename = 'replay_buffer.pkl'\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = EPSILON_START \n",
    "        self.epsilon_decay = EPSILON_DECAY\n",
    "        self.epsilon_min = ESPILON_MIN\n",
    "        self.step_counter = 0\n",
    "\n",
    "        self.update_target_network() # copy the q_net weights to target_q_net\n",
    "\n",
    "        try:\n",
    "            self.load_replay_buffer()\n",
    "            print(\"Loaded replay buffer from disk.\")\n",
    "        except:\n",
    "            print(\"Failed to load replay buffer from disk. Started to fill replay buffer.\")\n",
    "            state = env.reset()\n",
    "            self.fill_replay_buffer(env, state)\n",
    "            try:\n",
    "                self.save_replay_buffer()\n",
    "                print(\"Saved replay buffer to disk\")\n",
    "            except:\n",
    "                print(\"Failed to save generated replay buffer!\")\n",
    "\n",
    "\n",
    "    def epsilon_greedy(self, state):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon = self.epsilon - self.epsilon_decay\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.choice(self.action_space)\n",
    "        else:\n",
    "            norm_state = state._force()/255.0 # convert LazyFrame to array and normalize it\n",
    "            norm_state = np.expand_dims(norm_state, axis=0)\n",
    "            actions = self.q_net.predict(norm_state)\n",
    "            #print(f\"Actions: {actions}\")\n",
    "            action = np.argmax(actions)  # do I need to specify the axis? \n",
    "            #print(\"Chosen action: {action}\")\n",
    "            return action\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.replay_buffer.append((state, action, reward, new_state, done))\n",
    "        return ### Do Python methods in classes need a return statement?\n",
    "\n",
    "    def play_one_step(self, env, state):\n",
    "        action = self.epsilon_greedy(state)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        #print(f\"Done: {done}\")\n",
    "        self.replay_buffer.append((state, action, reward, new_state, done))\n",
    "        return state, action, reward, new_state, done, info\n",
    "\n",
    "    def fill_replay_buffer(self, env, state):\n",
    "        while len(self.replay_buffer) < REPLAY_START_SIZE:\n",
    "            action = random.choice(self.action_space)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            self.replay_buffer.append((state, action, reward, new_state, done))\n",
    "            state = new_state\n",
    "        return print(\"ReplayBuffer is filled!\")\n",
    "\n",
    "    def replay_buffer_stats(self):\n",
    "        \n",
    "        buffer_actions = [item[1] for item in self.replay_buffer]\n",
    "        buffer_rewards = [item[2] for item in self.replay_buffer]\n",
    "        buffer_dones = [item[4] for item in self.replay_buffer]\n",
    "        results = data_stats(buffer_actions, buffer_rewards, buffer_dones)\n",
    "        return results\n",
    "\n",
    "    def fill_reward_replay_buffer(self):\n",
    "        df, num_neg_rewards, num_zero_rewards, num_pos_rewards = self.replay_buffer_stats()\n",
    "        #df, _,_,_ =self.replay_buffer_stats()\n",
    "        reward_index = list(df.loc[(df.reward == -1) | (df.reward == 1)].index)\n",
    "        for index in reward_index:\n",
    "            self.reward_replay_buffer.append(self.replay_buffer[index])\n",
    "\n",
    "        return reward_index\n",
    "\n",
    "\n",
    "\n",
    "    def minibatch_stats(self, minibatch):\n",
    "        \n",
    "        buffer_actions = [item[1] for item in minibatch]\n",
    "        buffer_rewards = [item[2] for item in minibatch]\n",
    "        buffer_dones = [item[4] for item in minibatch]\n",
    "        df, num_neg_rewards, num_zero_rewards, num_pos_rewards = data_stats(buffer_actions, buffer_rewards, buffer_dones)\n",
    "        if (num_neg_rewards + num_pos_rewards) < 1:\n",
    "            no_rewards = True\n",
    "        else:\n",
    "            no_rewards = False\n",
    "        return df, num_neg_rewards, num_zero_rewards, num_pos_rewards, no_rewards\n",
    "\n",
    "\n",
    "    def update_target_network(self):\n",
    "        \"\"\"\n",
    "        Update the target Q network\n",
    "        \"\"\"\n",
    "        self.target_q_net.set_weights(self.q_net.get_weights())\n",
    "\n",
    "    \n",
    "    def train(self, batch_size= BATCH_SIZE):\n",
    "        minibatch = random.sample(self.replay_buffer, batch_size)\n",
    "\n",
    "        df, = self.minibatch_stats(minibatch)\n",
    "        #state_batch, action_batch, reward_batch, new_state_batch, done_batch = random.sample(self.replay_buffer, batch_size)\n",
    "        # loop over batch\n",
    "        #print(minibatch)\n",
    "        #print(type(minibatch))\n",
    "        #print(state_batch)\n",
    "        #print(type(state_batch))\n",
    "        state_batch = []\n",
    "        next_state_batch = []\n",
    "        targets = []\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            #print(f\"Action: {action}, reward: {reward}, done: {done}\")\n",
    "            norm_state_array = state._force()/255.0 # convert LazyFrame to array and normalize it\n",
    "            norm_state_array = np.expand_dims(norm_state_array,axis = 0)\n",
    "            state_batch.append(norm_state_array)\n",
    "\n",
    "            norm_next_state_array = state._force()/255.0 # convert LazyFrame to array and normalize it\n",
    "            norm_next_state_array = np.expand_dims(norm_next_state_array, axis=0)\n",
    "            #print(norm_next_state_array.shape)\n",
    "            next_state_batch.append(norm_next_state_array) \n",
    "\n",
    "            # Main QNet is used to find the next action\n",
    "            q_vals = self.q_net(norm_state_array)\n",
    "            #print(f\"q_vals: {q_vals}\")\n",
    "            next_action = np.argmax(q_vals, axis= 0) # TODO: check for amax and argmax!!!\n",
    "\n",
    "\n",
    "            target_q_vals = self.target_q_net(norm_next_state_array)\n",
    "            #print(target_q_vals)\n",
    "            #print(target_q_vals.shape)\n",
    "            target_q_max = np.amax(target_q_vals, axis= 1)\n",
    "            #print(f\"target_q_max: {target_q_max}\")\n",
    "\n",
    "            #rewards = np.copy(q_vals)\n",
    "            if reward == 1:\n",
    "                print(f\"One point for me!\")\n",
    "            rewards = np.zeros(self.n_actions)\n",
    "            rewards[next_action] = reward\n",
    "\n",
    "            if done:\n",
    "                target = rewards\n",
    "            else:\n",
    "                #target = reward + self.gamma * target_q_max\n",
    "                target = rewards + self.gamma * target_q_max\n",
    "            print(f\"target: {target}\")\n",
    "            targets.append(target)\n",
    "\n",
    "        state_batch = np.squeeze(state_batch)\n",
    "        #print(f\"State batch {state_batch.shape}\")    \n",
    "        state_batch_array = np.array(state_batch)\n",
    "        #print(f\"targets: {targets}\")\n",
    "        targets_array = np.array(targets, dtype=np.float32)\n",
    "        targets_array = targets_array.reshape((BATCH_SIZE, -1))\n",
    "        #targets_array = np.expand_dims(targets_array, axis=0)\n",
    "        #print(targets_array.shape)\n",
    "        #print(targets_array)\n",
    "\n",
    "        self.q_net.train_on_batch(state_batch_array, targets_array)\n",
    "        self.step_counter +=1\n",
    "        print (f\"Training step {self.step_counter}\")\n",
    "        #print(state_batch)  \n",
    "        #print(state_batch.shape)\n",
    "    \n",
    "    def train_agent(self):\n",
    "\n",
    "        version = 0 # versioning for model saving\n",
    "        scores = []\n",
    "        episodes = []\n",
    "        avg_scores = []\n",
    "        \n",
    "        for i in range (EPISODES):\n",
    "            done = False\n",
    "            score = 0.0\n",
    "            state = env.reset()\n",
    "\n",
    "            while not done:\n",
    "\n",
    "\n",
    "                state, action, reward, new_state, done, info = self.play_one_step(env, state)\n",
    "                score += reward\n",
    "                self.remember(state, action, reward, new_state, done) \n",
    "                state = new_state\n",
    "                self.train()\n",
    "                #self.step_counter += 1 # already updated in the self.train method\n",
    "\n",
    "                # update the target_network regularly\n",
    "                if self.step_counter % SYNC_TARGET_FREQ == 0:\n",
    "                    self.update_target_network()\n",
    "                    print(f\"Step: {self.step_counter} -  updating target model\")\n",
    "\n",
    "                if self.step_counter % LOGGING_FREQ == 0:\n",
    "                    print(f\"Episode {i}/ {EPISODES}, epsilon: {self.epsilon}, score: {score}\")\n",
    "\n",
    "\n",
    "\n",
    "            scores.append(score)\n",
    "            episodes.append(i)\n",
    "\n",
    "            avg_score= np.mean(scores[-AVG_SCORE_STEP:])\n",
    "\n",
    "            avg_scores.append(avg_score)\n",
    "\n",
    "            print(f\"Finished episode {i}/ {EPISODES}, epsilon: {self.epsilon}, score: {score}, avg. score: {avg_score}\") \n",
    "        \n",
    "        if score == 21:\n",
    "            self.save_model(version)\n",
    "            version +=1\n",
    "            print(f\"Episode {i}/ {EPISODES}, epsilon: {self.epsilon}, score: {score}, avg. score: {avg_score}\") \n",
    "\n",
    "        return ### Do Python methods in classes need a return statement?\n",
    "\n",
    "\n",
    "    def save_model(self, version):\n",
    "        self.q_net.save((f\"models/dqn_model_{version}\"))\n",
    "        self.q_net.save_weights((f\"models/dqn_model_{version}/weights_{version}.h5\"))\n",
    "\n",
    "    def save_replay_buffer(self):\n",
    "        outfile = open(self.buffer_filename,'wb')\n",
    "        pickle.dump(self.replay_buffer,outfile)\n",
    "        outfile.close()\n",
    "        return print(f\"Saved Replay Buffer to {self.buffer_filename} \")\n",
    "\n",
    "    def load_replay_buffer(self):\n",
    "        infile = open(self.buffer_filename,'rb')\n",
    "        self.replay_buffer = pickle.load(infile)\n",
    "        infile.close()\n",
    "        return print(f\"Loaded {self.buffer_filename} to Replay Buffer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 4)\n"
     ]
    }
   ],
   "source": [
    "input_shape = env.observation_space.shape\n",
    "print(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DQN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_48 (Conv2D)          (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " activation_72 (Activation)  (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_73 (Activation)  (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_74 (Activation)  (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " input_30 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_75 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      " activation_76 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,686,693\n",
      "Trainable params: 1,686,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"DQN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_51 (Conv2D)          (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " activation_77 (Activation)  (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_78 (Activation)  (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_79 (Activation)  (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " input_32 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_80 (Activation)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 5)                 2565      \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,686,693\n",
      "Trainable params: 1,686,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Failed to load replay buffer from disk. Started to fill replay buffer.\n",
      "ReplayBuffer is filled!\n",
      "Saved Replay Buffer to replay_buffer.pkl \n"
     ]
    }
   ],
   "source": [
    "agent = DoubleDQNAgent(input_shape, useful_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 rewards: positive rewards: 0, negative rewards: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(     action  reward   done\n",
       " 0         3     0.0  False\n",
       " 1         0     0.0  False\n",
       " 2         2     0.0  False\n",
       " 3         5     0.0  False\n",
       " 4         3     0.0  False\n",
       " ..      ...     ...    ...\n",
       " 995       2     0.0   True\n",
       " 996       5     0.0   True\n",
       " 997       5     0.0   True\n",
       " 998       0     0.0   True\n",
       " 999       3     0.0   True\n",
       " \n",
       " [1000 rows x 3 columns],\n",
       " 21,\n",
       " 979,\n",
       " 0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded replay_buffer.pkl to Replay Buffer\n"
     ]
    }
   ],
   "source": [
    "agent.load_replay_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.13783324 0.13783324 0.13783324 0.13783324 0.13783324]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.14010654 0.14010654 0.14010654 0.14010654 0.14010654]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "Training step 1\n"
     ]
    }
   ],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.13605039 0.13605039 0.13605039 0.13605039 0.13605039]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "Training step 2\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13876456 0.13876456 0.13876456 0.13876456 0.13876456]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "Training step 3\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.14161742 0.14161742 0.14161742 0.14161742 0.14161742]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "Training step 4\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "Training step 5\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [-0.86381398  0.13618602  0.13618602  0.13618602  0.13618602]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13605039 0.13605039 0.13605039 0.13605039 0.13605039]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.13876456 0.13876456 0.13876456 0.13876456 0.13876456]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "Training step 6\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13783324 0.13783324 0.13783324 0.13783324 0.13783324]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [-0.86381398  0.13618602  0.13618602  0.13618602  0.13618602]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14218344 0.14218344 0.14218344 0.14218344 0.14218344]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "Training step 7\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "Training step 8\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "Training step 9\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13609289 0.13609289 0.13609289 0.13609289 0.13609289]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.13605039 0.13605039 0.13605039 0.13605039 0.13605039]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13876456 0.13876456 0.13876456 0.13876456 0.13876456]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "Training step 10\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.14161742 0.14161742 0.14161742 0.14161742 0.14161742]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "Training step 11\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.13783324 0.13783324 0.13783324 0.13783324 0.13783324]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.13605039 0.13605039 0.13605039 0.13605039 0.13605039]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "Training step 12\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13605039 0.13605039 0.13605039 0.13605039 0.13605039]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "Training step 13\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "Training step 14\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.14010654 0.14010654 0.14010654 0.14010654 0.14010654]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.14161742 0.14161742 0.14161742 0.14161742 0.14161742]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.14218344 0.14218344 0.14218344 0.14218344 0.14218344]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "Training step 15\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13876456 0.13876456 0.13876456 0.13876456 0.13876456]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "Training step 16\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.14218344 0.14218344 0.14218344 0.14218344 0.14218344]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "Training step 17\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "Training step 18\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.13783324 0.13783324 0.13783324 0.13783324 0.13783324]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "Training step 19\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13876456 0.13876456 0.13876456 0.13876456 0.13876456]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13709469 0.13709469 0.13709469 0.13709469 0.13709469]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "Training step 20\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "Training step 21\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "Training step 22\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.14218344 0.14218344 0.14218344 0.14218344 0.14218344]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "Training step 23\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "Training step 24\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13876456 0.13876456 0.13876456 0.13876456 0.13876456]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.13591814 0.13591814 0.13591814 0.13591814 0.13591814]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.14161742 0.14161742 0.14161742 0.14161742 0.14161742]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "Training step 25\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "Training step 26\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "Training step 27\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13609289 0.13609289 0.13609289 0.13609289 0.13609289]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.14014839 0.14014839 0.14014839 0.14014839 0.14014839]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "Training step 28\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.13934252 0.13934252 0.13934252 0.13934252 0.13934252]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14010654 0.14010654 0.14010654 0.14010654 0.14010654]\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "Training step 29\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.13064812 0.13064812 0.13064812 0.13064812 0.13064812]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "Training step 30\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.14131285 0.14131285 0.14131285 0.14131285 0.14131285]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.13960077 0.13960077 0.13960077 0.13960077 0.13960077]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "Training step 31\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13605039 0.13605039 0.13605039 0.13605039 0.13605039]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.13609289 0.13609289 0.13609289 0.13609289 0.13609289]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "Training step 32\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.14010654 0.14010654 0.14010654 0.14010654 0.14010654]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "Training step 33\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14010654 0.14010654 0.14010654 0.14010654 0.14010654]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.13783324 0.13783324 0.13783324 0.13783324 0.13783324]\n",
      "target: [-0.86381398  0.13618602  0.13618602  0.13618602  0.13618602]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.13663793 0.13663793 0.13663793 0.13663793 0.13663793]\n",
      "target: [0.13972247 0.13972247 0.13972247 0.13972247 0.13972247]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.13245742 0.13245742 0.13245742 0.13245742 0.13245742]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.13960077 0.13960077 0.13960077 0.13960077 0.13960077]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.12600516 0.12600516 0.12600516 0.12600516 0.12600516]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13608041 0.13608041 0.13608041 0.13608041 0.13608041]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "Training step 34\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.14106898 0.14106898 0.14106898 0.14106898 0.14106898]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13744535 0.13744535 0.13744535 0.13744535 0.13744535]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.14045243 0.14045243 0.14045243 0.14045243 0.14045243]\n",
      "target: [0.14307144 0.14307144 0.14307144 0.14307144 0.14307144]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13614492 0.13614492 0.13614492 0.13614492 0.13614492]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.14131285 0.14131285 0.14131285 0.14131285 0.14131285]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.13678584 0.13678584 0.13678584 0.13678584 0.13678584]\n",
      "target: [0.13333696 0.13333696 0.13333696 0.13333696 0.13333696]\n",
      "Training step 35\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14229918 0.14229918 0.14229918 0.14229918 0.14229918]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.14044662 0.14044662 0.14044662 0.14044662 0.14044662]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.13775434 0.13775434 0.13775434 0.13775434 0.13775434]\n",
      "target: [0.13722198 0.13722198 0.13722198 0.13722198 0.13722198]\n",
      "target: [0.13896985 0.13896985 0.13896985 0.13896985 0.13896985]\n",
      "target: [0.13847096 0.13847096 0.13847096 0.13847096 0.13847096]\n",
      "target: [0.13371663 0.13371663 0.13371663 0.13371663 0.13371663]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13451105 0.13451105 0.13451105 0.13451105 0.13451105]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "Training step 36\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13790828 0.13790828 0.13790828 0.13790828 0.13790828]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13400531 0.13400531 0.13400531 0.13400531 0.13400531]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.1351478 0.1351478 0.1351478 0.1351478 0.1351478]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.1351478 0.1351478 0.1351478 0.1351478 0.1351478]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.13678584 0.13678584 0.13678584 0.13678584 0.13678584]\n",
      "target: [0.13744535 0.13744535 0.13744535 0.13744535 0.13744535]\n",
      "target: [0.14010654 0.14010654 0.14010654 0.14010654 0.14010654]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.14161742 0.14161742 0.14161742 0.14161742 0.14161742]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13570976 0.13570976 0.13570976 0.13570976 0.13570976]\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "Training step 37\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.14045243 0.14045243 0.14045243 0.14045243 0.14045243]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13878377 0.13878377 0.13878377 0.13878377 0.13878377]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.1351478 0.1351478 0.1351478 0.1351478 0.1351478]\n",
      "target: [0.13775434 0.13775434 0.13775434 0.13775434 0.13775434]\n",
      "target: [0.13559259 0.13559259 0.13559259 0.13559259 0.13559259]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.14091191 0.14091191 0.14091191 0.14091191 0.14091191]\n",
      "target: [0.13960077 0.13960077 0.13960077 0.13960077 0.13960077]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [-0.86381398  0.13618602  0.13618602  0.13618602  0.13618602]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.1421767 0.1421767 0.1421767 0.1421767 0.1421767]\n",
      "target: [0.13959065 0.13959065 0.13959065 0.13959065 0.13959065]\n",
      "target: [0.14218344 0.14218344 0.14218344 0.14218344 0.14218344]\n",
      "Training step 38\n",
      "target: [0.14160801 0.14160801 0.14160801 0.14160801 0.14160801]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.13443024 0.13443024 0.13443024 0.13443024 0.13443024]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13915834 0.13915834 0.13915834 0.13915834 0.13915834]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13583262 0.13583262 0.13583262 0.13583262 0.13583262]\n",
      "target: [0.13763298 0.13763298 0.13763298 0.13763298 0.13763298]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.13959266 0.13959266 0.13959266 0.13959266 0.13959266]\n",
      "target: [0.14011991 0.14011991 0.14011991 0.14011991 0.14011991]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.13969581 0.13969581 0.13969581 0.13969581 0.13969581]\n",
      "target: [0.1396378 0.1396378 0.1396378 0.1396378 0.1396378]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.1351478 0.1351478 0.1351478 0.1351478 0.1351478]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [0.1351478 0.1351478 0.1351478 0.1351478 0.1351478]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "Training step 39\n",
      "target: [0.13706218 0.13706218 0.13706218 0.13706218 0.13706218]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.13790929 0.13790929 0.13790929 0.13790929 0.13790929]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13938737 0.13938737 0.13938737 0.13938737 0.13938737]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13678584 0.13678584 0.13678584 0.13678584 0.13678584]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.14181928 0.14181928 0.14181928 0.14181928 0.14181928]\n",
      "target: [0.14250663 0.14250663 0.14250663 0.14250663 0.14250663]\n",
      "target: [0.13775434 0.13775434 0.13775434 0.13775434 0.13775434]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.14176078 0.14176078 0.14176078 0.14176078 0.14176078]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.13725951 0.13725951 0.13725951 0.13725951 0.13725951]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.12897466 0.12897466 0.12897466 0.12897466 0.12897466]\n",
      "target: [0.14131285 0.14131285 0.14131285 0.14131285 0.14131285]\n",
      "target: [0.13431513 0.13431513 0.13431513 0.13431513 0.13431513]\n",
      "target: [0.14009814 0.14009814 0.14009814 0.14009814 0.14009814]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.1393801 0.1393801 0.1393801 0.1393801 0.1393801]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "Training step 40\n",
      "target: [0.13775434 0.13775434 0.13775434 0.13775434 0.13775434]\n",
      "target: [0.14530762 0.14530762 0.14530762 0.14530762 0.14530762]\n",
      "target: [0.13663793 0.13663793 0.13663793 0.13663793 0.13663793]\n",
      "target: [0.13617149 0.13617149 0.13617149 0.13617149 0.13617149]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.13134892 0.13134892 0.13134892 0.13134892 0.13134892]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [-0.85629247  0.14370753  0.14370753  0.14370753  0.14370753]\n",
      "target: [0.13560712 0.13560712 0.13560712 0.13560712 0.13560712]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14131285 0.14131285 0.14131285 0.14131285 0.14131285]\n",
      "target: [0.14247653 0.14247653 0.14247653 0.14247653 0.14247653]\n",
      "target: [0.14595765 0.14595765 0.14595765 0.14595765 0.14595765]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.13590428 0.13590428 0.13590428 0.13590428 0.13590428]\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.13794863 0.13794863 0.13794863 0.13794863 0.13794863]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.14131285 0.14131285 0.14131285 0.14131285 0.14131285]\n",
      "target: [0.14087275 0.14087275 0.14087275 0.14087275 0.14087275]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.14014851 0.14014851 0.14014851 0.14014851 0.14014851]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.14112514 0.14112514 0.14112514 0.14112514 0.14112514]\n",
      "target: [0.13880114 0.13880114 0.13880114 0.13880114 0.13880114]\n",
      "Training step 41\n",
      "target: [0.14424866 0.14424866 0.14424866 0.14424866 0.14424866]\n",
      "target: [0.12411826 0.12411826 0.12411826 0.12411826 0.12411826]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.13960116 0.13960116 0.13960116 0.13960116 0.13960116]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.1358154 0.1358154 0.1358154 0.1358154 0.1358154]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.12888363 0.12888363 0.12888363 0.12888363 0.12888363]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.14300066 0.14300066 0.14300066 0.14300066 0.14300066]\n",
      "target: [0.13885905 0.13885905 0.13885905 0.13885905 0.13885905]\n",
      "target: [0.13387497 0.13387497 0.13387497 0.13387497 0.13387497]\n",
      "target: [0.13960077 0.13960077 0.13960077 0.13960077 0.13960077]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "target: [0.13134892 0.13134892 0.13134892 0.13134892 0.13134892]\n",
      "target: [0.1365559 0.1365559 0.1365559 0.1365559 0.1365559]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.13756882 0.13756882 0.13756882 0.13756882 0.13756882]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.13744535 0.13744535 0.13744535 0.13744535 0.13744535]\n",
      "target: [0.13312843 0.13312843 0.13312843 0.13312843 0.13312843]\n",
      "target: [0.13204329 0.13204329 0.13204329 0.13204329 0.13204329]\n",
      "target: [0.1367414 0.1367414 0.1367414 0.1367414 0.1367414]\n",
      "target: [0.13775434 0.13775434 0.13775434 0.13775434 0.13775434]\n",
      "target: [0.14457579 0.14457579 0.14457579 0.14457579 0.14457579]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "target: [0.15298167 0.15298167 0.15298167 0.15298167 0.15298167]\n",
      "target: [0.13678584 0.13678584 0.13678584 0.13678584 0.13678584]\n",
      "target: [0.14157195 0.14157195 0.14157195 0.14157195 0.14157195]\n",
      "Training step 42\n",
      "target: [0.13593699 0.13593699 0.13593699 0.13593699 0.13593699]\n",
      "target: [0.14072025 0.14072025 0.14072025 0.14072025 0.14072025]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.13923649 0.13923649 0.13923649 0.13923649 0.13923649]\n",
      "target: [0.13571374 0.13571374 0.13571374 0.13571374 0.13571374]\n",
      "target: [0.14119501 0.14119501 0.14119501 0.14119501 0.14119501]\n",
      "target: [0.14000392 0.14000392 0.14000392 0.14000392 0.14000392]\n",
      "target: [0.13603258 0.13603258 0.13603258 0.13603258 0.13603258]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13720797 0.13720797 0.13720797 0.13720797 0.13720797]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.1358704 0.1358704 0.1358704 0.1358704 0.1358704]\n",
      "target: [0.1358154 0.1358154 0.1358154 0.1358154 0.1358154]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.14359321 0.14359321 0.14359321 0.14359321 0.14359321]\n",
      "target: [0.13619521 0.13619521 0.13619521 0.13619521 0.13619521]\n",
      "target: [0.1393801 0.1393801 0.1393801 0.1393801 0.1393801]\n",
      "target: [0.13805185 0.13805185 0.13805185 0.13805185 0.13805185]\n",
      "target: [0.14131285 0.14131285 0.14131285 0.14131285 0.14131285]\n",
      "target: [0.1351478 0.1351478 0.1351478 0.1351478 0.1351478]\n",
      "target: [0.13991539 0.13991539 0.13991539 0.13991539 0.13991539]\n",
      "target: [0.13691765 0.13691765 0.13691765 0.13691765 0.13691765]\n",
      "target: [0.13961978 0.13961978 0.13961978 0.13961978 0.13961978]\n",
      "target: [0.14239693 0.14239693 0.14239693 0.14239693 0.14239693]\n",
      "target: [0.17075911 0.17075911 0.17075911 0.17075911 0.17075911]\n",
      "target: [0.13760193 0.13760193 0.13760193 0.13760193 0.13760193]\n",
      "target: [0.14151956 0.14151956 0.14151956 0.14151956 0.14151956]\n",
      "target: [0.12942651 0.12942651 0.12942651 0.12942651 0.12942651]\n",
      "target: [0.13488899 0.13488899 0.13488899 0.13488899 0.13488899]\n",
      "target: [0.1306302 0.1306302 0.1306302 0.1306302 0.1306302]\n",
      "target: [0.13411239 0.13411239 0.13411239 0.13411239 0.13411239]\n",
      "Training step 43\n",
      "target: [0.1393107 0.1393107 0.1393107 0.1393107 0.1393107]\n",
      "target: [0.13836816 0.13836816 0.13836816 0.13836816 0.13836816]\n",
      "target: [0.14250663 0.14250663 0.14250663 0.14250663 0.14250663]\n",
      "target: [0.1382997 0.1382997 0.1382997 0.1382997 0.1382997]\n",
      "target: [0.13936688 0.13936688 0.13936688 0.13936688 0.13936688]\n",
      "target: [0.13011836 0.13011836 0.13011836 0.13011836 0.13011836]\n",
      "target: [0.13818842 0.13818842 0.13818842 0.13818842 0.13818842]\n",
      "target: [0.13827935 0.13827935 0.13827935 0.13827935 0.13827935]\n",
      "target: [0.13775434 0.13775434 0.13775434 0.13775434 0.13775434]\n",
      "target: [0.13917166 0.13917166 0.13917166 0.13917166 0.13917166]\n",
      "target: [0.1409858 0.1409858 0.1409858 0.1409858 0.1409858]\n",
      "target: [0.13393801 0.13393801 0.13393801 0.13393801 0.13393801]\n",
      "target: [0.14220831 0.14220831 0.14220831 0.14220831 0.14220831]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.1393801 0.1393801 0.1393801 0.1393801 0.1393801]\n",
      "target: [0.14125462 0.14125462 0.14125462 0.14125462 0.14125462]\n",
      "target: [0.1366725 0.1366725 0.1366725 0.1366725 0.1366725]\n",
      "target: [0.14022771 0.14022771 0.14022771 0.14022771 0.14022771]\n",
      "target: [0.13134892 0.13134892 0.13134892 0.13134892 0.13134892]\n",
      "target: [0.1349698 0.1349698 0.1349698 0.1349698 0.1349698]\n",
      "target: [0.14045243 0.14045243 0.14045243 0.14045243 0.14045243]\n",
      "target: [0.13887106 0.13887106 0.13887106 0.13887106 0.13887106]\n",
      "target: [0.13828745 0.13828745 0.13828745 0.13828745 0.13828745]\n",
      "target: [0.13742179 0.13742179 0.13742179 0.13742179 0.13742179]\n",
      "target: [0.14239693 0.14239693 0.14239693 0.14239693 0.14239693]\n",
      "target: [0.13883206 0.13883206 0.13883206 0.13883206 0.13883206]\n",
      "target: [0.14135432 0.14135432 0.14135432 0.14135432 0.14135432]\n",
      "target: [0.13536964 0.13536964 0.13536964 0.13536964 0.13536964]\n",
      "target: [0.1399993 0.1399993 0.1399993 0.1399993 0.1399993]\n",
      "target: [0.152253 0.152253 0.152253 0.152253 0.152253]\n",
      "target: [0.13495116 0.13495116 0.13495116 0.13495116 0.13495116]\n",
      "target: [0.14045243 0.14045243 0.14045243 0.14045243 0.14045243]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=0'>1</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtrain_agent()\n",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 24\u001b[0m in \u001b[0;36mDoubleDQNAgent.train_agent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=143'>144</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember(state, action, reward, new_state, done) \n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=144'>145</a>\u001b[0m state \u001b[39m=\u001b[39m new_state\n\u001b[1;32m--> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=145'>146</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=146'>147</a>\u001b[0m \u001b[39m#self.step_counter += 1 # already updated in the self.train method\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=147'>148</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=148'>149</a>\u001b[0m \u001b[39m# update the target_network regularly\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=149'>150</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_counter \u001b[39m%\u001b[39m SYNC_TARGET_FREQ \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 24\u001b[0m in \u001b[0;36mDoubleDQNAgent.train\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=115'>116</a>\u001b[0m targets_array \u001b[39m=\u001b[39m targets_array\u001b[39m.\u001b[39mreshape((BATCH_SIZE, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=116'>117</a>\u001b[0m \u001b[39m#targets_array = np.expand_dims(targets_array, axis=0)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=117'>118</a>\u001b[0m \u001b[39m#print(targets_array.shape)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=118'>119</a>\u001b[0m \u001b[39m#print(targets_array)\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_net\u001b[39m.\u001b[39;49mtrain_on_batch(state_batch_array, targets_array)\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=122'>123</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining step \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_counter\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\training.py:2146\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2143\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[0;32m   2144\u001b[0m   logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m-> 2146\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2147\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n\u001b[0;32m   2148\u001b[0m   \u001b[39mreturn\u001b[39;00m logs\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 rewards: positive rewards: 0, negative rewards: 2\n"
     ]
    }
   ],
   "source": [
    "df, _,_,_ =agent.replay_buffer_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 98]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_index = list(df.loc[(df.reward == -1) | (df.reward == 1)].index)\n",
    "reward_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<wrappers.LazyFrames at 0x1c0cca950d0>,\n",
       " 3,\n",
       " -1.0,\n",
       " <wrappers.LazyFrames at 0x1c0cca95130>,\n",
       " False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in reward_index:\n",
    "    agent.reward_replay_buffer.append(agent.replay_buffer[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(<wrappers.LazyFrames at 0x1c0cca950d0>,\n",
       "        3,\n",
       "        -1.0,\n",
       "        <wrappers.LazyFrames at 0x1c0cca95130>,\n",
       "        False),\n",
       "       (<wrappers.LazyFrames at 0x1c0cca95df0>,\n",
       "        2,\n",
       "        -1.0,\n",
       "        <wrappers.LazyFrames at 0x1c0cca95e50>,\n",
       "        False)])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.reward_replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReplayBuffer is filled!\n"
     ]
    }
   ],
   "source": [
    "agent.fill_replay_buffer(env, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = random.sample(agent.replay_buffer, 32)\n",
    "type(batch)\n",
    "#state_batch, action_batch, reward_batch, new_state_batch, done_batch\n",
    "#state, action, reward, new_state, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence index must be integer, not 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000044?line=0'>1</a>\u001b[0m \u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m agent\u001b[39m.\u001b[39;49mreplay_buffer[:][\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence index must be integer, not 'slice'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<wrappers.LazyFrames at 0x1bf3a6422e0>,\n",
       " 3,\n",
       " 0.0,\n",
       " <wrappers.LazyFrames at 0x1bf3a642400>,\n",
       " False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in reward_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_actions = [item[1] for item in agent.replay_buffer]\n",
    "buffer_rewards = [item[2] for item in agent.replay_buffer]\n",
    "buffer_dones = [item[4] for item in agent.replay_buffer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 2, 4, 0, 5, 0, 3, 2, 0, 3, 0, 4, 5, 5, 0, 5, 3, 3, 4, 4, 3, 4, 0, 0, 5, 0, 5, 0, 2, 5, 0]\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "action_batch = [item[1] for item in batch]\n",
    "print(action_batch)\n",
    "reward_batch =[[item[2] for item in batch]]\n",
    "print(reward_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 rewards: positive rewards: 0, negative rewards: 2\n"
     ]
    }
   ],
   "source": [
    "results = data_stats(buffer_actions, buffer_rewards, buffer_dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    action  reward   done\n",
       "0        4     0.0  False\n",
       "1        5     0.0  False\n",
       "2        4     0.0  False\n",
       "3        3     0.0  False\n",
       "4        3     0.0  False\n",
       "..     ...     ...    ...\n",
       "95       4     0.0  False\n",
       "96       2     0.0  False\n",
       "97       3     0.0  False\n",
       "98       2    -1.0  False\n",
       "99       0     0.0  False\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_data = list(zip(buffer_actions, buffer_rewards, buffer_dones))\n",
    "df = pd.DataFrame(buffer_data, columns =[\"action\", \"reward\", \"done\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 rewards: positive rewards: 0, negative rewards: 2\n"
     ]
    }
   ],
   "source": [
    "num_neg_rewards = len(df[df[\"reward\"] == -1])\n",
    "num_zero_rewards = len(df[df[\"reward\"] == 0])\n",
    "num_pos_rewards = len(df[df[\"reward\"] == 1])\n",
    "print(f\"{num_neg_rewards + num_pos_rewards+ num_zero_rewards} rewards: positive rewards: {num_pos_rewards}, negative rewards: {num_neg_rewards}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "Training step 1\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "Training step 2\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "Training step 3\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "Training step 4\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "Training step 5\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "Training step 6\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "Training step 7\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "Training step 8\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03300688 0.03300688 0.03300688 0.03300688 0.03300688]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 9\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "Training step 10\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "Training step 11\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 12\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "Training step 13\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "Training step 14\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "Training step 15\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "Training step 16\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "Training step 17\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "Training step 18\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03471951 0.03471951 0.03471951 0.03471951 0.03471951]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "Training step 19\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "Training step 20\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "Training step 21\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "Training step 22\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 23\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "Training step 24\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "Training step 25\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "Training step 26\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "Training step 27\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "Training step 28\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 29\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 30\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "Training step 31\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "Training step 32\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "Training step 33\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "Training step 34\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "Training step 35\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "Training step 36\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.0332848 0.0332848 0.0332848 0.0332848 0.0332848]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "Training step 37\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "Training step 38\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "Training step 39\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "Training step 40\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "Training step 41\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "Training step 42\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "Training step 43\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 44\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "Training step 45\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 46\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "Training step 47\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 48\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "Training step 49\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 50\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "Training step 51\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "Training step 52\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "Training step 53\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "Training step 54\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "Training step 55\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03459824 0.03459824 0.03459824 0.03459824 0.03459824]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "Training step 56\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "Training step 57\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "Training step 58\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.0332848 0.0332848 0.0332848 0.0332848 0.0332848]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 59\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "Training step 60\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "Training step 61\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 62\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "Training step 63\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "Training step 64\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "Training step 65\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 66\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "Training step 67\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "Training step 68\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "Training step 69\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "Training step 70\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "Training step 71\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 72\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "Training step 73\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "Training step 74\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "Training step 75\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "Training step 76\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "Training step 77\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 78\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "Training step 79\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "Training step 80\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 81\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "Training step 82\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "Training step 83\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "Training step 84\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "Training step 85\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "Training step 86\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 87\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03459824 0.03459824 0.03459824 0.03459824 0.03459824]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "Training step 88\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "Training step 89\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "Training step 90\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "Training step 91\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "Training step 92\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 93\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "Training step 94\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "Training step 95\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "Training step 96\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "Training step 97\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "Training step 98\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "Training step 99\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03187704 0.03187704 0.03187704 0.03187704 0.03187704]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 100\n",
      "Episode 0/ 2, epsilon: 0.8999999999999999, score: -2.0\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03151607 0.03151607 0.03151607 0.03151607 0.03151607]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "Training step 101\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "Training step 102\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "Training step 103\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 104\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332848 0.0332848 0.0332848 0.0332848 0.0332848]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "Training step 105\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "Training step 106\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03151607 0.03151607 0.03151607 0.03151607 0.03151607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "Training step 107\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.0332848 0.0332848 0.0332848 0.0332848 0.0332848]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "Training step 108\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "Training step 109\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "Training step 110\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 111\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 112\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "Training step 113\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 114\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "Training step 115\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 116\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "Training step 117\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "Training step 118\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 119\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "Training step 120\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "Training step 121\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "Training step 122\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "Training step 123\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "Training step 124\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "Training step 125\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 126\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 127\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "Training step 128\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "Training step 129\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "Training step 130\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "Training step 131\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "Training step 132\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 133\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 134\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "Training step 135\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 136\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "Training step 137\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "Training step 138\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "Training step 139\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "Training step 140\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "Training step 141\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "Training step 142\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "Training step 143\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "Training step 144\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03187704 0.03187704 0.03187704 0.03187704 0.03187704]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 145\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "Training step 146\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "Training step 147\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "Training step 148\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "Training step 149\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.0332848 0.0332848 0.0332848 0.0332848 0.0332848]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "Training step 150\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "Training step 151\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "Training step 152\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "Training step 153\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "Training step 154\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "Training step 155\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "Training step 156\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 157\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "Training step 158\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "Training step 159\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "Training step 160\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "Training step 161\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "Training step 162\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "Training step 163\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "Training step 164\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "Training step 165\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 166\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03459824 0.03459824 0.03459824 0.03459824 0.03459824]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "Training step 167\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 168\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 169\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "Training step 170\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "Training step 171\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "Training step 172\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "Training step 173\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "Training step 174\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "Training step 175\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 176\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "Training step 177\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "Training step 178\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "Training step 179\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "Training step 180\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "Training step 181\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "Training step 182\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "Training step 183\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "Training step 184\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "Training step 185\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "Training step 186\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "Training step 187\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03151607 0.03151607 0.03151607 0.03151607 0.03151607]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "Training step 188\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187704 0.03187704 0.03187704 0.03187704 0.03187704]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "Training step 189\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "Training step 190\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "Training step 191\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "Training step 192\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "Training step 193\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "Training step 194\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "Training step 195\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "Training step 196\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "Training step 197\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "Training step 198\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "Training step 199\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "Training step 200\n",
      "Episode 0/ 2, epsilon: 0.7999999999999998, score: -4.0\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03471951 0.03471951 0.03471951 0.03471951 0.03471951]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 201\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 202\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 203\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "Training step 204\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 205\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03471951 0.03471951 0.03471951 0.03471951 0.03471951]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 206\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "Training step 207\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 208\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "Training step 209\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "Training step 210\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "Training step 211\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "Training step 212\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "Training step 213\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "Training step 214\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "Training step 215\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "Training step 216\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "Training step 217\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "Training step 218\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 219\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "Training step 220\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "Training step 221\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "Training step 222\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "Training step 223\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "Training step 224\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "Training step 225\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "Training step 226\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "Training step 227\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "Training step 228\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "Training step 229\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 230\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 231\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "Training step 232\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "Training step 233\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "Training step 234\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "Training step 235\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03300688 0.03300688 0.03300688 0.03300688 0.03300688]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "Training step 236\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "Training step 237\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "Training step 238\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "Training step 239\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "Training step 240\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 241\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "Training step 242\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "Training step 243\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "Training step 244\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "Training step 245\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "Training step 246\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "Training step 247\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "Training step 248\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "Training step 249\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "Training step 250\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "Training step 251\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "Training step 252\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "Training step 253\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "Training step 254\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03300688 0.03300688 0.03300688 0.03300688 0.03300688]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "Training step 255\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "Training step 256\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "Training step 257\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "Training step 258\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "Training step 259\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "Training step 260\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 261\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 262\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "Training step 263\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "Training step 264\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "Training step 265\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "Training step 266\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "Training step 267\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "Training step 268\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "Training step 269\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "Training step 270\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "Training step 271\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "Training step 272\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "Training step 273\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "Training step 274\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "Training step 275\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "Training step 276\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 277\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "Training step 278\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "Training step 279\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "Training step 280\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "Training step 281\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 282\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "Training step 283\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "Training step 284\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "Training step 285\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "Training step 286\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 287\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 288\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "Training step 289\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "Training step 290\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "Training step 291\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "Training step 292\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 293\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "Training step 294\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "Training step 295\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "Training step 296\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "Training step 297\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "Training step 298\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 299\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "Training step 300\n",
      "Episode 0/ 2, epsilon: 0.6999999999999997, score: -6.0\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03300688 0.03300688 0.03300688 0.03300688 0.03300688]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "Training step 301\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "Training step 302\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "Training step 303\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 304\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 305\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "Training step 306\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "Training step 307\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 308\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "Training step 309\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "Training step 310\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "Training step 311\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "Training step 312\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "Training step 313\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 314\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "Training step 315\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "Training step 316\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "Training step 317\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "Training step 318\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "Training step 319\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "Training step 320\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "Training step 321\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03187704 0.03187704 0.03187704 0.03187704 0.03187704]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "Training step 322\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 323\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "Training step 324\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03181498 0.03181498 0.03181498 0.03181498 0.03181498]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "Training step 325\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "Training step 326\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 327\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "Training step 328\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "Training step 329\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "Training step 330\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "Training step 331\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "Training step 332\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "Training step 333\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 334\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "Training step 335\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "Training step 336\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "Training step 337\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "Training step 338\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 339\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "Training step 340\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "Training step 341\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "Training step 342\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "Training step 343\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "Training step 344\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "Training step 345\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "Training step 346\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "Training step 347\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 348\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "Training step 349\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "Training step 350\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "Training step 351\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "Training step 352\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "Training step 353\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "Training step 354\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "Training step 355\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "Training step 356\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03187704 0.03187704 0.03187704 0.03187704 0.03187704]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 357\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "Training step 358\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 359\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "Training step 360\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "Training step 361\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 362\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "Training step 363\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "Training step 364\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 365\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "Training step 366\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "Training step 367\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 368\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "Training step 369\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "Training step 370\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "Training step 371\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 372\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "Training step 373\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "Training step 374\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "Training step 375\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "Training step 376\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "Training step 377\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "Training step 378\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "Training step 379\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "Training step 380\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 381\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "Training step 382\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "Training step 383\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "Training step 384\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "Training step 385\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 386\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "Training step 387\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "Training step 388\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "Training step 389\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "Training step 390\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "Training step 391\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "Training step 392\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "Training step 393\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "Training step 394\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "Training step 395\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "Training step 396\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "Training step 397\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "Training step 398\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "Training step 399\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "Training step 400\n",
      "Episode 0/ 2, epsilon: 0.5999999999999996, score: -9.0\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "Training step 401\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "Training step 402\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "Training step 403\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "Training step 404\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "Training step 405\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "Training step 406\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "Training step 407\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 408\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "Training step 409\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "Training step 410\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "Training step 411\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "Training step 412\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "Training step 413\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "Training step 414\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "Training step 415\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 416\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "Training step 417\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "Training step 418\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "Training step 419\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "Training step 420\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "Training step 421\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "Training step 422\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "Training step 423\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "Training step 424\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "Training step 425\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "Training step 426\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "Training step 427\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "Training step 428\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "Training step 429\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 430\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "Training step 431\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "Training step 432\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "Training step 433\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "Training step 434\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "Training step 435\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "Training step 436\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "Training step 437\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 438\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 439\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "Training step 440\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "Training step 441\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 442\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "Training step 443\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "Training step 444\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 445\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 446\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "Training step 447\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "Training step 448\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 449\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "Training step 450\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 451\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "Training step 452\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 453\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "Training step 454\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "Training step 455\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "Training step 456\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "Training step 457\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "Training step 458\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "Training step 459\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "Training step 460\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "Training step 461\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "Training step 462\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03296169 0.03296169 0.03296169 0.03296169 0.03296169]\n",
      "Training step 463\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "Training step 464\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "Training step 465\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "Training step 466\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "Training step 467\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "Training step 468\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "Training step 469\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 470\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "Training step 471\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "Training step 472\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "Training step 473\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "Training step 474\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03151607 0.03151607 0.03151607 0.03151607 0.03151607]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "Training step 475\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03241428 0.03241428 0.03241428 0.03241428 0.03241428]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "Training step 476\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "Training step 477\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "Training step 478\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03129374 0.03129374 0.03129374 0.03129374 0.03129374]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "Training step 479\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "Training step 480\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "Training step 481\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 482\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "Training step 483\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03471951 0.03471951 0.03471951 0.03471951 0.03471951]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "Training step 484\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "Training step 485\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03459824 0.03459824 0.03459824 0.03459824 0.03459824]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "Training step 486\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 487\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "Training step 488\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "Training step 489\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "Training step 490\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "Training step 491\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "Training step 492\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "Training step 493\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 494\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "Training step 495\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "Training step 496\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "Training step 497\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "Training step 498\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "Training step 499\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "Training step 500\n",
      "Episode 0/ 2, epsilon: 0.49999999999999956, score: -11.0\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "Training step 501\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "Training step 502\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "Training step 503\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [-0.96898568  0.03101432  0.03101432  0.03101432  0.03101432]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "Training step 504\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03251294 0.03251294 0.03251294 0.03251294 0.03251294]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "Training step 505\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "Training step 506\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "Training step 507\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "Training step 508\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "Training step 509\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03231627 0.03231627 0.03231627 0.03231627 0.03231627]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "Training step 510\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "Training step 511\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "Training step 512\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "Training step 513\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03459824 0.03459824 0.03459824 0.03459824 0.03459824]\n",
      "Training step 514\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "Training step 515\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "Training step 516\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "Training step 517\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "Training step 518\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.0359062 0.0359062 0.0359062 0.0359062 0.0359062]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03471951 0.03471951 0.03471951 0.03471951 0.03471951]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "Training step 519\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.0359062 0.0359062 0.0359062 0.0359062 0.0359062]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "Training step 520\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 521\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "Training step 522\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "Training step 523\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03459824 0.03459824 0.03459824 0.03459824 0.03459824]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "Training step 524\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "Training step 525\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03109434 0.03109434 0.03109434 0.03109434 0.03109434]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "Training step 526\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "Training step 527\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03178197 0.03178197 0.03178197 0.03178197 0.03178197]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "Training step 528\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "Training step 529\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "Training step 530\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "Training step 531\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "Training step 532\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03185741 0.03185741 0.03185741 0.03185741 0.03185741]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "Training step 533\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.0299293 0.0299293 0.0299293 0.0299293 0.0299293]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "Training step 534\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03342794 0.03342794 0.03342794 0.03342794 0.03342794]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "Training step 535\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 536\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "Training step 537\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "Training step 538\n",
      "target: [0.03578923 0.03578923 0.03578923 0.03578923 0.03578923]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "Training step 539\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "Training step 540\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "Training step 541\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "Training step 542\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03471951 0.03471951 0.03471951 0.03471951 0.03471951]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "Training step 543\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "Training step 544\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03219992 0.03219992 0.03219992 0.03219992 0.03219992]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "Training step 545\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "Training step 546\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "Training step 547\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03283511 0.03283511 0.03283511 0.03283511 0.03283511]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "Training step 548\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "Training step 549\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "Training step 550\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.02978042 0.02978042 0.02978042 0.02978042 0.02978042]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 551\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03167742 0.03167742 0.03167742 0.03167742 0.03167742]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "Training step 552\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.0359062 0.0359062 0.0359062 0.0359062 0.0359062]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "Training step 553\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "Training step 554\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03308255 0.03308255 0.03308255 0.03308255 0.03308255]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "Training step 555\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03251294 0.03251294 0.03251294 0.03251294 0.03251294]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "Training step 556\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "Training step 557\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "Training step 558\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "Training step 559\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "Training step 560\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "Training step 561\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "Training step 562\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03139 0.03139 0.03139 0.03139 0.03139]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "Training step 563\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "Training step 564\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03109434 0.03109434 0.03109434 0.03109434 0.03109434]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "Training step 565\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "Training step 566\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03177023 0.03177023 0.03177023 0.03177023 0.03177023]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "Training step 567\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03116084 0.03116084 0.03116084 0.03116084 0.03116084]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "Training step 568\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "Training step 569\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 570\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "Training step 571\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "Training step 572\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307122 0.03307122 0.03307122 0.03307122 0.03307122]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "Training step 573\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "Training step 574\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03109434 0.03109434 0.03109434 0.03109434 0.03109434]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "Training step 575\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03231627 0.03231627 0.03231627 0.03231627 0.03231627]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 576\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "Training step 577\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "Training step 578\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "Training step 579\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "Training step 580\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251294 0.03251294 0.03251294 0.03251294 0.03251294]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "Training step 581\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03185741 0.03185741 0.03185741 0.03185741 0.03185741]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 582\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "Training step 583\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03231627 0.03231627 0.03231627 0.03231627 0.03231627]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "Training step 584\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0359062 0.0359062 0.0359062 0.0359062 0.0359062]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "Training step 585\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 586\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "Training step 587\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "Training step 588\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03177023 0.03177023 0.03177023 0.03177023 0.03177023]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "Training step 589\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03251294 0.03251294 0.03251294 0.03251294 0.03251294]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "Training step 590\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "Training step 591\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03167742 0.03167742 0.03167742 0.03167742 0.03167742]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "Training step 592\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03658507 0.03658507 0.03658507 0.03658507 0.03658507]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "Training step 593\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "Training step 594\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "Training step 595\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03736843 0.03736843 0.03736843 0.03736843 0.03736843]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "Training step 596\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167742 0.03167742 0.03167742 0.03167742 0.03167742]\n",
      "target: [0.03079526 0.03079526 0.03079526 0.03079526 0.03079526]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "Training step 597\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "Training step 598\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03219523 0.03219523 0.03219523 0.03219523 0.03219523]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 599\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03765684 0.03765684 0.03765684 0.03765684 0.03765684]\n",
      "target: [0.0314861 0.0314861 0.0314861 0.0314861 0.0314861]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "target: [0.03213383 0.03213383 0.03213383 0.03213383 0.03213383]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03011288 0.03011288 0.03011288 0.03011288 0.03011288]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 600\n",
      "Episode 0/ 2, epsilon: 0.39999999999999947, score: -14.0\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03045754 0.03045754 0.03045754 0.03045754 0.03045754]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 601\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0333357 0.0333357 0.0333357 0.0333357 0.0333357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "Training step 602\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03179718 0.03179718 0.03179718 0.03179718 0.03179718]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03307122 0.03307122 0.03307122 0.03307122 0.03307122]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "Training step 603\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03307122 0.03307122 0.03307122 0.03307122 0.03307122]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "Training step 604\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "Training step 605\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "Training step 606\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "Training step 607\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03152388 0.03152388 0.03152388 0.03152388 0.03152388]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "Training step 608\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03097849 0.03097849 0.03097849 0.03097849 0.03097849]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 609\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "Training step 610\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03070411 0.03070411 0.03070411 0.03070411 0.03070411]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.02892532 0.02892532 0.02892532 0.02892532 0.02892532]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03273707 0.03273707 0.03273707 0.03273707 0.03273707]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "Training step 611\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "Training step 612\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "Training step 613\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03151607 0.03151607 0.03151607 0.03151607 0.03151607]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "Training step 614\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 615\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03299445 0.03299445 0.03299445 0.03299445 0.03299445]\n",
      "Training step 616\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "Training step 617\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "Training step 618\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03330616 0.03330616 0.03330616 0.03330616 0.03330616]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03079526 0.03079526 0.03079526 0.03079526 0.03079526]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03765684 0.03765684 0.03765684 0.03765684 0.03765684]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "Training step 619\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03144702 0.03144702 0.03144702 0.03144702 0.03144702]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03079526 0.03079526 0.03079526 0.03079526 0.03079526]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "Training step 620\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "Training step 621\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "Training step 622\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.033239 0.033239 0.033239 0.033239 0.033239]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "Training step 623\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "Training step 624\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03070828 0.03070828 0.03070828 0.03070828 0.03070828]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "Training step 625\n",
      "target: [0.03152388 0.03152388 0.03152388 0.03152388 0.03152388]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736843 0.03736843 0.03736843 0.03736843 0.03736843]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.0321596 0.0321596 0.0321596 0.0321596 0.0321596]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.0314861 0.0314861 0.0314861 0.0314861 0.0314861]\n",
      "Training step 626\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03179718 0.03179718 0.03179718 0.03179718 0.03179718]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [-0.96752317  0.03247683  0.03247683  0.03247683  0.03247683]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "Training step 627\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "Training step 628\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03431668 0.03431668 0.03431668 0.03431668 0.03431668]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "Training step 629\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03308255 0.03308255 0.03308255 0.03308255 0.03308255]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [-0.96886362  0.03113638  0.03113638  0.03113638  0.03113638]\n",
      "Training step 630\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03537888 0.03537888 0.03537888 0.03537888 0.03537888]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03521717 0.03521717 0.03521717 0.03521717 0.03521717]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "Training step 631\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "Training step 632\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03152388 0.03152388 0.03152388 0.03152388 0.03152388]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "Training step 633\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "Training step 634\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106095 0.03106095 0.03106095 0.03106095 0.03106095]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "Training step 635\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "Training step 636\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03012429 0.03012429 0.03012429 0.03012429 0.03012429]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03079327 0.03079327 0.03079327 0.03079327 0.03079327]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "Training step 637\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.02936958 0.02936958 0.02936958 0.02936958 0.02936958]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03304792 0.03304792 0.03304792 0.03304792 0.03304792]\n",
      "Training step 638\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "Training step 639\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [-0.96886362  0.03113638  0.03113638  0.03113638  0.03113638]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03312881 0.03312881 0.03312881 0.03312881 0.03312881]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "Training step 640\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03736843 0.03736843 0.03736843 0.03736843 0.03736843]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "Training step 641\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0.03699481 0.03699481 0.03699481 0.03699481 0.03699481]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 642\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03736843 0.03736843 0.03736843 0.03736843 0.03736843]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03765684 0.03765684 0.03765684 0.03765684 0.03765684]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "Training step 643\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "Training step 644\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03300447 0.03300447 0.03300447 0.03300447 0.03300447]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "Training step 645\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03243385 0.03243385 0.03243385 0.03243385 0.03243385]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03059724 0.03059724 0.03059724 0.03059724 0.03059724]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 646\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.0314861 0.0314861 0.0314861 0.0314861 0.0314861]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03015356 0.03015356 0.03015356 0.03015356 0.03015356]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "Training step 647\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03024809 0.03024809 0.03024809 0.03024809 0.03024809]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "Training step 648\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03167742 0.03167742 0.03167742 0.03167742 0.03167742]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "Training step 649\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03094893 0.03094893 0.03094893 0.03094893 0.03094893]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "Training step 650\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [-0.97027314  0.02972686  0.02972686  0.02972686  0.02972686]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "Training step 651\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03335228 0.03335228 0.03335228 0.03335228 0.03335228]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "Training step 652\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "Training step 653\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03375299 0.03375299 0.03375299 0.03375299 0.03375299]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 654\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 655\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03168476 0.03168476 0.03168476 0.03168476 0.03168476]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03018009 0.03018009 0.03018009 0.03018009 0.03018009]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "Training step 656\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 657\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "Training step 658\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.02997842 0.02997842 0.02997842 0.02997842 0.02997842]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.03205386 0.03205386 0.03205386 0.03205386 0.03205386]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "Training step 659\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "Training step 660\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.0329355 0.0329355 0.0329355 0.0329355 0.0329355]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "Training step 661\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96786104  0.03213896  0.03213896  0.03213896  0.03213896]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03146207 0.03146207 0.03146207 0.03146207 0.03146207]\n",
      "target: [-0.96886362  0.03113638  0.03113638  0.03113638  0.03113638]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "Training step 662\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.02877691 0.02877691 0.02877691 0.02877691 0.02877691]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03090948 0.03090948 0.03090948 0.03090948 0.03090948]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "Training step 663\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03566864 0.03566864 0.03566864 0.03566864 0.03566864]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03243385 0.03243385 0.03243385 0.03243385 0.03243385]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "Training step 664\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251052 0.03251052 0.03251052 0.03251052 0.03251052]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "Training step 665\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03228921 0.03228921 0.03228921 0.03228921 0.03228921]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.03765684 0.03765684 0.03765684 0.03765684 0.03765684]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.03103706 0.03103706 0.03103706 0.03103706 0.03103706]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "Training step 666\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03007041 0.03007041 0.03007041 0.03007041 0.03007041]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "Training step 667\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03065546 0.03065546 0.03065546 0.03065546 0.03065546]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03274968 0.03274968 0.03274968 0.03274968 0.03274968]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "Training step 668\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03143241 0.03143241 0.03143241 0.03143241 0.03143241]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03179718 0.03179718 0.03179718 0.03179718 0.03179718]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214541 0.03214541 0.03214541 0.03214541 0.03214541]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03395632 0.03395632 0.03395632 0.03395632 0.03395632]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "Training step 669\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "Training step 670\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03146207 0.03146207 0.03146207 0.03146207 0.03146207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [-0.9695688  0.0304312  0.0304312  0.0304312  0.0304312]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "Training step 671\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03134718 0.03134718 0.03134718 0.03134718 0.03134718]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03320789 0.03320789 0.03320789 0.03320789 0.03320789]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 672\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [-0.96898568  0.03101432  0.03101432  0.03101432  0.03101432]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "Training step 673\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03063383 0.03063383 0.03063383 0.03063383 0.03063383]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "Training step 674\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "Training step 675\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03109434 0.03109434 0.03109434 0.03109434 0.03109434]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "Training step 676\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03495299 0.03495299 0.03495299 0.03495299 0.03495299]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03179718 0.03179718 0.03179718 0.03179718 0.03179718]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 677\n",
      "target: [0.03185741 0.03185741 0.03185741 0.03185741 0.03185741]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03215774 0.03215774 0.03215774 0.03215774 0.03215774]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03258456 0.03258456 0.03258456 0.03258456 0.03258456]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03320721 0.03320721 0.03320721 0.03320721 0.03320721]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "Training step 678\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03187867 0.03187867 0.03187867 0.03187867 0.03187867]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03038352 0.03038352 0.03038352 0.03038352 0.03038352]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "Training step 679\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03016086 0.03016086 0.03016086 0.03016086 0.03016086]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03239138 0.03239138 0.03239138 0.03239138 0.03239138]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "Training step 680\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03120582 0.03120582 0.03120582 0.03120582 0.03120582]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03385859 0.03385859 0.03385859 0.03385859 0.03385859]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03199593 0.03199593 0.03199593 0.03199593 0.03199593]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03428265 0.03428265 0.03428265 0.03428265 0.03428265]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "Training step 681\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03229502 0.03229502 0.03229502 0.03229502 0.03229502]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03155768 0.03155768 0.03155768 0.03155768 0.03155768]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "Training step 682\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128207 0.03128207 0.03128207 0.03128207 0.03128207]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "Training step 683\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "Training step 684\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "Training step 685\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03335228 0.03335228 0.03335228 0.03335228 0.03335228]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03765684 0.03765684 0.03765684 0.03765684 0.03765684]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "Training step 686\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.03215367 0.03215367 0.03215367 0.03215367 0.03215367]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03152388 0.03152388 0.03152388 0.03152388 0.03152388]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "Training step 687\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03328352 0.03328352 0.03328352 0.03328352 0.03328352]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03387518 0.03387518 0.03387518 0.03387518 0.03387518]\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "Training step 688\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "Training step 689\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300688 0.03300688 0.03300688 0.03300688 0.03300688]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03018009 0.03018009 0.03018009 0.03018009 0.03018009]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 690\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03772558 0.03772558 0.03772558 0.03772558 0.03772558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03217443 0.03217443 0.03217443 0.03217443 0.03217443]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324589 0.03324589 0.03324589 0.03324589 0.03324589]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 691\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03097849 0.03097849 0.03097849 0.03097849 0.03097849]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "Training step 692\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.0319448 0.0319448 0.0319448 0.0319448 0.0319448]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187867 0.03187867 0.03187867 0.03187867 0.03187867]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.03276503 0.03276503 0.03276503 0.03276503 0.03276503]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.037026 0.037026 0.037026 0.037026 0.037026]\n",
      "Training step 693\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03079526 0.03079526 0.03079526 0.03079526 0.03079526]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03019285 0.03019285 0.03019285 0.03019285 0.03019285]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "Training step 694\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.0363405 0.0363405 0.0363405 0.0363405 0.0363405]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.0340727 0.0340727 0.0340727 0.0340727 0.0340727]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "Training step 695\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03430597 0.03430597 0.03430597 0.03430597 0.03430597]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03333755 0.03333755 0.03333755 0.03333755 0.03333755]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 696\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03641253 0.03641253 0.03641253 0.03641253 0.03641253]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03345165 0.03345165 0.03345165 0.03345165 0.03345165]\n",
      "target: [0.03265386 0.03265386 0.03265386 0.03265386 0.03265386]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0.03036657 0.03036657 0.03036657 0.03036657 0.03036657]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03295275 0.03295275 0.03295275 0.03295275 0.03295275]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "Training step 697\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03395632 0.03395632 0.03395632 0.03395632 0.03395632]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03308255 0.03308255 0.03308255 0.03308255 0.03308255]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "Training step 698\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "Training step 699\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03467072 0.03467072 0.03467072 0.03467072 0.03467072]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03420137 0.03420137 0.03420137 0.03420137 0.03420137]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03144702 0.03144702 0.03144702 0.03144702 0.03144702]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03333491 0.03333491 0.03333491 0.03333491 0.03333491]\n",
      "target: [0.03223506 0.03223506 0.03223506 0.03223506 0.03223506]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 700\n",
      "Episode 0/ 2, epsilon: 0.2999999999999994, score: -15.0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03467072 0.03467072 0.03467072 0.03467072 0.03467072]\n",
      "target: [0.03385859 0.03385859 0.03385859 0.03385859 0.03385859]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03116305 0.03116305 0.03116305 0.03116305 0.03116305]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.02995708 0.02995708 0.02995708 0.02995708 0.02995708]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0.03138249 0.03138249 0.03138249 0.03138249 0.03138249]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "Training step 701\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03070411 0.03070411 0.03070411 0.03070411 0.03070411]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03088141 0.03088141 0.03088141 0.03088141 0.03088141]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03333755 0.03333755 0.03333755 0.03333755 0.03333755]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "Training step 702\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03046574 0.03046574 0.03046574 0.03046574 0.03046574]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03160848 0.03160848 0.03160848 0.03160848 0.03160848]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03030523 0.03030523 0.03030523 0.03030523 0.03030523]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03271632 0.03271632 0.03271632 0.03271632 0.03271632]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "Training step 703\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02988539 0.02988539 0.02988539 0.02988539 0.02988539]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03673504 0.03673504 0.03673504 0.03673504 0.03673504]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03243385 0.03243385 0.03243385 0.03243385 0.03243385]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03148404 0.03148404 0.03148404 0.03148404 0.03148404]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "Training step 704\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "Training step 705\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0.03685872 0.03685872 0.03685872 0.03685872 0.03685872]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.0385243 0.0385243 0.0385243 0.0385243 0.0385243]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "Training step 706\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03251052 0.03251052 0.03251052 0.03251052 0.03251052]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03699481 0.03699481 0.03699481 0.03699481 0.03699481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "Training step 707\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03251052 0.03251052 0.03251052 0.03251052 0.03251052]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03088141 0.03088141 0.03088141 0.03088141 0.03088141]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "Training step 708\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03566864 0.03566864 0.03566864 0.03566864 0.03566864]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03228778 0.03228778 0.03228778 0.03228778 0.03228778]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0.03179718 0.03179718 0.03179718 0.03179718 0.03179718]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "Training step 709\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.02900957 0.02900957 0.02900957 0.02900957 0.02900957]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03106263 0.03106263 0.03106263 0.03106263 0.03106263]\n",
      "target: [0.03143939 0.03143939 0.03143939 0.03143939 0.03143939]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "Training step 710\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03297813 0.03297813 0.03297813 0.03297813 0.03297813]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03211948 0.03211948 0.03211948 0.03211948 0.03211948]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03335228 0.03335228 0.03335228 0.03335228 0.03335228]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03215367 0.03215367 0.03215367 0.03215367 0.03215367]\n",
      "target: [0.03307122 0.03307122 0.03307122 0.03307122 0.03307122]\n",
      "Training step 711\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [-0.96934923  0.03065077  0.03065077  0.03065077  0.03065077]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03420137 0.03420137 0.03420137 0.03420137 0.03420137]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "Training step 712\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03070411 0.03070411 0.03070411 0.03070411 0.03070411]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03144702 0.03144702 0.03144702 0.03144702 0.03144702]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03097849 0.03097849 0.03097849 0.03097849 0.03097849]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "Training step 713\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03251294 0.03251294 0.03251294 0.03251294 0.03251294]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "Training step 714\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03215367 0.03215367 0.03215367 0.03215367 0.03215367]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "Training step 715\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.02872288 0.02872288 0.02872288 0.02872288 0.02872288]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "Training step 716\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03146207 0.03146207 0.03146207 0.03146207 0.03146207]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03109211 0.03109211 0.03109211 0.03109211 0.03109211]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [-0.96886362  0.03113638  0.03113638  0.03113638  0.03113638]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "Training step 717\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03225597 0.03225597 0.03225597 0.03225597 0.03225597]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03209883 0.03209883 0.03209883 0.03209883 0.03209883]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "Training step 718\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03328352 0.03328352 0.03328352 0.03328352 0.03328352]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.02778478 0.02778478 0.02778478 0.02778478 0.02778478]\n",
      "Training step 719\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03324589 0.03324589 0.03324589 0.03324589 0.03324589]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "Training step 720\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0.03290694 0.03290694 0.03290694 0.03290694 0.03290694]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03641253 0.03641253 0.03641253 0.03641253 0.03641253]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 721\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03149409 0.03149409 0.03149409 0.03149409 0.03149409]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03144702 0.03144702 0.03144702 0.03144702 0.03144702]\n",
      "Training step 722\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.02872288 0.02872288 0.02872288 0.02872288 0.02872288]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03711858 0.03711858 0.03711858 0.03711858 0.03711858]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03399844 0.03399844 0.03399844 0.03399844 0.03399844]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03094435 0.03094435 0.03094435 0.03094435 0.03094435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "Training step 723\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.02941018 0.02941018 0.02941018 0.02941018 0.02941018]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.0329355 0.0329355 0.0329355 0.0329355 0.0329355]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03243385 0.03243385 0.03243385 0.03243385 0.03243385]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "Training step 724\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.03237301 0.03237301 0.03237301 0.03237301 0.03237301]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.0319577 0.0319577 0.0319577 0.0319577 0.0319577]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03231627 0.03231627 0.03231627 0.03231627 0.03231627]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "Training step 725\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.02995708 0.02995708 0.02995708 0.02995708 0.02995708]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03056591 0.03056591 0.03056591 0.03056591 0.03056591]\n",
      "target: [0.03179718 0.03179718 0.03179718 0.03179718 0.03179718]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.0334249 0.0334249 0.0334249 0.0334249 0.0334249]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "Training step 726\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03121343 0.03121343 0.03121343 0.03121343 0.03121343]\n",
      "target: [0.02917159 0.02917159 0.02917159 0.02917159 0.02917159]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03685872 0.03685872 0.03685872 0.03685872 0.03685872]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.03228778 0.03228778 0.03228778 0.03228778 0.03228778]\n",
      "target: [0.03387754 0.03387754 0.03387754 0.03387754 0.03387754]\n",
      "Training step 727\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03267441 0.03267441 0.03267441 0.03267441 0.03267441]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03427537 0.03427537 0.03427537 0.03427537 0.03427537]\n",
      "target: [-0.96898568  0.03101432  0.03101432  0.03101432  0.03101432]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "Training step 728\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03060498 0.03060498 0.03060498 0.03060498 0.03060498]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "Training step 729\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.03392778 0.03392778 0.03392778 0.03392778 0.03392778]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03049576 0.03049576 0.03049576 0.03049576 0.03049576]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03139 0.03139 0.03139 0.03139 0.03139]\n",
      "target: [0.03059071 0.03059071 0.03059071 0.03059071 0.03059071]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "Training step 730\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.03175391 0.03175391 0.03175391 0.03175391 0.03175391]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03361207 0.03361207 0.03361207 0.03361207 0.03361207]\n",
      "target: [0.03387754 0.03387754 0.03387754 0.03387754 0.03387754]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "Training step 731\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03402946 0.03402946 0.03402946 0.03402946 0.03402946]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03290779 0.03290779 0.03290779 0.03290779 0.03290779]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03127985 0.03127985 0.03127985 0.03127985 0.03127985]\n",
      "Training step 732\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.03110048 0.03110048 0.03110048 0.03110048 0.03110048]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.02988539 0.02988539 0.02988539 0.02988539 0.02988539]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03116305 0.03116305 0.03116305 0.03116305 0.03116305]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "Training step 733\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03177023 0.03177023 0.03177023 0.03177023 0.03177023]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03109434 0.03109434 0.03109434 0.03109434 0.03109434]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03047433 0.03047433 0.03047433 0.03047433 0.03047433]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03243385 0.03243385 0.03243385 0.03243385 0.03243385]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 734\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.0315438 0.0315438 0.0315438 0.0315438 0.0315438]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.02778478 0.02778478 0.02778478 0.02778478 0.02778478]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03265386 0.03265386 0.03265386 0.03265386 0.03265386]\n",
      "target: [0.03309958 0.03309958 0.03309958 0.03309958 0.03309958]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03227958 0.03227958 0.03227958 0.03227958 0.03227958]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "Training step 735\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03308255 0.03308255 0.03308255 0.03308255 0.03308255]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0.03346591 0.03346591 0.03346591 0.03346591 0.03346591]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02778478 0.02778478 0.02778478 0.02778478 0.02778478]\n",
      "target: [0.03221905 0.03221905 0.03221905 0.03221905 0.03221905]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03265386 0.03265386 0.03265386 0.03265386 0.03265386]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "Training step 736\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03488547 0.03488547 0.03488547 0.03488547 0.03488547]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03648455 0.03648455 0.03648455 0.03648455 0.03648455]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03433214 0.03433214 0.03433214 0.03433214 0.03433214]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "Training step 737\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [-0.96854452  0.03145548  0.03145548  0.03145548  0.03145548]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03284999 0.03284999 0.03284999 0.03284999 0.03284999]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.03046574 0.03046574 0.03046574 0.03046574 0.03046574]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03032715 0.03032715 0.03032715 0.03032715 0.03032715]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "Training step 738\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03228778 0.03228778 0.03228778 0.03228778 0.03228778]\n",
      "target: [0.03052849 0.03052849 0.03052849 0.03052849 0.03052849]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03017149 0.03017149 0.03017149 0.03017149 0.03017149]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324589 0.03324589 0.03324589 0.03324589 0.03324589]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "Training step 739\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.02913323 0.02913323 0.02913323 0.02913323 0.02913323]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03015444 0.03015444 0.03015444 0.03015444 0.03015444]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "Training step 740\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03509094 0.03509094 0.03509094 0.03509094 0.03509094]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03136881 0.03136881 0.03136881 0.03136881 0.03136881]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "Training step 741\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03641253 0.03641253 0.03641253 0.03641253 0.03641253]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03046574 0.03046574 0.03046574 0.03046574 0.03046574]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03532823 0.03532823 0.03532823 0.03532823 0.03532823]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "Training step 742\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03231458 0.03231458 0.03231458 0.03231458 0.03231458]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.04126637 0.04126637 0.04126637 0.04126637 0.04126637]\n",
      "Training step 743\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03039982 0.03039982 0.03039982 0.03039982 0.03039982]\n",
      "target: [0.03026052 0.03026052 0.03026052 0.03026052 0.03026052]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03231627 0.03231627 0.03231627 0.03231627 0.03231627]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03287543 0.03287543 0.03287543 0.03287543 0.03287543]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03371214 0.03371214 0.03371214 0.03371214 0.03371214]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "Training step 744\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.0359062 0.0359062 0.0359062 0.0359062 0.0359062]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "Training step 745\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03130912 0.03130912 0.03130912 0.03130912 0.03130912]\n",
      "target: [0.0295541 0.0295541 0.0295541 0.0295541 0.0295541]\n",
      "Training step 746\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [-0.96493174  0.03506826  0.03506826  0.03506826  0.03506826]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03130912 0.03130912 0.03130912 0.03130912 0.03130912]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03102983 0.03102983 0.03102983 0.03102983 0.03102983]\n",
      "target: [0.03006561 0.03006561 0.03006561 0.03006561 0.03006561]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03427564 0.03427564 0.03427564 0.03427564 0.03427564]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03074452 0.03074452 0.03074452 0.03074452 0.03074452]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "Training step 747\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.03093102 0.03093102 0.03093102 0.03093102 0.03093102]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03308347 0.03308347 0.03308347 0.03308347 0.03308347]\n",
      "target: [0.03699481 0.03699481 0.03699481 0.03699481 0.03699481]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03818216 0.03818216 0.03818216 0.03818216 0.03818216]\n",
      "target: [0.03225597 0.03225597 0.03225597 0.03225597 0.03225597]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03099602 0.03099602 0.03099602 0.03099602 0.03099602]\n",
      "Training step 748\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03713183 0.03713183 0.03713183 0.03713183 0.03713183]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03137509 0.03137509 0.03137509 0.03137509 0.03137509]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03455015 0.03455015 0.03455015 0.03455015 0.03455015]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03362555 0.03362555 0.03362555 0.03362555 0.03362555]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "Training step 749\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337905 0.03337905 0.03337905 0.03337905 0.03337905]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03327454 0.03327454 0.03327454 0.03327454 0.03327454]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03253134 0.03253134 0.03253134 0.03253134 0.03253134]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [-0.96493174  0.03506826  0.03506826  0.03506826  0.03506826]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03251052 0.03251052 0.03251052 0.03251052 0.03251052]\n",
      "Training step 750\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03578041 0.03578041 0.03578041 0.03578041 0.03578041]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138249 0.03138249 0.03138249 0.03138249 0.03138249]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.02872288 0.02872288 0.02872288 0.02872288 0.02872288]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "target: [0.03308347 0.03308347 0.03308347 0.03308347 0.03308347]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03055145 0.03055145 0.03055145 0.03055145 0.03055145]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03387205 0.03387205 0.03387205 0.03387205 0.03387205]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.0351847 0.0351847 0.0351847 0.0351847 0.0351847]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [-0.96682384  0.03317616  0.03317616  0.03317616  0.03317616]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "Training step 751\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03469793 0.03469793 0.03469793 0.03469793 0.03469793]\n",
      "target: [0.02964172 0.02964172 0.02964172 0.02964172 0.02964172]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03566733 0.03566733 0.03566733 0.03566733 0.03566733]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03065619 0.03065619 0.03065619 0.03065619 0.03065619]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147889 0.03147889 0.03147889 0.03147889 0.03147889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "Training step 752\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.03152634 0.03152634 0.03152634 0.03152634 0.03152634]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03207192 0.03207192 0.03207192 0.03207192 0.03207192]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "Training step 753\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03509094 0.03509094 0.03509094 0.03509094 0.03509094]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.0317872 0.0317872 0.0317872 0.0317872 0.0317872]\n",
      "Training step 754\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03315859 0.03315859 0.03315859 0.03315859 0.03315859]\n",
      "target: [0.03345101 0.03345101 0.03345101 0.03345101 0.03345101]\n",
      "target: [-0.96898568  0.03101432  0.03101432  0.03101432  0.03101432]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.02778478 0.02778478 0.02778478 0.02778478 0.02778478]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03149409 0.03149409 0.03149409 0.03149409 0.03149409]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "Training step 755\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.0312973 0.0312973 0.0312973 0.0312973 0.0312973]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03509094 0.03509094 0.03509094 0.03509094 0.03509094]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [0.0363405 0.0363405 0.0363405 0.0363405 0.0363405]\n",
      "target: [0.02872288 0.02872288 0.02872288 0.02872288 0.02872288]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "Training step 756\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03523396 0.03523396 0.03523396 0.03523396 0.03523396]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.03647588 0.03647588 0.03647588 0.03647588 0.03647588]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03378254 0.03378254 0.03378254 0.03378254 0.03378254]\n",
      "target: [0.03705374 0.03705374 0.03705374 0.03705374 0.03705374]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03181905 0.03181905 0.03181905 0.03181905 0.03181905]\n",
      "target: [0.03274785 0.03274785 0.03274785 0.03274785 0.03274785]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "Training step 757\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03299445 0.03299445 0.03299445 0.03299445 0.03299445]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03748832 0.03748832 0.03748832 0.03748832 0.03748832]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03137081 0.03137081 0.03137081 0.03137081 0.03137081]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03026264 0.03026264 0.03026264 0.03026264 0.03026264]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03078815 0.03078815 0.03078815 0.03078815 0.03078815]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "Training step 758\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03296537 0.03296537 0.03296537 0.03296537 0.03296537]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03093102 0.03093102 0.03093102 0.03093102 0.03093102]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03324372 0.03324372 0.03324372 0.03324372 0.03324372]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03223506 0.03223506 0.03223506 0.03223506 0.03223506]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "Training step 759\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03449791 0.03449791 0.03449791 0.03449791 0.03449791]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03242345 0.03242345 0.03242345 0.03242345 0.03242345]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03642006 0.03642006 0.03642006 0.03642006 0.03642006]\n",
      "target: [0.03152388 0.03152388 0.03152388 0.03152388 0.03152388]\n",
      "target: [0.03295102 0.03295102 0.03295102 0.03295102 0.03295102]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03283328 0.03283328 0.03283328 0.03283328 0.03283328]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.0363405 0.0363405 0.0363405 0.0363405 0.0363405]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "Training step 760\n",
      "target: [0.03271632 0.03271632 0.03271632 0.03271632 0.03271632]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03308255 0.03308255 0.03308255 0.03308255 0.03308255]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03360985 0.03360985 0.03360985 0.03360985 0.03360985]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "Training step 761\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03282386 0.03282386 0.03282386 0.03282386 0.03282386]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03260836 0.03260836 0.03260836 0.03260836 0.03260836]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.03179974 0.03179974 0.03179974 0.03179974 0.03179974]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0.03829637 0.03829637 0.03829637 0.03829637 0.03829637]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "Training step 762\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03495299 0.03495299 0.03495299 0.03495299 0.03495299]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03772802 0.03772802 0.03772802 0.03772802 0.03772802]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03280419 0.03280419 0.03280419 0.03280419 0.03280419]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03012015 0.03012015 0.03012015 0.03012015 0.03012015]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.03342888 0.03342888 0.03342888 0.03342888 0.03342888]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183835 0.03183835 0.03183835 0.03183835 0.03183835]\n",
      "Training step 763\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03652291 0.03652291 0.03652291 0.03652291 0.03652291]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03238167 0.03238167 0.03238167 0.03238167 0.03238167]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03217164 0.03217164 0.03217164 0.03217164 0.03217164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03495299 0.03495299 0.03495299 0.03495299 0.03495299]\n",
      "target: [0.03231458 0.03231458 0.03231458 0.03231458 0.03231458]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03292766 0.03292766 0.03292766 0.03292766 0.03292766]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.0329721 0.0329721 0.0329721 0.0329721 0.0329721]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03106286 0.03106286 0.03106286 0.03106286 0.03106286]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "Training step 764\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03060409 0.03060409 0.03060409 0.03060409 0.03060409]\n",
      "target: [0.03432517 0.03432517 0.03432517 0.03432517 0.03432517]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03215837 0.03215837 0.03215837 0.03215837 0.03215837]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03251052 0.03251052 0.03251052 0.03251052 0.03251052]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 765\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.02961506 0.02961506 0.02961506 0.02961506 0.02961506]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03165918 0.03165918 0.03165918 0.03165918 0.03165918]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03255912 0.03255912 0.03255912 0.03255912 0.03255912]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321301 0.03321301 0.03321301 0.03321301 0.03321301]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [-0.96493174  0.03506826  0.03506826  0.03506826  0.03506826]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "Training step 766\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03641253 0.03641253 0.03641253 0.03641253 0.03641253]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03029426 0.03029426 0.03029426 0.03029426 0.03029426]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [0.03193145 0.03193145 0.03193145 0.03193145 0.03193145]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03588621 0.03588621 0.03588621 0.03588621 0.03588621]\n",
      "target: [0.03216389 0.03216389 0.03216389 0.03216389 0.03216389]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "Training step 767\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.03736843 0.03736843 0.03736843 0.03736843 0.03736843]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03394222 0.03394222 0.03394222 0.03394222 0.03394222]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "Training step 768\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02996162 0.02996162 0.02996162 0.02996162 0.02996162]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03131021 0.03131021 0.03131021 0.03131021 0.03131021]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03124013 0.03124013 0.03124013 0.03124013 0.03124013]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "Training step 769\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03095674 0.03095674 0.03095674 0.03095674 0.03095674]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03259067 0.03259067 0.03259067 0.03259067 0.03259067]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.0306591 0.0306591 0.0306591 0.0306591 0.0306591]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03681271 0.03681271 0.03681271 0.03681271 0.03681271]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.0343981 0.0343981 0.0343981 0.0343981 0.0343981]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "Training step 770\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03308703 0.03308703 0.03308703 0.03308703 0.03308703]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.0363405 0.0363405 0.0363405 0.0363405 0.0363405]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03308255 0.03308255 0.03308255 0.03308255 0.03308255]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [-0.96898568  0.03101432  0.03101432  0.03101432  0.03101432]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.03155041 0.03155041 0.03155041 0.03155041 0.03155041]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "Training step 771\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.0379849 0.0379849 0.0379849 0.0379849 0.0379849]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03382752 0.03382752 0.03382752 0.03382752 0.03382752]\n",
      "target: [0.03412732 0.03412732 0.03412732 0.03412732 0.03412732]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03261476 0.03261476 0.03261476 0.03261476 0.03261476]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03136488 0.03136488 0.03136488 0.03136488 0.03136488]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.03274476 0.03274476 0.03274476 0.03274476 0.03274476]\n",
      "Training step 772\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03239271 0.03239271 0.03239271 0.03239271 0.03239271]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03292166 0.03292166 0.03292166 0.03292166 0.03292166]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03063383 0.03063383 0.03063383 0.03063383 0.03063383]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03387754 0.03387754 0.03387754 0.03387754 0.03387754]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.03433171 0.03433171 0.03433171 0.03433171 0.03433171]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "Training step 773\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03063383 0.03063383 0.03063383 0.03063383 0.03063383]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03269459 0.03269459 0.03269459 0.03269459 0.03269459]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03913996 0.03913996 0.03913996 0.03913996 0.03913996]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03018009 0.03018009 0.03018009 0.03018009 0.03018009]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0.02963722 0.02963722 0.02963722 0.02963722 0.02963722]\n",
      "target: [0.03060725 0.03060725 0.03060725 0.03060725 0.03060725]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "Training step 774\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03350601 0.03350601 0.03350601 0.03350601 0.03350601]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.0336126 0.0336126 0.0336126 0.0336126 0.0336126]\n",
      "target: [0.03305446 0.03305446 0.03305446 0.03305446 0.03305446]\n",
      "target: [0.03266681 0.03266681 0.03266681 0.03266681 0.03266681]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03070411 0.03070411 0.03070411 0.03070411 0.03070411]\n",
      "target: [0.03162115 0.03162115 0.03162115 0.03162115 0.03162115]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.03070411 0.03070411 0.03070411 0.03070411 0.03070411]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "Training step 775\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03215367 0.03215367 0.03215367 0.03215367 0.03215367]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [-0.96810943  0.03189057  0.03189057  0.03189057  0.03189057]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03187127 0.03187127 0.03187127 0.03187127 0.03187127]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "Training step 776\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03184177 0.03184177 0.03184177 0.03184177 0.03184177]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.02995068 0.02995068 0.02995068 0.02995068 0.02995068]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.03177023 0.03177023 0.03177023 0.03177023 0.03177023]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03130912 0.03130912 0.03130912 0.03130912 0.03130912]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03070712 0.03070712 0.03070712 0.03070712 0.03070712]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "Training step 777\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03078815 0.03078815 0.03078815 0.03078815 0.03078815]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03314034 0.03314034 0.03314034 0.03314034 0.03314034]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0.03648909 0.03648909 0.03648909 0.03648909 0.03648909]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "Training step 778\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [-0.96721253  0.03278747  0.03278747  0.03278747  0.03278747]\n",
      "target: [0.03518197 0.03518197 0.03518197 0.03518197 0.03518197]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.02857837 0.02857837 0.02857837 0.02857837 0.02857837]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03184584 0.03184584 0.03184584 0.03184584 0.03184584]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03378254 0.03378254 0.03378254 0.03378254 0.03378254]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "Training step 779\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.02986283 0.02986283 0.02986283 0.02986283 0.02986283]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03290025 0.03290025 0.03290025 0.03290025 0.03290025]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03402946 0.03402946 0.03402946 0.03402946 0.03402946]\n",
      "target: [0.03132715 0.03132715 0.03132715 0.03132715 0.03132715]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03711202 0.03711202 0.03711202 0.03711202 0.03711202]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.03106063 0.03106063 0.03106063 0.03106063 0.03106063]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.02872288 0.02872288 0.02872288 0.02872288 0.02872288]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "Training step 780\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.03018009 0.03018009 0.03018009 0.03018009 0.03018009]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03251052 0.03251052 0.03251052 0.03251052 0.03251052]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03113684 0.03113684 0.03113684 0.03113684 0.03113684]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03307122 0.03307122 0.03307122 0.03307122 0.03307122]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03182801 0.03182801 0.03182801 0.03182801 0.03182801]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03085058 0.03085058 0.03085058 0.03085058 0.03085058]\n",
      "target: [0.02995708 0.02995708 0.02995708 0.02995708 0.02995708]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03324372 0.03324372 0.03324372 0.03324372 0.03324372]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.0317899 0.0317899 0.0317899 0.0317899 0.0317899]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "Training step 781\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03825441 0.03825441 0.03825441 0.03825441 0.03825441]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03063905 0.03063905 0.03063905 0.03063905 0.03063905]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03290424 0.03290424 0.03290424 0.03290424 0.03290424]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.03216315 0.03216315 0.03216315 0.03216315 0.03216315]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "Training step 782\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03087624 0.03087624 0.03087624 0.03087624 0.03087624]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03049851 0.03049851 0.03049851 0.03049851 0.03049851]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0.03415782 0.03415782 0.03415782 0.03415782 0.03415782]\n",
      "target: [0.03229849 0.03229849 0.03229849 0.03229849 0.03229849]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03345009 0.03345009 0.03345009 0.03345009 0.03345009]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "Training step 783\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03467072 0.03467072 0.03467072 0.03467072 0.03467072]\n",
      "target: [0.03249104 0.03249104 0.03249104 0.03249104 0.03249104]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0.03529156 0.03529156 0.03529156 0.03529156 0.03529156]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0.03231627 0.03231627 0.03231627 0.03231627 0.03231627]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03158554 0.03158554 0.03158554 0.03158554 0.03158554]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 784\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03417147 0.03417147 0.03417147 0.03417147 0.03417147]\n",
      "target: [0.03112192 0.03112192 0.03112192 0.03112192 0.03112192]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03241618 0.03241618 0.03241618 0.03241618 0.03241618]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.0309823 0.0309823 0.0309823 0.0309823 0.0309823]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03428255 0.03428255 0.03428255 0.03428255 0.03428255]\n",
      "target: [-0.96906484  0.03093516  0.03093516  0.03093516  0.03093516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03156399 0.03156399 0.03156399 0.03156399 0.03156399]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03088598 0.03088598 0.03088598 0.03088598 0.03088598]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "Training step 785\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03698695 0.03698695 0.03698695 0.03698695 0.03698695]\n",
      "target: [0.02981604 0.02981604 0.02981604 0.02981604 0.02981604]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03185741 0.03185741 0.03185741 0.03185741 0.03185741]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03879698 0.03879698 0.03879698 0.03879698 0.03879698]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.0357175 0.0357175 0.0357175 0.0357175 0.0357175]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "Training step 786\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03271632 0.03271632 0.03271632 0.03271632 0.03271632]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [-0.96886362  0.03113638  0.03113638  0.03113638  0.03113638]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03003907 0.03003907 0.03003907 0.03003907 0.03003907]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "Training step 787\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03199593 0.03199593 0.03199593 0.03199593 0.03199593]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03187372 0.03187372 0.03187372 0.03187372 0.03187372]\n",
      "target: [0.03056394 0.03056394 0.03056394 0.03056394 0.03056394]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.04252667 0.04252667 0.04252667 0.04252667 0.04252667]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093102 0.03093102 0.03093102 0.03093102 0.03093102]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "Training step 788\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03357795 0.03357795 0.03357795 0.03357795 0.03357795]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03130912 0.03130912 0.03130912 0.03130912 0.03130912]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309034 0.0309034 0.0309034 0.0309034 0.0309034]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.03123375 0.03123375 0.03123375 0.03123375 0.03123375]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "Training step 789\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03003907 0.03003907 0.03003907 0.03003907 0.03003907]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03172487 0.03172487 0.03172487 0.03172487 0.03172487]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03433171 0.03433171 0.03433171 0.03433171 0.03433171]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03223506 0.03223506 0.03223506 0.03223506 0.03223506]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03080648 0.03080648 0.03080648 0.03080648 0.03080648]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03165918 0.03165918 0.03165918 0.03165918 0.03165918]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "Training step 790\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936897 0.02936897 0.02936897 0.02936897 0.02936897]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03133505 0.03133505 0.03133505 0.03133505 0.03133505]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03165918 0.03165918 0.03165918 0.03165918 0.03165918]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "Training step 791\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0.03139 0.03139 0.03139 0.03139 0.03139]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03369891 0.03369891 0.03369891 0.03369891 0.03369891]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03385859 0.03385859 0.03385859 0.03385859 0.03385859]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.02968471 0.02968471 0.02968471 0.02968471 0.02968471]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.02990857 0.02990857 0.02990857 0.02990857 0.02990857]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03530799 0.03530799 0.03530799 0.03530799 0.03530799]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "Training step 792\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03187867 0.03187867 0.03187867 0.03187867 0.03187867]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.03385593 0.03385593 0.03385593 0.03385593 0.03385593]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.03157662 0.03157662 0.03157662 0.03157662 0.03157662]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03568207 0.03568207 0.03568207 0.03568207 0.03568207]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.02963543 0.02963543 0.02963543 0.02963543 0.02963543]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03133505 0.03133505 0.03133505 0.03133505 0.03133505]\n",
      "target: [0.03138249 0.03138249 0.03138249 0.03138249 0.03138249]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 793\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03552419 0.03552419 0.03552419 0.03552419 0.03552419]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0.03147889 0.03147889 0.03147889 0.03147889 0.03147889]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03385859 0.03385859 0.03385859 0.03385859 0.03385859]\n",
      "target: [0.03243504 0.03243504 0.03243504 0.03243504 0.03243504]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0.03387205 0.03387205 0.03387205 0.03387205 0.03387205]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.0326072 0.0326072 0.0326072 0.0326072 0.0326072]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "Training step 794\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.03043371 0.03043371 0.03043371 0.03043371 0.03043371]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.0379849 0.0379849 0.0379849 0.0379849 0.0379849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03652291 0.03652291 0.03652291 0.03652291 0.03652291]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03378254 0.03378254 0.03378254 0.03378254 0.03378254]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.02911701 0.02911701 0.02911701 0.02911701 0.02911701]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "Training step 795\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03420137 0.03420137 0.03420137 0.03420137 0.03420137]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0294877 0.0294877 0.0294877 0.0294877 0.0294877]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03356595 0.03356595 0.03356595 0.03356595 0.03356595]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03479374 0.03479374 0.03479374 0.03479374 0.03479374]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "Training step 796\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03328352 0.03328352 0.03328352 0.03328352 0.03328352]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03063025 0.03063025 0.03063025 0.03063025 0.03063025]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03187867 0.03187867 0.03187867 0.03187867 0.03187867]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03095793 0.03095793 0.03095793 0.03095793 0.03095793]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03227958 0.03227958 0.03227958 0.03227958 0.03227958]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 797\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0.03257836 0.03257836 0.03257836 0.03257836 0.03257836]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.030066 0.030066 0.030066 0.030066 0.030066]\n",
      "target: [0.03052117 0.03052117 0.03052117 0.03052117 0.03052117]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03221734 0.03221734 0.03221734 0.03221734 0.03221734]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "Training step 798\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03325589 0.03325589 0.03325589 0.03325589 0.03325589]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03052901 0.03052901 0.03052901 0.03052901 0.03052901]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03076516 0.03076516 0.03076516 0.03076516 0.03076516]\n",
      "target: [0.03685872 0.03685872 0.03685872 0.03685872 0.03685872]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03063383 0.03063383 0.03063383 0.03063383 0.03063383]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03639408 0.03639408 0.03639408 0.03639408 0.03639408]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03196099 0.03196099 0.03196099 0.03196099 0.03196099]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.03291115 0.03291115 0.03291115 0.03291115 0.03291115]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 799\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03003907 0.03003907 0.03003907 0.03003907 0.03003907]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358539 0.03358539 0.03358539 0.03358539 0.03358539]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0.03295102 0.03295102 0.03295102 0.03295102 0.03295102]\n",
      "target: [0.03082128 0.03082128 0.03082128 0.03082128 0.03082128]\n",
      "target: [0.03088328 0.03088328 0.03088328 0.03088328 0.03088328]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.0379849 0.0379849 0.0379849 0.0379849 0.0379849]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03236032 0.03236032 0.03236032 0.03236032 0.03236032]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.02967565 0.02967565 0.02967565 0.02967565 0.02967565]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "Training step 800\n",
      "Episode 0/ 2, epsilon: 0.1999999999999993, score: -18.0\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.02967565 0.02967565 0.02967565 0.02967565 0.02967565]\n",
      "target: [0.03582125 0.03582125 0.03582125 0.03582125 0.03582125]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.02935135 0.02935135 0.02935135 0.02935135 0.02935135]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03320716 0.03320716 0.03320716 0.03320716 0.03320716]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03132715 0.03132715 0.03132715 0.03132715 0.03132715]\n",
      "target: [0.03107193 0.03107193 0.03107193 0.03107193 0.03107193]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03149409 0.03149409 0.03149409 0.03149409 0.03149409]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03072655 0.03072655 0.03072655 0.03072655 0.03072655]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03236859 0.03236859 0.03236859 0.03236859 0.03236859]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03332883 0.03332883 0.03332883 0.03332883 0.03332883]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 801\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0.03467072 0.03467072 0.03467072 0.03467072 0.03467072]\n",
      "target: [0.03328247 0.03328247 0.03328247 0.03328247 0.03328247]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03566461 0.03566461 0.03566461 0.03566461 0.03566461]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.03277895 0.03277895 0.03277895 0.03277895 0.03277895]\n",
      "target: [0.03165918 0.03165918 0.03165918 0.03165918 0.03165918]\n",
      "target: [0.0397536 0.0397536 0.0397536 0.0397536 0.0397536]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "Training step 802\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.0312559 0.0312559 0.0312559 0.0312559 0.0312559]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03626952 0.03626952 0.03626952 0.03626952 0.03626952]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03299445 0.03299445 0.03299445 0.03299445 0.03299445]\n",
      "target: [0.03164728 0.03164728 0.03164728 0.03164728 0.03164728]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03308347 0.03308347 0.03308347 0.03308347 0.03308347]\n",
      "target: [0.03266402 0.03266402 0.03266402 0.03266402 0.03266402]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03120269 0.03120269 0.03120269 0.03120269 0.03120269]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.02778478 0.02778478 0.02778478 0.02778478 0.02778478]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03693606 0.03693606 0.03693606 0.03693606 0.03693606]\n",
      "target: [-0.96840126  0.03159874  0.03159874  0.03159874  0.03159874]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03126986 0.03126986 0.03126986 0.03126986 0.03126986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 803\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03699262 0.03699262 0.03699262 0.03699262 0.03699262]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03072658 0.03072658 0.03072658 0.03072658 0.03072658]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0.03346994 0.03346994 0.03346994 0.03346994 0.03346994]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0.03385593 0.03385593 0.03385593 0.03385593 0.03385593]\n",
      "target: [0.03108025 0.03108025 0.03108025 0.03108025 0.03108025]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03172623 0.03172623 0.03172623 0.03172623 0.03172623]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03257836 0.03257836 0.03257836 0.03257836 0.03257836]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 804\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03113071 0.03113071 0.03113071 0.03113071 0.03113071]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03495299 0.03495299 0.03495299 0.03495299 0.03495299]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "Training step 805\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02903316 0.02903316 0.02903316 0.02903316 0.02903316]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03333755 0.03333755 0.03333755 0.03333755 0.03333755]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03699481 0.03699481 0.03699481 0.03699481 0.03699481]\n",
      "target: [0.03750216 0.03750216 0.03750216 0.03750216 0.03750216]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03042078 0.03042078 0.03042078 0.03042078 0.03042078]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "Training step 806\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03025988 0.03025988 0.03025988 0.03025988 0.03025988]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.02973695 0.02973695 0.02973695 0.02973695 0.02973695]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03160895 0.03160895 0.03160895 0.03160895 0.03160895]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03139126 0.03139126 0.03139126 0.03139126 0.03139126]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [-0.96840126  0.03159874  0.03159874  0.03159874  0.03159874]\n",
      "target: [0.03195508 0.03195508 0.03195508 0.03195508 0.03195508]\n",
      "target: [0.03738934 0.03738934 0.03738934 0.03738934 0.03738934]\n",
      "target: [0.03158112 0.03158112 0.03158112 0.03158112 0.03158112]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.03145492 0.03145492 0.03145492 0.03145492 0.03145492]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03022519 0.03022519 0.03022519 0.03022519 0.03022519]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.03093102 0.03093102 0.03093102 0.03093102 0.03093102]\n",
      "Training step 807\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161106 0.03161106 0.03161106 0.03161106 0.03161106]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03731045 0.03731045 0.03731045 0.03731045 0.03731045]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03266117 0.03266117 0.03266117 0.03266117 0.03266117]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03240525 0.03240525 0.03240525 0.03240525 0.03240525]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03061584 0.03061584 0.03061584 0.03061584 0.03061584]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03148343 0.03148343 0.03148343 0.03148343 0.03148343]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0.03546324 0.03546324 0.03546324 0.03546324 0.03546324]\n",
      "target: [0.03305388 0.03305388 0.03305388 0.03305388 0.03305388]\n",
      "target: [0.02962932 0.02962932 0.02962932 0.02962932 0.02962932]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03144088 0.03144088 0.03144088 0.03144088 0.03144088]\n",
      "Training step 808\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [-0.96679057  0.03320943  0.03320943  0.03320943  0.03320943]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03187867 0.03187867 0.03187867 0.03187867 0.03187867]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0.03132356 0.03132356 0.03132356 0.03132356 0.03132356]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03043672 0.03043672 0.03043672 0.03043672 0.03043672]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.03147889 0.03147889 0.03147889 0.03147889 0.03147889]\n",
      "target: [0.03056245 0.03056245 0.03056245 0.03056245 0.03056245]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03652291 0.03652291 0.03652291 0.03652291 0.03652291]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "Training step 809\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03060498 0.03060498 0.03060498 0.03060498 0.03060498]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03312024 0.03312024 0.03312024 0.03312024 0.03312024]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03479534 0.03479534 0.03479534 0.03479534 0.03479534]\n",
      "target: [0.03385283 0.03385283 0.03385283 0.03385283 0.03385283]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03427564 0.03427564 0.03427564 0.03427564 0.03427564]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03063383 0.03063383 0.03063383 0.03063383 0.03063383]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03235926 0.03235926 0.03235926 0.03235926 0.03235926]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03149345 0.03149345 0.03149345 0.03149345 0.03149345]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "Training step 810\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03380415 0.03380415 0.03380415 0.03380415 0.03380415]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03347055 0.03347055 0.03347055 0.03347055 0.03347055]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03652291 0.03652291 0.03652291 0.03652291 0.03652291]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03551719 0.03551719 0.03551719 0.03551719 0.03551719]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03156836 0.03156836 0.03156836 0.03156836 0.03156836]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03215123 0.03215123 0.03215123 0.03215123 0.03215123]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03003907 0.03003907 0.03003907 0.03003907 0.03003907]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03228261 0.03228261 0.03228261 0.03228261 0.03228261]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "Training step 811\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03403125 0.03403125 0.03403125 0.03403125 0.03403125]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03344383 0.03344383 0.03344383 0.03344383 0.03344383]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03193626 0.03193626 0.03193626 0.03193626 0.03193626]\n",
      "target: [0.02999874 0.02999874 0.02999874 0.02999874 0.02999874]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.03410373 0.03410373 0.03410373 0.03410373 0.03410373]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03138753 0.03138753 0.03138753 0.03138753 0.03138753]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03345852 0.03345852 0.03345852 0.03345852 0.03345852]\n",
      "target: [-0.96843145  0.03156855  0.03156855  0.03156855  0.03156855]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.02996162 0.02996162 0.02996162 0.02996162 0.02996162]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03095674 0.03095674 0.03095674 0.03095674 0.03095674]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03039842 0.03039842 0.03039842 0.03039842 0.03039842]\n",
      "Training step 812\n",
      "target: [0.03139397 0.03139397 0.03139397 0.03139397 0.03139397]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03395632 0.03395632 0.03395632 0.03395632 0.03395632]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03065244 0.03065244 0.03065244 0.03065244 0.03065244]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03338993 0.03338993 0.03338993 0.03338993 0.03338993]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03378396 0.03378396 0.03378396 0.03378396 0.03378396]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "Training step 813\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03583948 0.03583948 0.03583948 0.03583948 0.03583948]\n",
      "target: [0.03069956 0.03069956 0.03069956 0.03069956 0.03069956]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03271027 0.03271027 0.03271027 0.03271027 0.03271027]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03324372 0.03324372 0.03324372 0.03324372 0.03324372]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [-0.96978553  0.03021447  0.03021447  0.03021447  0.03021447]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03500741 0.03500741 0.03500741 0.03500741 0.03500741]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 814\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03255486 0.03255486 0.03255486 0.03255486 0.03255486]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03741092 0.03741092 0.03741092 0.03741092 0.03741092]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187127 0.03187127 0.03187127 0.03187127 0.03187127]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.03060498 0.03060498 0.03060498 0.03060498 0.03060498]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03568378 0.03568378 0.03568378 0.03568378 0.03568378]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03379845 0.03379845 0.03379845 0.03379845 0.03379845]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [-0.9657352  0.0342648  0.0342648  0.0342648  0.0342648]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.03479374 0.03479374 0.03479374 0.03479374 0.03479374]\n",
      "target: [0.03407128 0.03407128 0.03407128 0.03407128 0.03407128]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03166799 0.03166799 0.03166799 0.03166799 0.03166799]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "Training step 815\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03304792 0.03304792 0.03304792 0.03304792 0.03304792]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03670145 0.03670145 0.03670145 0.03670145 0.03670145]\n",
      "target: [0.0315552 0.0315552 0.0315552 0.0315552 0.0315552]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03065244 0.03065244 0.03065244 0.03065244 0.03065244]\n",
      "target: [0.03319136 0.03319136 0.03319136 0.03319136 0.03319136]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [-0.96817156  0.03182844  0.03182844  0.03182844  0.03182844]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0.03328352 0.03328352 0.03328352 0.03328352 0.03328352]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03232586 0.03232586 0.03232586 0.03232586 0.03232586]\n",
      "target: [0.03197361 0.03197361 0.03197361 0.03197361 0.03197361]\n",
      "Training step 816\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03787248 0.03787248 0.03787248 0.03787248 0.03787248]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03295102 0.03295102 0.03295102 0.03295102 0.03295102]\n",
      "target: [0.03347855 0.03347855 0.03347855 0.03347855 0.03347855]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03488638 0.03488638 0.03488638 0.03488638 0.03488638]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03600809 0.03600809 0.03600809 0.03600809 0.03600809]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03298202 0.03298202 0.03298202 0.03298202 0.03298202]\n",
      "target: [0.03165918 0.03165918 0.03165918 0.03165918 0.03165918]\n",
      "target: [0.03290424 0.03290424 0.03290424 0.03290424 0.03290424]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.03054959 0.03054959 0.03054959 0.03054959 0.03054959]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "Training step 817\n",
      "target: [0.03418368 0.03418368 0.03418368 0.03418368 0.03418368]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03051221 0.03051221 0.03051221 0.03051221 0.03051221]\n",
      "target: [0.03095674 0.03095674 0.03095674 0.03095674 0.03095674]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03180281 0.03180281 0.03180281 0.03180281 0.03180281]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.03290424 0.03290424 0.03290424 0.03290424 0.03290424]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03307078 0.03307078 0.03307078 0.03307078 0.03307078]\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03312024 0.03312024 0.03312024 0.03312024 0.03312024]\n",
      "target: [0.03074385 0.03074385 0.03074385 0.03074385 0.03074385]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03116732 0.03116732 0.03116732 0.03116732 0.03116732]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03390209 0.03390209 0.03390209 0.03390209 0.03390209]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03387504 0.03387504 0.03387504 0.03387504 0.03387504]\n",
      "Training step 818\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.02987642 0.02987642 0.02987642 0.02987642 0.02987642]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03488638 0.03488638 0.03488638 0.03488638 0.03488638]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03255793 0.03255793 0.03255793 0.03255793 0.03255793]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03380423 0.03380423 0.03380423 0.03380423 0.03380423]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03141757 0.03141757 0.03141757 0.03141757 0.03141757]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03704704 0.03704704 0.03704704 0.03704704 0.03704704]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03088141 0.03088141 0.03088141 0.03088141 0.03088141]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03287794 0.03287794 0.03287794 0.03287794 0.03287794]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.02992545 0.02992545 0.02992545 0.02992545 0.02992545]\n",
      "Training step 819\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03040886 0.03040886 0.03040886 0.03040886 0.03040886]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03765684 0.03765684 0.03765684 0.03765684 0.03765684]\n",
      "target: [0.0321769 0.0321769 0.0321769 0.0321769 0.0321769]\n",
      "target: [0.03147889 0.03147889 0.03147889 0.03147889 0.03147889]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03130912 0.03130912 0.03130912 0.03130912 0.03130912]\n",
      "target: [0.03213268 0.03213268 0.03213268 0.03213268 0.03213268]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03366246 0.03366246 0.03366246 0.03366246 0.03366246]\n",
      "target: [0.03040258 0.03040258 0.03040258 0.03040258 0.03040258]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03178549 0.03178549 0.03178549 0.03178549 0.03178549]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 820\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03296537 0.03296537 0.03296537 0.03296537 0.03296537]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [0.03225524 0.03225524 0.03225524 0.03225524 0.03225524]\n",
      "target: [0.03506267 0.03506267 0.03506267 0.03506267 0.03506267]\n",
      "target: [0.03666038 0.03666038 0.03666038 0.03666038 0.03666038]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03323302 0.03323302 0.03323302 0.03323302 0.03323302]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03092714 0.03092714 0.03092714 0.03092714 0.03092714]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0.03365719 0.03365719 0.03365719 0.03365719 0.03365719]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03434652 0.03434652 0.03434652 0.03434652 0.03434652]\n",
      "target: [0.03855604 0.03855604 0.03855604 0.03855604 0.03855604]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.0329355 0.0329355 0.0329355 0.0329355 0.0329355]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "Training step 821\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03296537 0.03296537 0.03296537 0.03296537 0.03296537]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03161106 0.03161106 0.03161106 0.03161106 0.03161106]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [-0.96493174  0.03506826  0.03506826  0.03506826  0.03506826]\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [0.03786388 0.03786388 0.03786388 0.03786388 0.03786388]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03295102 0.03295102 0.03295102 0.03295102 0.03295102]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "Training step 822\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199593 0.03199593 0.03199593 0.03199593 0.03199593]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03171276 0.03171276 0.03171276 0.03171276 0.03171276]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03297614 0.03297614 0.03297614 0.03297614 0.03297614]\n",
      "target: [0.03259068 0.03259068 0.03259068 0.03259068 0.03259068]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.0314861 0.0314861 0.0314861 0.0314861 0.0314861]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03641253 0.03641253 0.03641253 0.03641253 0.03641253]\n",
      "target: [0.03326329 0.03326329 0.03326329 0.03326329 0.03326329]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.0342768 0.0342768 0.0342768 0.0342768 0.0342768]\n",
      "target: [0.03264991 0.03264991 0.03264991 0.03264991 0.03264991]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.02974251 0.02974251 0.02974251 0.02974251 0.02974251]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03078815 0.03078815 0.03078815 0.03078815 0.03078815]\n",
      "target: [0.03233515 0.03233515 0.03233515 0.03233515 0.03233515]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03092866 0.03092866 0.03092866 0.03092866 0.03092866]\n",
      "Training step 823\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03385745 0.03385745 0.03385745 0.03385745 0.03385745]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03324589 0.03324589 0.03324589 0.03324589 0.03324589]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [-0.96886362  0.03113638  0.03113638  0.03113638  0.03113638]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.02953963 0.02953963 0.02953963 0.02953963 0.02953963]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03046574 0.03046574 0.03046574 0.03046574 0.03046574]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.02991573 0.02991573 0.02991573 0.02991573 0.02991573]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "Training step 824\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [-0.9671917  0.0328083  0.0328083  0.0328083  0.0328083]\n",
      "target: [0.03531126 0.03531126 0.03531126 0.03531126 0.03531126]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03910481 0.03910481 0.03910481 0.03910481 0.03910481]\n",
      "target: [0.03016156 0.03016156 0.03016156 0.03016156 0.03016156]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03097849 0.03097849 0.03097849 0.03097849 0.03097849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03411689 0.03411689 0.03411689 0.03411689 0.03411689]\n",
      "target: [0.03383577 0.03383577 0.03383577 0.03383577 0.03383577]\n",
      "target: [0.03251521 0.03251521 0.03251521 0.03251521 0.03251521]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02792388 0.02792388 0.02792388 0.02792388 0.02792388]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03117186 0.03117186 0.03117186 0.03117186 0.03117186]\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03403458 0.03403458 0.03403458 0.03403458 0.03403458]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.02916702 0.02916702 0.02916702 0.02916702 0.02916702]\n",
      "Training step 825\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03165918 0.03165918 0.03165918 0.03165918 0.03165918]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03233043 0.03233043 0.03233043 0.03233043 0.03233043]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.02999081 0.02999081 0.02999081 0.02999081 0.02999081]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03434352 0.03434352 0.03434352 0.03434352 0.03434352]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03244983 0.03244983 0.03244983 0.03244983 0.03244983]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.0359062 0.0359062 0.0359062 0.0359062 0.0359062]\n",
      "target: [0.03157905 0.03157905 0.03157905 0.03157905 0.03157905]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.03133699 0.03133699 0.03133699 0.03133699 0.03133699]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03331425 0.03331425 0.03331425 0.03331425 0.03331425]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "Training step 826\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.02978911 0.02978911 0.02978911 0.02978911 0.02978911]\n",
      "target: [0.03214089 0.03214089 0.03214089 0.03214089 0.03214089]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03212992 0.03212992 0.03212992 0.03212992 0.03212992]\n",
      "target: [0.0340303 0.0340303 0.0340303 0.0340303 0.0340303]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03060498 0.03060498 0.03060498 0.03060498 0.03060498]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.02950752 0.02950752 0.02950752 0.02950752 0.02950752]\n",
      "target: [0.03336416 0.03336416 0.03336416 0.03336416 0.03336416]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.0370668 0.0370668 0.0370668 0.0370668 0.0370668]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03234241 0.03234241 0.03234241 0.03234241 0.03234241]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "Training step 827\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03167545 0.03167545 0.03167545 0.03167545 0.03167545]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.02975502 0.02975502 0.02975502 0.02975502 0.02975502]\n",
      "target: [0.03203671 0.03203671 0.03203671 0.03203671 0.03203671]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03692452 0.03692452 0.03692452 0.03692452 0.03692452]\n",
      "target: [0.03223661 0.03223661 0.03223661 0.03223661 0.03223661]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03322248 0.03322248 0.03322248 0.03322248 0.03322248]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "target: [0.03030449 0.03030449 0.03030449 0.03030449 0.03030449]\n",
      "Training step 828\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03235259 0.03235259 0.03235259 0.03235259 0.03235259]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03163048 0.03163048 0.03163048 0.03163048 0.03163048]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03059033 0.03059033 0.03059033 0.03059033 0.03059033]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.03005069 0.03005069 0.03005069 0.03005069 0.03005069]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.0300473 0.0300473 0.0300473 0.0300473 0.0300473]\n",
      "target: [0.03308356 0.03308356 0.03308356 0.03308356 0.03308356]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0328152 0.0328152 0.0328152 0.0328152 0.0328152]\n",
      "target: [0.03387205 0.03387205 0.03387205 0.03387205 0.03387205]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03461303 0.03461303 0.03461303 0.03461303 0.03461303]\n",
      "target: [0.03550806 0.03550806 0.03550806 0.03550806 0.03550806]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03018347 0.03018347 0.03018347 0.03018347 0.03018347]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03063699 0.03063699 0.03063699 0.03063699 0.03063699]\n",
      "Training step 829\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03230964 0.03230964 0.03230964 0.03230964 0.03230964]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03028996 0.03028996 0.03028996 0.03028996 0.03028996]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03448268 0.03448268 0.03448268 0.03448268 0.03448268]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0.03129352 0.03129352 0.03129352 0.03129352 0.03129352]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03440049 0.03440049 0.03440049 0.03440049 0.03440049]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.0381197 0.0381197 0.0381197 0.0381197 0.0381197]\n",
      "target: [0.03334991 0.03334991 0.03334991 0.03334991 0.03334991]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.02996162 0.02996162 0.02996162 0.02996162 0.02996162]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03106685 0.03106685 0.03106685 0.03106685 0.03106685]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0.03308347 0.03308347 0.03308347 0.03308347 0.03308347]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "Training step 830\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.02940564 0.02940564 0.02940564 0.02940564 0.02940564]\n",
      "target: [0.03186768 0.03186768 0.03186768 0.03186768 0.03186768]\n",
      "target: [0.03027873 0.03027873 0.03027873 0.03027873 0.03027873]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03156854 0.03156854 0.03156854 0.03156854 0.03156854]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03614252 0.03614252 0.03614252 0.03614252 0.03614252]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.0314675 0.0314675 0.0314675 0.0314675 0.0314675]\n",
      "target: [0.03076483 0.03076483 0.03076483 0.03076483 0.03076483]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03045224 0.03045224 0.03045224 0.03045224 0.03045224]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02997782 0.02997782 0.02997782 0.02997782 0.02997782]\n",
      "target: [0.03165969 0.03165969 0.03165969 0.03165969 0.03165969]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03134607 0.03134607 0.03134607 0.03134607 0.03134607]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03780476 0.03780476 0.03780476 0.03780476 0.03780476]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 831\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03257836 0.03257836 0.03257836 0.03257836 0.03257836]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03235273 0.03235273 0.03235273 0.03235273 0.03235273]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03249986 0.03249986 0.03249986 0.03249986 0.03249986]\n",
      "target: [0.03495555 0.03495555 0.03495555 0.03495555 0.03495555]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.03385593 0.03385593 0.03385593 0.03385593 0.03385593]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03232407 0.03232407 0.03232407 0.03232407 0.03232407]\n",
      "target: [0.03288725 0.03288725 0.03288725 0.03288725 0.03288725]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03297813 0.03297813 0.03297813 0.03297813 0.03297813]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03174762 0.03174762 0.03174762 0.03174762 0.03174762]\n",
      "target: [0.03052117 0.03052117 0.03052117 0.03052117 0.03052117]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.0323152 0.0323152 0.0323152 0.0323152 0.0323152]\n",
      "Training step 832\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03070703 0.03070703 0.03070703 0.03070703 0.03070703]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03267376 0.03267376 0.03267376 0.03267376 0.03267376]\n",
      "target: [0.0332353 0.0332353 0.0332353 0.0332353 0.0332353]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03233496 0.03233496 0.03233496 0.03233496 0.03233496]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03328352 0.03328352 0.03328352 0.03328352 0.03328352]\n",
      "target: [0.03488638 0.03488638 0.03488638 0.03488638 0.03488638]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03110742 0.03110742 0.03110742 0.03110742 0.03110742]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03162804 0.03162804 0.03162804 0.03162804 0.03162804]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03222355 0.03222355 0.03222355 0.03222355 0.03222355]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03094222 0.03094222 0.03094222 0.03094222 0.03094222]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "Training step 833\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.03274525 0.03274525 0.03274525 0.03274525 0.03274525]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02787041 0.02787041 0.02787041 0.02787041 0.02787041]\n",
      "target: [0.03264544 0.03264544 0.03264544 0.03264544 0.03264544]\n",
      "target: [0.03228778 0.03228778 0.03228778 0.03228778 0.03228778]\n",
      "target: [0.03355167 0.03355167 0.03355167 0.03355167 0.03355167]\n",
      "target: [0.0330257 0.0330257 0.0330257 0.0330257 0.0330257]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.03080648 0.03080648 0.03080648 0.03080648 0.03080648]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03344666 0.03344666 0.03344666 0.03344666 0.03344666]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03343199 0.03343199 0.03343199 0.03343199 0.03343199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03553716 0.03553716 0.03553716 0.03553716 0.03553716]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03265386 0.03265386 0.03265386 0.03265386 0.03265386]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "Training step 834\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03102889 0.03102889 0.03102889 0.03102889 0.03102889]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03420382 0.03420382 0.03420382 0.03420382 0.03420382]\n",
      "target: [0.0347996 0.0347996 0.0347996 0.0347996 0.0347996]\n",
      "target: [0.03321301 0.03321301 0.03321301 0.03321301 0.03321301]\n",
      "target: [0.03132385 0.03132385 0.03132385 0.03132385 0.03132385]\n",
      "target: [0.03243385 0.03243385 0.03243385 0.03243385 0.03243385]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03335306 0.03335306 0.03335306 0.03335306 0.03335306]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "target: [0.03240983 0.03240983 0.03240983 0.03240983 0.03240983]\n",
      "target: [0.03117409 0.03117409 0.03117409 0.03117409 0.03117409]\n",
      "target: [0.0321421 0.0321421 0.0321421 0.0321421 0.0321421]\n",
      "target: [0.03109434 0.03109434 0.03109434 0.03109434 0.03109434]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304792 0.03304792 0.03304792 0.03304792 0.03304792]\n",
      "target: [0.03266563 0.03266563 0.03266563 0.03266563 0.03266563]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "Training step 835\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03217237 0.03217237 0.03217237 0.03217237 0.03217237]\n",
      "target: [0.03525509 0.03525509 0.03525509 0.03525509 0.03525509]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03324372 0.03324372 0.03324372 0.03324372 0.03324372]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03130554 0.03130554 0.03130554 0.03130554 0.03130554]\n",
      "target: [0.03055185 0.03055185 0.03055185 0.03055185 0.03055185]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03358539 0.03358539 0.03358539 0.03358539 0.03358539]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093102 0.03093102 0.03093102 0.03093102 0.03093102]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03097849 0.03097849 0.03097849 0.03097849 0.03097849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03732474 0.03732474 0.03732474 0.03732474 0.03732474]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "Training step 836\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.031012 0.031012 0.031012 0.031012 0.031012]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03183121 0.03183121 0.03183121 0.03183121 0.03183121]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03562227 0.03562227 0.03562227 0.03562227 0.03562227]\n",
      "target: [0.03053305 0.03053305 0.03053305 0.03053305 0.03053305]\n",
      "target: [0.03655456 0.03655456 0.03655456 0.03655456 0.03655456]\n",
      "target: [0.0292892 0.0292892 0.0292892 0.0292892 0.0292892]\n",
      "target: [0.0319817 0.0319817 0.0319817 0.0319817 0.0319817]\n",
      "target: [0.03217903 0.03217903 0.03217903 0.03217903 0.03217903]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03075699 0.03075699 0.03075699 0.03075699 0.03075699]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.02841803 0.02841803 0.02841803 0.02841803 0.02841803]\n",
      "target: [0.02945234 0.02945234 0.02945234 0.02945234 0.02945234]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03177023 0.03177023 0.03177023 0.03177023 0.03177023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02990955 0.02990955 0.02990955 0.02990955 0.02990955]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03328352 0.03328352 0.03328352 0.03328352 0.03328352]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "Training step 837\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03406474 0.03406474 0.03406474 0.03406474 0.03406474]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03091419 0.03091419 0.03091419 0.03091419 0.03091419]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02844551 0.02844551 0.02844551 0.02844551 0.02844551]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03641253 0.03641253 0.03641253 0.03641253 0.03641253]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03104737 0.03104737 0.03104737 0.03104737 0.03104737]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "target: [0.03286854 0.03286854 0.03286854 0.03286854 0.03286854]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03335232 0.03335232 0.03335232 0.03335232 0.03335232]\n",
      "target: [0.03464589 0.03464589 0.03464589 0.03464589 0.03464589]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03392058 0.03392058 0.03392058 0.03392058 0.03392058]\n",
      "target: [0.03155904 0.03155904 0.03155904 0.03155904 0.03155904]\n",
      "target: [0.03021293 0.03021293 0.03021293 0.03021293 0.03021293]\n",
      "target: [0.02961226 0.02961226 0.02961226 0.02961226 0.02961226]\n",
      "target: [0.03148443 0.03148443 0.03148443 0.03148443 0.03148443]\n",
      "Training step 838\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03318705 0.03318705 0.03318705 0.03318705 0.03318705]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.0364853 0.0364853 0.0364853 0.0364853 0.0364853]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03234044 0.03234044 0.03234044 0.03234044 0.03234044]\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03152428 0.03152428 0.03152428 0.03152428 0.03152428]\n",
      "target: [0.0335014 0.0335014 0.0335014 0.0335014 0.0335014]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.0314861 0.0314861 0.0314861 0.0314861 0.0314861]\n",
      "target: [0.03231458 0.03231458 0.03231458 0.03231458 0.03231458]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03268553 0.03268553 0.03268553 0.03268553 0.03268553]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03215899 0.03215899 0.03215899 0.03215899 0.03215899]\n",
      "target: [0.03173177 0.03173177 0.03173177 0.03173177 0.03173177]\n",
      "target: [0.02790806 0.02790806 0.02790806 0.02790806 0.02790806]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "Training step 839\n",
      "target: [0.03321301 0.03321301 0.03321301 0.03321301 0.03321301]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03061123 0.03061123 0.03061123 0.03061123 0.03061123]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.02992585 0.02992585 0.02992585 0.02992585 0.02992585]\n",
      "target: [0.03931685 0.03931685 0.03931685 0.03931685 0.03931685]\n",
      "target: [0.03204255 0.03204255 0.03204255 0.03204255 0.03204255]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03603683 0.03603683 0.03603683 0.03603683 0.03603683]\n",
      "target: [0.03515995 0.03515995 0.03515995 0.03515995 0.03515995]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03303583 0.03303583 0.03303583 0.03303583 0.03303583]\n",
      "target: [0.03148444 0.03148444 0.03148444 0.03148444 0.03148444]\n",
      "target: [0.03138208 0.03138208 0.03138208 0.03138208 0.03138208]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03055708 0.03055708 0.03055708 0.03055708 0.03055708]\n",
      "target: [0.03270999 0.03270999 0.03270999 0.03270999 0.03270999]\n",
      "target: [0.03799292 0.03799292 0.03799292 0.03799292 0.03799292]\n",
      "target: [-0.96898568  0.03101432  0.03101432  0.03101432  0.03101432]\n",
      "target: [0.03231458 0.03231458 0.03231458 0.03231458 0.03231458]\n",
      "target: [0.03163226 0.03163226 0.03163226 0.03163226 0.03163226]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [0.03166799 0.03166799 0.03166799 0.03166799 0.03166799]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "Training step 840\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03044804 0.03044804 0.03044804 0.03044804 0.03044804]\n",
      "target: [0.03048044 0.03048044 0.03048044 0.03048044 0.03048044]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03238142 0.03238142 0.03238142 0.03238142 0.03238142]\n",
      "target: [0.03068396 0.03068396 0.03068396 0.03068396 0.03068396]\n",
      "target: [0.03184703 0.03184703 0.03184703 0.03184703 0.03184703]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03429846 0.03429846 0.03429846 0.03429846 0.03429846]\n",
      "target: [0.0331617 0.0331617 0.0331617 0.0331617 0.0331617]\n",
      "target: [0.03573441 0.03573441 0.03573441 0.03573441 0.03573441]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03110456 0.03110456 0.03110456 0.03110456 0.03110456]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03102155 0.03102155 0.03102155 0.03102155 0.03102155]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03187106 0.03187106 0.03187106 0.03187106 0.03187106]\n",
      "target: [0.03157249 0.03157249 0.03157249 0.03157249 0.03157249]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 841\n",
      "target: [0.03461391 0.03461391 0.03461391 0.03461391 0.03461391]\n",
      "target: [0.0297728 0.0297728 0.0297728 0.0297728 0.0297728]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03816498 0.03816498 0.03816498 0.03816498 0.03816498]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03262326 0.03262326 0.03262326 0.03262326 0.03262326]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.02987328 0.02987328 0.02987328 0.02987328 0.02987328]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03269268 0.03269268 0.03269268 0.03269268 0.03269268]\n",
      "target: [0.03114104 0.03114104 0.03114104 0.03114104 0.03114104]\n",
      "target: [0.03009005 0.03009005 0.03009005 0.03009005 0.03009005]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03070518 0.03070518 0.03070518 0.03070518 0.03070518]\n",
      "target: [0.03342931 0.03342931 0.03342931 0.03342931 0.03342931]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [-0.96761822  0.03238178  0.03238178  0.03238178  0.03238178]\n",
      "target: [0.03007205 0.03007205 0.03007205 0.03007205 0.03007205]\n",
      "target: [0.03138357 0.03138357 0.03138357 0.03138357 0.03138357]\n",
      "target: [0.0326736 0.0326736 0.0326736 0.0326736 0.0326736]\n",
      "target: [0.03298716 0.03298716 0.03298716 0.03298716 0.03298716]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03996643 0.03996643 0.03996643 0.03996643 0.03996643]\n",
      "target: [0.03026264 0.03026264 0.03026264 0.03026264 0.03026264]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "Training step 842\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0.0309415 0.0309415 0.0309415 0.0309415 0.0309415]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.0336093 0.0336093 0.0336093 0.0336093 0.0336093]\n",
      "target: [0.0307253 0.0307253 0.0307253 0.0307253 0.0307253]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03477823 0.03477823 0.03477823 0.03477823 0.03477823]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03405168 0.03405168 0.03405168 0.03405168 0.03405168]\n",
      "target: [0.03192176 0.03192176 0.03192176 0.03192176 0.03192176]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03167889 0.03167889 0.03167889 0.03167889 0.03167889]\n",
      "target: [0.03128926 0.03128926 0.03128926 0.03128926 0.03128926]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.03666655 0.03666655 0.03666655 0.03666655 0.03666655]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.03416213 0.03416213 0.03416213 0.03416213 0.03416213]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.03060498 0.03060498 0.03060498 0.03060498 0.03060498]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0.03265386 0.03265386 0.03265386 0.03265386 0.03265386]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "Training step 843\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03144649 0.03144649 0.03144649 0.03144649 0.03144649]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03161106 0.03161106 0.03161106 0.03161106 0.03161106]\n",
      "target: [0.03252234 0.03252234 0.03252234 0.03252234 0.03252234]\n",
      "target: [0.03206078 0.03206078 0.03206078 0.03206078 0.03206078]\n",
      "target: [0.03589255 0.03589255 0.03589255 0.03589255 0.03589255]\n",
      "target: [0.03182184 0.03182184 0.03182184 0.03182184 0.03182184]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03148444 0.03148444 0.03148444 0.03148444 0.03148444]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03281916 0.03281916 0.03281916 0.03281916 0.03281916]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03100223 0.03100223 0.03100223 0.03100223 0.03100223]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03324064 0.03324064 0.03324064 0.03324064 0.03324064]\n",
      "target: [0.03753912 0.03753912 0.03753912 0.03753912 0.03753912]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03799292 0.03799292 0.03799292 0.03799292 0.03799292]\n",
      "target: [0.03167742 0.03167742 0.03167742 0.03167742 0.03167742]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 844\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0.03137363 0.03137363 0.03137363 0.03137363 0.03137363]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236625 0.03236625 0.03236625 0.03236625 0.03236625]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03239138 0.03239138 0.03239138 0.03239138 0.03239138]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03128755 0.03128755 0.03128755 0.03128755 0.03128755]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.0373591 0.0373591 0.0373591 0.0373591 0.0373591]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.0332728 0.0332728 0.0332728 0.0332728 0.0332728]\n",
      "target: [0.03370298 0.03370298 0.03370298 0.03370298 0.03370298]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03078405 0.03078405 0.03078405 0.03078405 0.03078405]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03183119 0.03183119 0.03183119 0.03183119 0.03183119]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "Training step 845\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03091838 0.03091838 0.03091838 0.03091838 0.03091838]\n",
      "target: [0.0309604 0.0309604 0.0309604 0.0309604 0.0309604]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0359892 0.0359892 0.0359892 0.0359892 0.0359892]\n",
      "target: [0.02994419 0.02994419 0.02994419 0.02994419 0.02994419]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [-0.96877884  0.03122116  0.03122116  0.03122116  0.03122116]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03034917 0.03034917 0.03034917 0.03034917 0.03034917]\n",
      "target: [0.04080296 0.04080296 0.04080296 0.04080296 0.04080296]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03187867 0.03187867 0.03187867 0.03187867 0.03187867]\n",
      "target: [0.03042109 0.03042109 0.03042109 0.03042109 0.03042109]\n",
      "target: [0.03387754 0.03387754 0.03387754 0.03387754 0.03387754]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03296537 0.03296537 0.03296537 0.03296537 0.03296537]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.03276539 0.03276539 0.03276539 0.03276539 0.03276539]\n",
      "target: [0.02955261 0.02955261 0.02955261 0.02955261 0.02955261]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 846\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199672 0.03199672 0.03199672 0.03199672 0.03199672]\n",
      "target: [0.03169525 0.03169525 0.03169525 0.03169525 0.03169525]\n",
      "target: [0.0317728 0.0317728 0.0317728 0.0317728 0.0317728]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.0308094 0.0308094 0.0308094 0.0308094 0.0308094]\n",
      "target: [0.03080648 0.03080648 0.03080648 0.03080648 0.03080648]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03023025 0.03023025 0.03023025 0.03023025 0.03023025]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03128443 0.03128443 0.03128443 0.03128443 0.03128443]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03264897 0.03264897 0.03264897 0.03264897 0.03264897]\n",
      "target: [0.03178376 0.03178376 0.03178376 0.03178376 0.03178376]\n",
      "target: [0.03402946 0.03402946 0.03402946 0.03402946 0.03402946]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.03238212 0.03238212 0.03238212 0.03238212 0.03238212]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03147196 0.03147196 0.03147196 0.03147196 0.03147196]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0.03707558 0.03707558 0.03707558 0.03707558 0.03707558]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0336883 0.0336883 0.0336883 0.0336883 0.0336883]\n",
      "target: [0.03396817 0.03396817 0.03396817 0.03396817 0.03396817]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.0348944 0.0348944 0.0348944 0.0348944 0.0348944]\n",
      "Training step 847\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03342888 0.03342888 0.03342888 0.03342888 0.03342888]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [-0.96493174  0.03506826  0.03506826  0.03506826  0.03506826]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0261976 0.0261976 0.0261976 0.0261976 0.0261976]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.0314831 0.0314831 0.0314831 0.0314831 0.0314831]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03566864 0.03566864 0.03566864 0.03566864 0.03566864]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03279373 0.03279373 0.03279373 0.03279373 0.03279373]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.0352945 0.0352945 0.0352945 0.0352945 0.0352945]\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [0.03231458 0.03231458 0.03231458 0.03231458 0.03231458]\n",
      "target: [0.03048946 0.03048946 0.03048946 0.03048946 0.03048946]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03155164 0.03155164 0.03155164 0.03155164 0.03155164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "Training step 848\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "target: [0.03894775 0.03894775 0.03894775 0.03894775 0.03894775]\n",
      "target: [-0.96856991  0.03143009  0.03143009  0.03143009  0.03143009]\n",
      "target: [0.03432262 0.03432262 0.03432262 0.03432262 0.03432262]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03183823 0.03183823 0.03183823 0.03183823 0.03183823]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03395632 0.03395632 0.03395632 0.03395632 0.03395632]\n",
      "target: [0.03197427 0.03197427 0.03197427 0.03197427 0.03197427]\n",
      "target: [0.03138158 0.03138158 0.03138158 0.03138158 0.03138158]\n",
      "target: [0.03809412 0.03809412 0.03809412 0.03809412 0.03809412]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03060062 0.03060062 0.03060062 0.03060062 0.03060062]\n",
      "target: [0.03164254 0.03164254 0.03164254 0.03164254 0.03164254]\n",
      "target: [0.03396122 0.03396122 0.03396122 0.03396122 0.03396122]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03491185 0.03491185 0.03491185 0.03491185 0.03491185]\n",
      "target: [0.03095674 0.03095674 0.03095674 0.03095674 0.03095674]\n",
      "target: [0.03069229 0.03069229 0.03069229 0.03069229 0.03069229]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03206989 0.03206989 0.03206989 0.03206989 0.03206989]\n",
      "target: [0.03300853 0.03300853 0.03300853 0.03300853 0.03300853]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [-0.96890358  0.03109642  0.03109642  0.03109642  0.03109642]\n",
      "target: [0.03370101 0.03370101 0.03370101 0.03370101 0.03370101]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03289989 0.03289989 0.03289989 0.03289989 0.03289989]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "Training step 849\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.02968925 0.02968925 0.02968925 0.02968925 0.02968925]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03082004 0.03082004 0.03082004 0.03082004 0.03082004]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.02995708 0.02995708 0.02995708 0.02995708 0.02995708]\n",
      "target: [0.03106156 0.03106156 0.03106156 0.03106156 0.03106156]\n",
      "target: [0.03238212 0.03238212 0.03238212 0.03238212 0.03238212]\n",
      "target: [0.03318254 0.03318254 0.03318254 0.03318254 0.03318254]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03164606 0.03164606 0.03164606 0.03164606 0.03164606]\n",
      "target: [0.03355167 0.03355167 0.03355167 0.03355167 0.03355167]\n",
      "target: [0.03209517 0.03209517 0.03209517 0.03209517 0.03209517]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03429347 0.03429347 0.03429347 0.03429347 0.03429347]\n",
      "target: [0.03307969 0.03307969 0.03307969 0.03307969 0.03307969]\n",
      "target: [0.03048978 0.03048978 0.03048978 0.03048978 0.03048978]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03528719 0.03528719 0.03528719 0.03528719 0.03528719]\n",
      "target: [0.03016096 0.03016096 0.03016096 0.03016096 0.03016096]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03116438 0.03116438 0.03116438 0.03116438 0.03116438]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "Training step 850\n",
      "target: [0.03420667 0.03420667 0.03420667 0.03420667 0.03420667]\n",
      "target: [0.03198592 0.03198592 0.03198592 0.03198592 0.03198592]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03479374 0.03479374 0.03479374 0.03479374 0.03479374]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [-0.96955653  0.03044347  0.03044347  0.03044347  0.03044347]\n",
      "target: [0.03365163 0.03365163 0.03365163 0.03365163 0.03365163]\n",
      "target: [0.03199593 0.03199593 0.03199593 0.03199593 0.03199593]\n",
      "target: [0.03521225 0.03521225 0.03521225 0.03521225 0.03521225]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03154303 0.03154303 0.03154303 0.03154303 0.03154303]\n",
      "target: [0.03730308 0.03730308 0.03730308 0.03730308 0.03730308]\n",
      "target: [0.03195625 0.03195625 0.03195625 0.03195625 0.03195625]\n",
      "target: [0.03037838 0.03037838 0.03037838 0.03037838 0.03037838]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.03115566 0.03115566 0.03115566 0.03115566 0.03115566]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03217766 0.03217766 0.03217766 0.03217766 0.03217766]\n",
      "target: [0.03481322 0.03481322 0.03481322 0.03481322 0.03481322]\n",
      "target: [0.03210044 0.03210044 0.03210044 0.03210044 0.03210044]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03615849 0.03615849 0.03615849 0.03615849 0.03615849]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03078862 0.03078862 0.03078862 0.03078862 0.03078862]\n",
      "Training step 851\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03113884 0.03113884 0.03113884 0.03113884 0.03113884]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02881279 0.02881279 0.02881279 0.02881279 0.02881279]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03093214 0.03093214 0.03093214 0.03093214 0.03093214]\n",
      "target: [0.0386253 0.0386253 0.0386253 0.0386253 0.0386253]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03378254 0.03378254 0.03378254 0.03378254 0.03378254]\n",
      "target: [0.0318274 0.0318274 0.0318274 0.0318274 0.0318274]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03135347 0.03135347 0.03135347 0.03135347 0.03135347]\n",
      "target: [0.03313592 0.03313592 0.03313592 0.03313592 0.03313592]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.03020358 0.03020358 0.03020358 0.03020358 0.03020358]\n",
      "target: [0.03290443 0.03290443 0.03290443 0.03290443 0.03290443]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.03057692 0.03057692 0.03057692 0.03057692 0.03057692]\n",
      "target: [0.03505124 0.03505124 0.03505124 0.03505124 0.03505124]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03482081 0.03482081 0.03482081 0.03482081 0.03482081]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03304395 0.03304395 0.03304395 0.03304395 0.03304395]\n",
      "Training step 852\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03282286 0.03282286 0.03282286 0.03282286 0.03282286]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03347605 0.03347605 0.03347605 0.03347605 0.03347605]\n",
      "target: [0.03095674 0.03095674 0.03095674 0.03095674 0.03095674]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03539772 0.03539772 0.03539772 0.03539772 0.03539772]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.02988579 0.02988579 0.02988579 0.02988579 0.02988579]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03187127 0.03187127 0.03187127 0.03187127 0.03187127]\n",
      "target: [0.03238212 0.03238212 0.03238212 0.03238212 0.03238212]\n",
      "target: [0.03477964 0.03477964 0.03477964 0.03477964 0.03477964]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.03164506 0.03164506 0.03164506 0.03164506 0.03164506]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03268376 0.03268376 0.03268376 0.03268376 0.03268376]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.03443022 0.03443022 0.03443022 0.03443022 0.03443022]\n",
      "target: [0.03005506 0.03005506 0.03005506 0.03005506 0.03005506]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "Training step 853\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03337575 0.03337575 0.03337575 0.03337575 0.03337575]\n",
      "target: [0.03131862 0.03131862 0.03131862 0.03131862 0.03131862]\n",
      "target: [-0.97058257  0.02941743  0.02941743  0.02941743  0.02941743]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03409021 0.03409021 0.03409021 0.03409021 0.03409021]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03243324 0.03243324 0.03243324 0.03243324 0.03243324]\n",
      "target: [0.0316207 0.0316207 0.0316207 0.0316207 0.0316207]\n",
      "target: [0.03293897 0.03293897 0.03293897 0.03293897 0.03293897]\n",
      "target: [0.0318479 0.0318479 0.0318479 0.0318479 0.0318479]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.0308517 0.0308517 0.0308517 0.0308517 0.0308517]\n",
      "target: [0.03256139 0.03256139 0.03256139 0.03256139 0.03256139]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03537475 0.03537475 0.03537475 0.03537475 0.03537475]\n",
      "target: [0.02936539 0.02936539 0.02936539 0.02936539 0.02936539]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "target: [0.03079526 0.03079526 0.03079526 0.03079526 0.03079526]\n",
      "target: [0.03711087 0.03711087 0.03711087 0.03711087 0.03711087]\n",
      "target: [0.03128072 0.03128072 0.03128072 0.03128072 0.03128072]\n",
      "target: [0.03029306 0.03029306 0.03029306 0.03029306 0.03029306]\n",
      "target: [0.03108183 0.03108183 0.03108183 0.03108183 0.03108183]\n",
      "target: [0.0306512 0.0306512 0.0306512 0.0306512 0.0306512]\n",
      "Training step 854\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "target: [0.03320957 0.03320957 0.03320957 0.03320957 0.03320957]\n",
      "target: [0.03132715 0.03132715 0.03132715 0.03132715 0.03132715]\n",
      "target: [0.0408466 0.0408466 0.0408466 0.0408466 0.0408466]\n",
      "target: [0.03144702 0.03144702 0.03144702 0.03144702 0.03144702]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03428611 0.03428611 0.03428611 0.03428611 0.03428611]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03162115 0.03162115 0.03162115 0.03162115 0.03162115]\n",
      "target: [0.03124717 0.03124717 0.03124717 0.03124717 0.03124717]\n",
      "target: [0.03299635 0.03299635 0.03299635 0.03299635 0.03299635]\n",
      "target: [0.03169222 0.03169222 0.03169222 0.03169222 0.03169222]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03204448 0.03204448 0.03204448 0.03204448 0.03204448]\n",
      "target: [0.03597953 0.03597953 0.03597953 0.03597953 0.03597953]\n",
      "target: [0.03397492 0.03397492 0.03397492 0.03397492 0.03397492]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03171276 0.03171276 0.03171276 0.03171276 0.03171276]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03195532 0.03195532 0.03195532 0.03195532 0.03195532]\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03488638 0.03488638 0.03488638 0.03488638 0.03488638]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "Training step 855\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.0307651 0.0307651 0.0307651 0.0307651 0.0307651]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.02890176 0.02890176 0.02890176 0.02890176 0.02890176]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03276569 0.03276569 0.03276569 0.03276569 0.03276569]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03033057 0.03033057 0.03033057 0.03033057 0.03033057]\n",
      "target: [0.03736044 0.03736044 0.03736044 0.03736044 0.03736044]\n",
      "target: [0.02995708 0.02995708 0.02995708 0.02995708 0.02995708]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.0356896 0.0356896 0.0356896 0.0356896 0.0356896]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03142709 0.03142709 0.03142709 0.03142709 0.03142709]\n",
      "target: [0.03002946 0.03002946 0.03002946 0.03002946 0.03002946]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03334733 0.03334733 0.03334733 0.03334733 0.03334733]\n",
      "target: [0.03305199 0.03305199 0.03305199 0.03305199 0.03305199]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0.03396409 0.03396409 0.03396409 0.03396409 0.03396409]\n",
      "target: [0.03180406 0.03180406 0.03180406 0.03180406 0.03180406]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03387754 0.03387754 0.03387754 0.03387754 0.03387754]\n",
      "Training step 856\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0.03132638 0.03132638 0.03132638 0.03132638 0.03132638]\n",
      "target: [0.03193394 0.03193394 0.03193394 0.03193394 0.03193394]\n",
      "target: [0.03384542 0.03384542 0.03384542 0.03384542 0.03384542]\n",
      "target: [0.02987489 0.02987489 0.02987489 0.02987489 0.02987489]\n",
      "target: [0.03199387 0.03199387 0.03199387 0.03199387 0.03199387]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03672838 0.03672838 0.03672838 0.03672838 0.03672838]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03116253 0.03116253 0.03116253 0.03116253 0.03116253]\n",
      "target: [0.03230955 0.03230955 0.03230955 0.03230955 0.03230955]\n",
      "target: [0.03699481 0.03699481 0.03699481 0.03699481 0.03699481]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03496897 0.03496897 0.03496897 0.03496897 0.03496897]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03228476 0.03228476 0.03228476 0.03228476 0.03228476]\n",
      "target: [0.0320796 0.0320796 0.0320796 0.0320796 0.0320796]\n",
      "target: [0.0311288 0.0311288 0.0311288 0.0311288 0.0311288]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0.03337575 0.03337575 0.03337575 0.03337575 0.03337575]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03292377 0.03292377 0.03292377 0.03292377 0.03292377]\n",
      "target: [0.02978803 0.02978803 0.02978803 0.02978803 0.02978803]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03304792 0.03304792 0.03304792 0.03304792 0.03304792]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.0323518 0.0323518 0.0323518 0.0323518 0.0323518]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "Training step 857\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03059282 0.03059282 0.03059282 0.03059282 0.03059282]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03161106 0.03161106 0.03161106 0.03161106 0.03161106]\n",
      "target: [0.03533646 0.03533646 0.03533646 0.03533646 0.03533646]\n",
      "target: [0.03342509 0.03342509 0.03342509 0.03342509 0.03342509]\n",
      "target: [0.032196 0.032196 0.032196 0.032196 0.032196]\n",
      "target: [0.02967565 0.02967565 0.02967565 0.02967565 0.02967565]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03162115 0.03162115 0.03162115 0.03162115 0.03162115]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03228498 0.03228498 0.03228498 0.03228498 0.03228498]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03181905 0.03181905 0.03181905 0.03181905 0.03181905]\n",
      "target: [0.03554156 0.03554156 0.03554156 0.03554156 0.03554156]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03080781 0.03080781 0.03080781 0.03080781 0.03080781]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03194397 0.03194397 0.03194397 0.03194397 0.03194397]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0.03357672 0.03357672 0.03357672 0.03357672 0.03357672]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03051982 0.03051982 0.03051982 0.03051982 0.03051982]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03112499 0.03112499 0.03112499 0.03112499 0.03112499]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "Training step 858\n",
      "target: [0.03102843 0.03102843 0.03102843 0.03102843 0.03102843]\n",
      "target: [0.03095712 0.03095712 0.03095712 0.03095712 0.03095712]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0374358 0.0374358 0.0374358 0.0374358 0.0374358]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03610595 0.03610595 0.03610595 0.03610595 0.03610595]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03637482 0.03637482 0.03637482 0.03637482 0.03637482]\n",
      "target: [0.03271632 0.03271632 0.03271632 0.03271632 0.03271632]\n",
      "target: [0.03588163 0.03588163 0.03588163 0.03588163 0.03588163]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0.03266402 0.03266402 0.03266402 0.03266402 0.03266402]\n",
      "target: [0.03479588 0.03479588 0.03479588 0.03479588 0.03479588]\n",
      "target: [0.03246063 0.03246063 0.03246063 0.03246063 0.03246063]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.03195236 0.03195236 0.03195236 0.03195236 0.03195236]\n",
      "target: [0.03377167 0.03377167 0.03377167 0.03377167 0.03377167]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02995268 0.02995268 0.02995268 0.02995268 0.02995268]\n",
      "target: [0.03323614 0.03323614 0.03323614 0.03323614 0.03323614]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03138249 0.03138249 0.03138249 0.03138249 0.03138249]\n",
      "target: [0.0326105 0.0326105 0.0326105 0.0326105 0.0326105]\n",
      "Training step 859\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.03132268 0.03132268 0.03132268 0.03132268 0.03132268]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03309162 0.03309162 0.03309162 0.03309162 0.03309162]\n",
      "target: [0.03032598 0.03032598 0.03032598 0.03032598 0.03032598]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03131945 0.03131945 0.03131945 0.03131945 0.03131945]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.03695498 0.03695498 0.03695498 0.03695498 0.03695498]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03043837 0.03043837 0.03043837 0.03043837 0.03043837]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03391544 0.03391544 0.03391544 0.03391544 0.03391544]\n",
      "target: [0.03263215 0.03263215 0.03263215 0.03263215 0.03263215]\n",
      "target: [0.03227657 0.03227657 0.03227657 0.03227657 0.03227657]\n",
      "target: [0.03427564 0.03427564 0.03427564 0.03427564 0.03427564]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03391218 0.03391218 0.03391218 0.03391218 0.03391218]\n",
      "target: [0.03128023 0.03128023 0.03128023 0.03128023 0.03128023]\n",
      "target: [0.03056588 0.03056588 0.03056588 0.03056588 0.03056588]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03269324 0.03269324 0.03269324 0.03269324 0.03269324]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.0328006 0.0328006 0.0328006 0.0328006 0.0328006]\n",
      "target: [0.03394243 0.03394243 0.03394243 0.03394243 0.03394243]\n",
      "Training step 860\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [0.03540704 0.03540704 0.03540704 0.03540704 0.03540704]\n",
      "target: [0.03357815 0.03357815 0.03357815 0.03357815 0.03357815]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03338513 0.03338513 0.03338513 0.03338513 0.03338513]\n",
      "target: [0.0314861 0.0314861 0.0314861 0.0314861 0.0314861]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03216602 0.03216602 0.03216602 0.03216602 0.03216602]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.03172359 0.03172359 0.03172359 0.03172359 0.03172359]\n",
      "target: [0.03142179 0.03142179 0.03142179 0.03142179 0.03142179]\n",
      "target: [0.03276905 0.03276905 0.03276905 0.03276905 0.03276905]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0.03052117 0.03052117 0.03052117 0.03052117 0.03052117]\n",
      "target: [0.03032245 0.03032245 0.03032245 0.03032245 0.03032245]\n",
      "target: [0.03463842 0.03463842 0.03463842 0.03463842 0.03463842]\n",
      "target: [0.03217663 0.03217663 0.03217663 0.03217663 0.03217663]\n",
      "target: [0.03172075 0.03172075 0.03172075 0.03172075 0.03172075]\n",
      "target: [0.03215367 0.03215367 0.03215367 0.03215367 0.03215367]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.03033845 0.03033845 0.03033845 0.03033845 0.03033845]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.03017014 0.03017014 0.03017014 0.03017014 0.03017014]\n",
      "target: [0.03408759 0.03408759 0.03408759 0.03408759 0.03408759]\n",
      "target: [0.03293718 0.03293718 0.03293718 0.03293718 0.03293718]\n",
      "target: [0.03410304 0.03410304 0.03410304 0.03410304 0.03410304]\n",
      "Training step 861\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0.02976125 0.02976125 0.02976125 0.02976125 0.02976125]\n",
      "target: [-0.96897466  0.03102534  0.03102534  0.03102534  0.03102534]\n",
      "target: [0.03080648 0.03080648 0.03080648 0.03080648 0.03080648]\n",
      "target: [0.03161516 0.03161516 0.03161516 0.03161516 0.03161516]\n",
      "target: [0.0347073 0.0347073 0.0347073 0.0347073 0.0347073]\n",
      "target: [0.03389641 0.03389641 0.03389641 0.03389641 0.03389641]\n",
      "target: [0.03196654 0.03196654 0.03196654 0.03196654 0.03196654]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03284359 0.03284359 0.03284359 0.03284359 0.03284359]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03081607 0.03081607 0.03081607 0.03081607 0.03081607]\n",
      "target: [0.03344414 0.03344414 0.03344414 0.03344414 0.03344414]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [-0.96945977  0.03054023  0.03054023  0.03054023  0.03054023]\n",
      "target: [0.03098529 0.03098529 0.03098529 0.03098529 0.03098529]\n",
      "target: [0.03215931 0.03215931 0.03215931 0.03215931 0.03215931]\n",
      "target: [0.03518818 0.03518818 0.03518818 0.03518818 0.03518818]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03239138 0.03239138 0.03239138 0.03239138 0.03239138]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.02970617 0.02970617 0.02970617 0.02970617 0.02970617]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03181105 0.03181105 0.03181105 0.03181105 0.03181105]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "Training step 862\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.03224286 0.03224286 0.03224286 0.03224286 0.03224286]\n",
      "target: [0.03134279 0.03134279 0.03134279 0.03134279 0.03134279]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03119391 0.03119391 0.03119391 0.03119391 0.03119391]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03137509 0.03137509 0.03137509 0.03137509 0.03137509]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03097849 0.03097849 0.03097849 0.03097849 0.03097849]\n",
      "target: [0.03258163 0.03258163 0.03258163 0.03258163 0.03258163]\n",
      "target: [0.03139 0.03139 0.03139 0.03139 0.03139]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03306892 0.03306892 0.03306892 0.03306892 0.03306892]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.0302901 0.0302901 0.0302901 0.0302901 0.0302901]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03304792 0.03304792 0.03304792 0.03304792 0.03304792]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03690225 0.03690225 0.03690225 0.03690225 0.03690225]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03295102 0.03295102 0.03295102 0.03295102 0.03295102]\n",
      "target: [0.02956065 0.02956065 0.02956065 0.02956065 0.02956065]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03093488 0.03093488 0.03093488 0.03093488 0.03093488]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03342561 0.03342561 0.03342561 0.03342561 0.03342561]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "Training step 863\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.03799292 0.03799292 0.03799292 0.03799292 0.03799292]\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.0312282 0.0312282 0.0312282 0.0312282 0.0312282]\n",
      "target: [0.03290024 0.03290024 0.03290024 0.03290024 0.03290024]\n",
      "target: [0.03879653 0.03879653 0.03879653 0.03879653 0.03879653]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03801803 0.03801803 0.03801803 0.03801803 0.03801803]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03493109 0.03493109 0.03493109 0.03493109 0.03493109]\n",
      "target: [0.03369079 0.03369079 0.03369079 0.03369079 0.03369079]\n",
      "target: [0.03401424 0.03401424 0.03401424 0.03401424 0.03401424]\n",
      "target: [0.0324451 0.0324451 0.0324451 0.0324451 0.0324451]\n",
      "target: [0.03252245 0.03252245 0.03252245 0.03252245 0.03252245]\n",
      "target: [0.03239031 0.03239031 0.03239031 0.03239031 0.03239031]\n",
      "target: [0.03052117 0.03052117 0.03052117 0.03052117 0.03052117]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03183305 0.03183305 0.03183305 0.03183305 0.03183305]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.02997354 0.02997354 0.02997354 0.02997354 0.02997354]\n",
      "target: [0.03120269 0.03120269 0.03120269 0.03120269 0.03120269]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03491223 0.03491223 0.03491223 0.03491223 0.03491223]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "Training step 864\n",
      "target: [0.03112768 0.03112768 0.03112768 0.03112768 0.03112768]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03137687 0.03137687 0.03137687 0.03137687 0.03137687]\n",
      "target: [0.03185515 0.03185515 0.03185515 0.03185515 0.03185515]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0.03252094 0.03252094 0.03252094 0.03252094 0.03252094]\n",
      "target: [0.03760174 0.03760174 0.03760174 0.03760174 0.03760174]\n",
      "target: [0.03093214 0.03093214 0.03093214 0.03093214 0.03093214]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.032597 0.032597 0.032597 0.032597 0.032597]\n",
      "target: [0.03221862 0.03221862 0.03221862 0.03221862 0.03221862]\n",
      "target: [0.03080648 0.03080648 0.03080648 0.03080648 0.03080648]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03237695 0.03237695 0.03237695 0.03237695 0.03237695]\n",
      "target: [0.02962128 0.02962128 0.02962128 0.02962128 0.02962128]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03335228 0.03335228 0.03335228 0.03335228 0.03335228]\n",
      "target: [0.03871179 0.03871179 0.03871179 0.03871179 0.03871179]\n",
      "target: [0.03088521 0.03088521 0.03088521 0.03088521 0.03088521]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03477438 0.03477438 0.03477438 0.03477438 0.03477438]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03288286 0.03288286 0.03288286 0.03288286 0.03288286]\n",
      "target: [0.03231458 0.03231458 0.03231458 0.03231458 0.03231458]\n",
      "target: [0.03127678 0.03127678 0.03127678 0.03127678 0.03127678]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "Training step 865\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.02995324 0.02995324 0.02995324 0.02995324 0.02995324]\n",
      "target: [0.03318782 0.03318782 0.03318782 0.03318782 0.03318782]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03162115 0.03162115 0.03162115 0.03162115 0.03162115]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03620192 0.03620192 0.03620192 0.03620192 0.03620192]\n",
      "target: [0.03427564 0.03427564 0.03427564 0.03427564 0.03427564]\n",
      "target: [0.03407901 0.03407901 0.03407901 0.03407901 0.03407901]\n",
      "target: [0.0365038 0.0365038 0.0365038 0.0365038 0.0365038]\n",
      "target: [0.03684574 0.03684574 0.03684574 0.03684574 0.03684574]\n",
      "target: [0.03819262 0.03819262 0.03819262 0.03819262 0.03819262]\n",
      "target: [0.03058681 0.03058681 0.03058681 0.03058681 0.03058681]\n",
      "target: [0.03345272 0.03345272 0.03345272 0.03345272 0.03345272]\n",
      "target: [-0.96801686  0.03198314  0.03198314  0.03198314  0.03198314]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.0337476 0.0337476 0.0337476 0.0337476 0.0337476]\n",
      "target: [0.03196055 0.03196055 0.03196055 0.03196055 0.03196055]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03054652 0.03054652 0.03054652 0.03054652 0.03054652]\n",
      "target: [0.03559993 0.03559993 0.03559993 0.03559993 0.03559993]\n",
      "target: [-0.96840126  0.03159874  0.03159874  0.03159874  0.03159874]\n",
      "target: [0.03194715 0.03194715 0.03194715 0.03194715 0.03194715]\n",
      "target: [0.03058366 0.03058366 0.03058366 0.03058366 0.03058366]\n",
      "target: [0.03234828 0.03234828 0.03234828 0.03234828 0.03234828]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.0340364 0.0340364 0.0340364 0.0340364 0.0340364]\n",
      "target: [0.03316184 0.03316184 0.03316184 0.03316184 0.03316184]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03434611 0.03434611 0.03434611 0.03434611 0.03434611]\n",
      "target: [0.03345833 0.03345833 0.03345833 0.03345833 0.03345833]\n",
      "Training step 866\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [-0.96819136  0.03180864  0.03180864  0.03180864  0.03180864]\n",
      "target: [0.03321955 0.03321955 0.03321955 0.03321955 0.03321955]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03241515 0.03241515 0.03241515 0.03241515 0.03241515]\n",
      "target: [0.03124009 0.03124009 0.03124009 0.03124009 0.03124009]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03111726 0.03111726 0.03111726 0.03111726 0.03111726]\n",
      "target: [0.03121759 0.03121759 0.03121759 0.03121759 0.03121759]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03053762 0.03053762 0.03053762 0.03053762 0.03053762]\n",
      "target: [0.03187127 0.03187127 0.03187127 0.03187127 0.03187127]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0.02946749 0.02946749 0.02946749 0.02946749 0.02946749]\n",
      "target: [0.03615108 0.03615108 0.03615108 0.03615108 0.03615108]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03129515 0.03129515 0.03129515 0.03129515 0.03129515]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03115272 0.03115272 0.03115272 0.03115272 0.03115272]\n",
      "target: [0.03267228 0.03267228 0.03267228 0.03267228 0.03267228]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03251294 0.03251294 0.03251294 0.03251294 0.03251294]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03285147 0.03285147 0.03285147 0.03285147 0.03285147]\n",
      "target: [0.03314589 0.03314589 0.03314589 0.03314589 0.03314589]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "Training step 867\n",
      "target: [0.03331659 0.03331659 0.03331659 0.03331659 0.03331659]\n",
      "target: [0.03038565 0.03038565 0.03038565 0.03038565 0.03038565]\n",
      "target: [0.03337575 0.03337575 0.03337575 0.03337575 0.03337575]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03018009 0.03018009 0.03018009 0.03018009 0.03018009]\n",
      "target: [0.03378336 0.03378336 0.03378336 0.03378336 0.03378336]\n",
      "target: [0.0316781 0.0316781 0.0316781 0.0316781 0.0316781]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03186534 0.03186534 0.03186534 0.03186534 0.03186534]\n",
      "target: [0.0306824 0.0306824 0.0306824 0.0306824 0.0306824]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.031686 0.031686 0.031686 0.031686 0.031686]\n",
      "target: [0.03004826 0.03004826 0.03004826 0.03004826 0.03004826]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03043281 0.03043281 0.03043281 0.03043281 0.03043281]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03843182 0.03843182 0.03843182 0.03843182 0.03843182]\n",
      "target: [0.03169964 0.03169964 0.03169964 0.03169964 0.03169964]\n",
      "target: [0.03688981 0.03688981 0.03688981 0.03688981 0.03688981]\n",
      "target: [0.03731749 0.03731749 0.03731749 0.03731749 0.03731749]\n",
      "target: [0.03075947 0.03075947 0.03075947 0.03075947 0.03075947]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03608049 0.03608049 0.03608049 0.03608049 0.03608049]\n",
      "target: [0.02945426 0.02945426 0.02945426 0.02945426 0.02945426]\n",
      "target: [0.03270697 0.03270697 0.03270697 0.03270697 0.03270697]\n",
      "target: [0.03300382 0.03300382 0.03300382 0.03300382 0.03300382]\n",
      "target: [0.03029026 0.03029026 0.03029026 0.03029026 0.03029026]\n",
      "target: [0.03358539 0.03358539 0.03358539 0.03358539 0.03358539]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "Training step 868\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03077775 0.03077775 0.03077775 0.03077775 0.03077775]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.02977804 0.02977804 0.02977804 0.02977804 0.02977804]\n",
      "target: [0.03229995 0.03229995 0.03229995 0.03229995 0.03229995]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03718455 0.03718455 0.03718455 0.03718455 0.03718455]\n",
      "target: [0.0293094 0.0293094 0.0293094 0.0293094 0.0293094]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.0308517 0.0308517 0.0308517 0.0308517 0.0308517]\n",
      "target: [0.03812174 0.03812174 0.03812174 0.03812174 0.03812174]\n",
      "target: [0.03097796 0.03097796 0.03097796 0.03097796 0.03097796]\n",
      "target: [0.03169541 0.03169541 0.03169541 0.03169541 0.03169541]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0332626 0.0332626 0.0332626 0.0332626 0.0332626]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.02819912 0.02819912 0.02819912 0.02819912 0.02819912]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03597495 0.03597495 0.03597495 0.03597495 0.03597495]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03743435 0.03743435 0.03743435 0.03743435 0.03743435]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236677 0.03236677 0.03236677 0.03236677 0.03236677]\n",
      "target: [0.03178689 0.03178689 0.03178689 0.03178689 0.03178689]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03199593 0.03199593 0.03199593 0.03199593 0.03199593]\n",
      "Training step 869\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0.03347605 0.03347605 0.03347605 0.03347605 0.03347605]\n",
      "target: [0.03132715 0.03132715 0.03132715 0.03132715 0.03132715]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03609257 0.03609257 0.03609257 0.03609257 0.03609257]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03028699 0.03028699 0.03028699 0.03028699 0.03028699]\n",
      "target: [0.03010698 0.03010698 0.03010698 0.03010698 0.03010698]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03237742 0.03237742 0.03237742 0.03237742 0.03237742]\n",
      "target: [0.03249795 0.03249795 0.03249795 0.03249795 0.03249795]\n",
      "target: [0.03265191 0.03265191 0.03265191 0.03265191 0.03265191]\n",
      "target: [0.03048613 0.03048613 0.03048613 0.03048613 0.03048613]\n",
      "target: [0.03433171 0.03433171 0.03433171 0.03433171 0.03433171]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.0388757 0.0388757 0.0388757 0.0388757 0.0388757]\n",
      "target: [0.03324372 0.03324372 0.03324372 0.03324372 0.03324372]\n",
      "target: [0.03099698 0.03099698 0.03099698 0.03099698 0.03099698]\n",
      "target: [0.02910147 0.02910147 0.02910147 0.02910147 0.02910147]\n",
      "target: [0.03327432 0.03327432 0.03327432 0.03327432 0.03327432]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [-0.96839099  0.03160901  0.03160901  0.03160901  0.03160901]\n",
      "target: [0.03089564 0.03089564 0.03089564 0.03089564 0.03089564]\n",
      "target: [0.03028386 0.03028386 0.03028386 0.03028386 0.03028386]\n",
      "target: [0.03642601 0.03642601 0.03642601 0.03642601 0.03642601]\n",
      "target: [0.03658081 0.03658081 0.03658081 0.03658081 0.03658081]\n",
      "target: [0.0317948 0.0317948 0.0317948 0.0317948 0.0317948]\n",
      "target: [0.03308613 0.03308613 0.03308613 0.03308613 0.03308613]\n",
      "target: [0.03739973 0.03739973 0.03739973 0.03739973 0.03739973]\n",
      "target: [0.0338309 0.0338309 0.0338309 0.0338309 0.0338309]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "Training step 870\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03224614 0.03224614 0.03224614 0.03224614 0.03224614]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03400677 0.03400677 0.03400677 0.03400677 0.03400677]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03056507 0.03056507 0.03056507 0.03056507 0.03056507]\n",
      "target: [0.03460274 0.03460274 0.03460274 0.03460274 0.03460274]\n",
      "target: [0.03162484 0.03162484 0.03162484 0.03162484 0.03162484]\n",
      "target: [0.03143509 0.03143509 0.03143509 0.03143509 0.03143509]\n",
      "target: [0.03278988 0.03278988 0.03278988 0.03278988 0.03278988]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.02927245 0.02927245 0.02927245 0.02927245 0.02927245]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "target: [0.0317778 0.0317778 0.0317778 0.0317778 0.0317778]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [0.03292623 0.03292623 0.03292623 0.03292623 0.03292623]\n",
      "target: [0.03294659 0.03294659 0.03294659 0.03294659 0.03294659]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03269717 0.03269717 0.03269717 0.03269717 0.03269717]\n",
      "target: [0.03420137 0.03420137 0.03420137 0.03420137 0.03420137]\n",
      "target: [0.03299445 0.03299445 0.03299445 0.03299445 0.03299445]\n",
      "target: [0.03579143 0.03579143 0.03579143 0.03579143 0.03579143]\n",
      "target: [0.03140588 0.03140588 0.03140588 0.03140588 0.03140588]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03487168 0.03487168 0.03487168 0.03487168 0.03487168]\n",
      "target: [0.03685872 0.03685872 0.03685872 0.03685872 0.03685872]\n",
      "target: [0.03254192 0.03254192 0.03254192 0.03254192 0.03254192]\n",
      "target: [0.03082004 0.03082004 0.03082004 0.03082004 0.03082004]\n",
      "target: [0.0325191 0.0325191 0.0325191 0.0325191 0.0325191]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "Training step 871\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.0309735 0.0309735 0.0309735 0.0309735 0.0309735]\n",
      "target: [0.03261821 0.03261821 0.03261821 0.03261821 0.03261821]\n",
      "target: [0.03179903 0.03179903 0.03179903 0.03179903 0.03179903]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03334118 0.03334118 0.03334118 0.03334118 0.03334118]\n",
      "target: [0.03261394 0.03261394 0.03261394 0.03261394 0.03261394]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03224665 0.03224665 0.03224665 0.03224665 0.03224665]\n",
      "target: [0.03301903 0.03301903 0.03301903 0.03301903 0.03301903]\n",
      "target: [0.03160174 0.03160174 0.03160174 0.03160174 0.03160174]\n",
      "target: [0.02962835 0.02962835 0.02962835 0.02962835 0.02962835]\n",
      "target: [0.03467533 0.03467533 0.03467533 0.03467533 0.03467533]\n",
      "target: [0.03635339 0.03635339 0.03635339 0.03635339 0.03635339]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03415132 0.03415132 0.03415132 0.03415132 0.03415132]\n",
      "target: [0.03205276 0.03205276 0.03205276 0.03205276 0.03205276]\n",
      "target: [0.03366411 0.03366411 0.03366411 0.03366411 0.03366411]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.0330271 0.0330271 0.0330271 0.0330271 0.0330271]\n",
      "target: [0.03126427 0.03126427 0.03126427 0.03126427 0.03126427]\n",
      "target: [0.03300846 0.03300846 0.03300846 0.03300846 0.03300846]\n",
      "target: [0.03220841 0.03220841 0.03220841 0.03220841 0.03220841]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03184852 0.03184852 0.03184852 0.03184852 0.03184852]\n",
      "target: [0.03210349 0.03210349 0.03210349 0.03210349 0.03210349]\n",
      "target: [0.03184192 0.03184192 0.03184192 0.03184192 0.03184192]\n",
      "target: [0.03123355 0.03123355 0.03123355 0.03123355 0.03123355]\n",
      "Training step 872\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03321455 0.03321455 0.03321455 0.03321455 0.03321455]\n",
      "target: [0.03150167 0.03150167 0.03150167 0.03150167 0.03150167]\n",
      "target: [0.03093567 0.03093567 0.03093567 0.03093567 0.03093567]\n",
      "target: [0.03171276 0.03171276 0.03171276 0.03171276 0.03171276]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.034863 0.034863 0.034863 0.034863 0.034863]\n",
      "target: [0.03273393 0.03273393 0.03273393 0.03273393 0.03273393]\n",
      "target: [0.03106879 0.03106879 0.03106879 0.03106879 0.03106879]\n",
      "target: [0.03235919 0.03235919 0.03235919 0.03235919 0.03235919]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.03232728 0.03232728 0.03232728 0.03232728 0.03232728]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03154049 0.03154049 0.03154049 0.03154049 0.03154049]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03118284 0.03118284 0.03118284 0.03118284 0.03118284]\n",
      "target: [0.03308347 0.03308347 0.03308347 0.03308347 0.03308347]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03289056 0.03289056 0.03289056 0.03289056 0.03289056]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03162115 0.03162115 0.03162115 0.03162115 0.03162115]\n",
      "target: [0.03457851 0.03457851 0.03457851 0.03457851 0.03457851]\n",
      "target: [0.03398627 0.03398627 0.03398627 0.03398627 0.03398627]\n",
      "target: [0.03513796 0.03513796 0.03513796 0.03513796 0.03513796]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03070576 0.03070576 0.03070576 0.03070576 0.03070576]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03705596 0.03705596 0.03705596 0.03705596 0.03705596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03584426 0.03584426 0.03584426 0.03584426 0.03584426]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03197697 0.03197697 0.03197697 0.03197697 0.03197697]\n",
      "Training step 873\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03318272 0.03318272 0.03318272 0.03318272 0.03318272]\n",
      "target: [0.03170185 0.03170185 0.03170185 0.03170185 0.03170185]\n",
      "target: [0.03297324 0.03297324 0.03297324 0.03297324 0.03297324]\n",
      "target: [0.0362199 0.0362199 0.0362199 0.0362199 0.0362199]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03358539 0.03358539 0.03358539 0.03358539 0.03358539]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03600354 0.03600354 0.03600354 0.03600354 0.03600354]\n",
      "target: [0.03087185 0.03087185 0.03087185 0.03087185 0.03087185]\n",
      "target: [0.0350638 0.0350638 0.0350638 0.0350638 0.0350638]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03236701 0.03236701 0.03236701 0.03236701 0.03236701]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "target: [0.03629677 0.03629677 0.03629677 0.03629677 0.03629677]\n",
      "target: [0.03246858 0.03246858 0.03246858 0.03246858 0.03246858]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.0387634 0.0387634 0.0387634 0.0387634 0.0387634]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03377425 0.03377425 0.03377425 0.03377425 0.03377425]\n",
      "target: [0.03250959 0.03250959 0.03250959 0.03250959 0.03250959]\n",
      "target: [0.03690358 0.03690358 0.03690358 0.03690358 0.03690358]\n",
      "target: [0.03305147 0.03305147 0.03305147 0.03305147 0.03305147]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0.03167304 0.03167304 0.03167304 0.03167304 0.03167304]\n",
      "target: [0.03145307 0.03145307 0.03145307 0.03145307 0.03145307]\n",
      "target: [0.03187588 0.03187588 0.03187588 0.03187588 0.03187588]\n",
      "target: [0.03179281 0.03179281 0.03179281 0.03179281 0.03179281]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.03337575 0.03337575 0.03337575 0.03337575 0.03337575]\n",
      "target: [0.03252094 0.03252094 0.03252094 0.03252094 0.03252094]\n",
      "Training step 874\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03253851 0.03253851 0.03253851 0.03253851 0.03253851]\n",
      "target: [0.03334991 0.03334991 0.03334991 0.03334991 0.03334991]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.03387205 0.03387205 0.03387205 0.03387205 0.03387205]\n",
      "target: [0.03638716 0.03638716 0.03638716 0.03638716 0.03638716]\n",
      "target: [0.03435803 0.03435803 0.03435803 0.03435803 0.03435803]\n",
      "target: [0.02685506 0.02685506 0.02685506 0.02685506 0.02685506]\n",
      "target: [0.03315887 0.03315887 0.03315887 0.03315887 0.03315887]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.03320337 0.03320337 0.03320337 0.03320337 0.03320337]\n",
      "target: [0.03711762 0.03711762 0.03711762 0.03711762 0.03711762]\n",
      "target: [0.03455655 0.03455655 0.03455655 0.03455655 0.03455655]\n",
      "target: [0.03353114 0.03353114 0.03353114 0.03353114 0.03353114]\n",
      "target: [0.03407104 0.03407104 0.03407104 0.03407104 0.03407104]\n",
      "target: [0.03572518 0.03572518 0.03572518 0.03572518 0.03572518]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03240396 0.03240396 0.03240396 0.03240396 0.03240396]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03306207 0.03306207 0.03306207 0.03306207 0.03306207]\n",
      "target: [0.0321286 0.0321286 0.0321286 0.0321286 0.0321286]\n",
      "target: [0.03093177 0.03093177 0.03093177 0.03093177 0.03093177]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0316411 0.0316411 0.0316411 0.0316411 0.0316411]\n",
      "target: [0.03385859 0.03385859 0.03385859 0.03385859 0.03385859]\n",
      "target: [-0.96819136  0.03180864  0.03180864  0.03180864  0.03180864]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [0.03324694 0.03324694 0.03324694 0.03324694 0.03324694]\n",
      "target: [0.0324911 0.0324911 0.0324911 0.0324911 0.0324911]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03048583 0.03048583 0.03048583 0.03048583 0.03048583]\n",
      "Training step 875\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "target: [0.03086439 0.03086439 0.03086439 0.03086439 0.03086439]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03020163 0.03020163 0.03020163 0.03020163 0.03020163]\n",
      "target: [0.03107885 0.03107885 0.03107885 0.03107885 0.03107885]\n",
      "target: [0.03028578 0.03028578 0.03028578 0.03028578 0.03028578]\n",
      "target: [0.03149948 0.03149948 0.03149948 0.03149948 0.03149948]\n",
      "target: [0.03345719 0.03345719 0.03345719 0.03345719 0.03345719]\n",
      "target: [0.03390877 0.03390877 0.03390877 0.03390877 0.03390877]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03291776 0.03291776 0.03291776 0.03291776 0.03291776]\n",
      "target: [0.03056424 0.03056424 0.03056424 0.03056424 0.03056424]\n",
      "target: [0.03060551 0.03060551 0.03060551 0.03060551 0.03060551]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03643548 0.03643548 0.03643548 0.03643548 0.03643548]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03754953 0.03754953 0.03754953 0.03754953 0.03754953]\n",
      "target: [0.03057124 0.03057124 0.03057124 0.03057124 0.03057124]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03029749 0.03029749 0.03029749 0.03029749 0.03029749]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03426438 0.03426438 0.03426438 0.03426438 0.03426438]\n",
      "target: [0.03528887 0.03528887 0.03528887 0.03528887 0.03528887]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03050455 0.03050455 0.03050455 0.03050455 0.03050455]\n",
      "target: [0.0313629 0.0313629 0.0313629 0.0313629 0.0313629]\n",
      "target: [0.03188562 0.03188562 0.03188562 0.03188562 0.03188562]\n",
      "target: [0.03420299 0.03420299 0.03420299 0.03420299 0.03420299]\n",
      "Training step 876\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03068685 0.03068685 0.03068685 0.03068685 0.03068685]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03303343 0.03303343 0.03303343 0.03303343 0.03303343]\n",
      "target: [0.03028001 0.03028001 0.03028001 0.03028001 0.03028001]\n",
      "target: [0.03265386 0.03265386 0.03265386 0.03265386 0.03265386]\n",
      "target: [0.03252094 0.03252094 0.03252094 0.03252094 0.03252094]\n",
      "target: [0.03172109 0.03172109 0.03172109 0.03172109 0.03172109]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03321561 0.03321561 0.03321561 0.03321561 0.03321561]\n",
      "target: [0.03452645 0.03452645 0.03452645 0.03452645 0.03452645]\n",
      "target: [0.03737041 0.03737041 0.03737041 0.03737041 0.03737041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03254203 0.03254203 0.03254203 0.03254203 0.03254203]\n",
      "target: [0.03078096 0.03078096 0.03078096 0.03078096 0.03078096]\n",
      "target: [0.0308499 0.0308499 0.0308499 0.0308499 0.0308499]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03228778 0.03228778 0.03228778 0.03228778 0.03228778]\n",
      "target: [0.03176222 0.03176222 0.03176222 0.03176222 0.03176222]\n",
      "target: [0.03304785 0.03304785 0.03304785 0.03304785 0.03304785]\n",
      "target: [0.03336626 0.03336626 0.03336626 0.03336626 0.03336626]\n",
      "target: [0.03566864 0.03566864 0.03566864 0.03566864 0.03566864]\n",
      "target: [0.03056535 0.03056535 0.03056535 0.03056535 0.03056535]\n",
      "target: [0.03256874 0.03256874 0.03256874 0.03256874 0.03256874]\n",
      "target: [0.03112482 0.03112482 0.03112482 0.03112482 0.03112482]\n",
      "target: [0.03181905 0.03181905 0.03181905 0.03181905 0.03181905]\n",
      "target: [0.03152421 0.03152421 0.03152421 0.03152421 0.03152421]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03479374 0.03479374 0.03479374 0.03479374 0.03479374]\n",
      "target: [0.03606812 0.03606812 0.03606812 0.03606812 0.03606812]\n",
      "target: [0.03055359 0.03055359 0.03055359 0.03055359 0.03055359]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "Training step 877\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03018124 0.03018124 0.03018124 0.03018124 0.03018124]\n",
      "target: [0.03076656 0.03076656 0.03076656 0.03076656 0.03076656]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03544315 0.03544315 0.03544315 0.03544315 0.03544315]\n",
      "target: [0.03093914 0.03093914 0.03093914 0.03093914 0.03093914]\n",
      "target: [0.034271 0.034271 0.034271 0.034271 0.034271]\n",
      "target: [0.0302103 0.0302103 0.0302103 0.0302103 0.0302103]\n",
      "target: [0.03229702 0.03229702 0.03229702 0.03229702 0.03229702]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03156853 0.03156853 0.03156853 0.03156853 0.03156853]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.02911898 0.02911898 0.02911898 0.02911898 0.02911898]\n",
      "target: [0.03030972 0.03030972 0.03030972 0.03030972 0.03030972]\n",
      "target: [0.03275859 0.03275859 0.03275859 0.03275859 0.03275859]\n",
      "target: [0.03337575 0.03337575 0.03337575 0.03337575 0.03337575]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.0334286 0.0334286 0.0334286 0.0334286 0.0334286]\n",
      "target: [0.03321301 0.03321301 0.03321301 0.03321301 0.03321301]\n",
      "target: [0.03263307 0.03263307 0.03263307 0.03263307 0.03263307]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03727514 0.03727514 0.03727514 0.03727514 0.03727514]\n",
      "target: [0.0336971 0.0336971 0.0336971 0.0336971 0.0336971]\n",
      "target: [0.03410324 0.03410324 0.03410324 0.03410324 0.03410324]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.02903488 0.02903488 0.02903488 0.02903488 0.02903488]\n",
      "target: [0.03019181 0.03019181 0.03019181 0.03019181 0.03019181]\n",
      "target: [0.0306958 0.0306958 0.0306958 0.0306958 0.0306958]\n",
      "target: [0.0314189 0.0314189 0.0314189 0.0314189 0.0314189]\n",
      "target: [0.03325908 0.03325908 0.03325908 0.03325908 0.03325908]\n",
      "target: [0.03466538 0.03466538 0.03466538 0.03466538 0.03466538]\n",
      "target: [0.03422366 0.03422366 0.03422366 0.03422366 0.03422366]\n",
      "Training step 878\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.0306064 0.0306064 0.0306064 0.0306064 0.0306064]\n",
      "target: [0.03042024 0.03042024 0.03042024 0.03042024 0.03042024]\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.0334466 0.0334466 0.0334466 0.0334466 0.0334466]\n",
      "target: [0.03267917 0.03267917 0.03267917 0.03267917 0.03267917]\n",
      "target: [0.03256732 0.03256732 0.03256732 0.03256732 0.03256732]\n",
      "target: [0.03215325 0.03215325 0.03215325 0.03215325 0.03215325]\n",
      "target: [0.03121118 0.03121118 0.03121118 0.03121118 0.03121118]\n",
      "target: [0.03358311 0.03358311 0.03358311 0.03358311 0.03358311]\n",
      "target: [0.03826069 0.03826069 0.03826069 0.03826069 0.03826069]\n",
      "target: [0.03296537 0.03296537 0.03296537 0.03296537 0.03296537]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03339727 0.03339727 0.03339727 0.03339727 0.03339727]\n",
      "target: [0.03301807 0.03301807 0.03301807 0.03301807 0.03301807]\n",
      "target: [0.03604379 0.03604379 0.03604379 0.03604379 0.03604379]\n",
      "target: [0.03165004 0.03165004 0.03165004 0.03165004 0.03165004]\n",
      "target: [0.03224774 0.03224774 0.03224774 0.03224774 0.03224774]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0.03018009 0.03018009 0.03018009 0.03018009 0.03018009]\n",
      "target: [0.03097549 0.03097549 0.03097549 0.03097549 0.03097549]\n",
      "target: [0.02967322 0.02967322 0.02967322 0.02967322 0.02967322]\n",
      "target: [0.0318496 0.0318496 0.0318496 0.0318496 0.0318496]\n",
      "target: [0.03183618 0.03183618 0.03183618 0.03183618 0.03183618]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03434611 0.03434611 0.03434611 0.03434611 0.03434611]\n",
      "target: [0.03135736 0.03135736 0.03135736 0.03135736 0.03135736]\n",
      "target: [0.03098529 0.03098529 0.03098529 0.03098529 0.03098529]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02905789 0.02905789 0.02905789 0.02905789 0.02905789]\n",
      "target: [0.03457525 0.03457525 0.03457525 0.03457525 0.03457525]\n",
      "target: [0.03076691 0.03076691 0.03076691 0.03076691 0.03076691]\n",
      "target: [0.03858449 0.03858449 0.03858449 0.03858449 0.03858449]\n",
      "Training step 879\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "target: [0.03300908 0.03300908 0.03300908 0.03300908 0.03300908]\n",
      "target: [0.03261908 0.03261908 0.03261908 0.03261908 0.03261908]\n",
      "target: [0.03324372 0.03324372 0.03324372 0.03324372 0.03324372]\n",
      "target: [0.03149012 0.03149012 0.03149012 0.03149012 0.03149012]\n",
      "target: [0.03009683 0.03009683 0.03009683 0.03009683 0.03009683]\n",
      "target: [0.03281789 0.03281789 0.03281789 0.03281789 0.03281789]\n",
      "target: [0.03919793 0.03919793 0.03919793 0.03919793 0.03919793]\n",
      "target: [0.03371315 0.03371315 0.03371315 0.03371315 0.03371315]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03127164 0.03127164 0.03127164 0.03127164 0.03127164]\n",
      "target: [0.03044018 0.03044018 0.03044018 0.03044018 0.03044018]\n",
      "target: [0.03251383 0.03251383 0.03251383 0.03251383 0.03251383]\n",
      "target: [0.03266042 0.03266042 0.03266042 0.03266042 0.03266042]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03318137 0.03318137 0.03318137 0.03318137 0.03318137]\n",
      "target: [0.03144702 0.03144702 0.03144702 0.03144702 0.03144702]\n",
      "target: [0.03130374 0.03130374 0.03130374 0.03130374 0.03130374]\n",
      "target: [0.03325154 0.03325154 0.03325154 0.03325154 0.03325154]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03799292 0.03799292 0.03799292 0.03799292 0.03799292]\n",
      "target: [0.03345745 0.03345745 0.03345745 0.03345745 0.03345745]\n",
      "target: [0.03102681 0.03102681 0.03102681 0.03102681 0.03102681]\n",
      "target: [0.03304362 0.03304362 0.03304362 0.03304362 0.03304362]\n",
      "target: [0.03529232 0.03529232 0.03529232 0.03529232 0.03529232]\n",
      "target: [0.03187319 0.03187319 0.03187319 0.03187319 0.03187319]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0.03323038 0.03323038 0.03323038 0.03323038 0.03323038]\n",
      "target: [0.03702873 0.03702873 0.03702873 0.03702873 0.03702873]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0.03104522 0.03104522 0.03104522 0.03104522 0.03104522]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0.03073438 0.03073438 0.03073438 0.03073438 0.03073438]\n",
      "Training step 880\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03344926 0.03344926 0.03344926 0.03344926 0.03344926]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03495299 0.03495299 0.03495299 0.03495299 0.03495299]\n",
      "target: [0.03672734 0.03672734 0.03672734 0.03672734 0.03672734]\n",
      "target: [0.03127982 0.03127982 0.03127982 0.03127982 0.03127982]\n",
      "target: [0.03271632 0.03271632 0.03271632 0.03271632 0.03271632]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03414699 0.03414699 0.03414699 0.03414699 0.03414699]\n",
      "target: [0.03120269 0.03120269 0.03120269 0.03120269 0.03120269]\n",
      "target: [0.03089657 0.03089657 0.03089657 0.03089657 0.03089657]\n",
      "target: [0.03227664 0.03227664 0.03227664 0.03227664 0.03227664]\n",
      "target: [0.02988539 0.02988539 0.02988539 0.02988539 0.02988539]\n",
      "target: [0.03117037 0.03117037 0.03117037 0.03117037 0.03117037]\n",
      "target: [-0.96798086  0.03201914  0.03201914  0.03201914  0.03201914]\n",
      "target: [0.03184192 0.03184192 0.03184192 0.03184192 0.03184192]\n",
      "target: [0.03424727 0.03424727 0.03424727 0.03424727 0.03424727]\n",
      "target: [0.03066804 0.03066804 0.03066804 0.03066804 0.03066804]\n",
      "target: [0.03147889 0.03147889 0.03147889 0.03147889 0.03147889]\n",
      "target: [0.03260569 0.03260569 0.03260569 0.03260569 0.03260569]\n",
      "target: [0.0363405 0.0363405 0.0363405 0.0363405 0.0363405]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03558303 0.03558303 0.03558303 0.03558303 0.03558303]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03201688 0.03201688 0.03201688 0.03201688 0.03201688]\n",
      "target: [0.03433812 0.03433812 0.03433812 0.03433812 0.03433812]\n",
      "target: [0.03240024 0.03240024 0.03240024 0.03240024 0.03240024]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03010806 0.03010806 0.03010806 0.03010806 0.03010806]\n",
      "target: [0.03049384 0.03049384 0.03049384 0.03049384 0.03049384]\n",
      "target: [0.03467787 0.03467787 0.03467787 0.03467787 0.03467787]\n",
      "Training step 881\n",
      "Finished episode 0/ 2, epsilon: 0.11899999999999922, score: -21.0, avg. score: -21.0\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "target: [0.03814596 0.03814596 0.03814596 0.03814596 0.03814596]\n",
      "target: [0.03558181 0.03558181 0.03558181 0.03558181 0.03558181]\n",
      "target: [0.03314334 0.03314334 0.03314334 0.03314334 0.03314334]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.04036219 0.04036219 0.04036219 0.04036219 0.04036219]\n",
      "target: [0.03310772 0.03310772 0.03310772 0.03310772 0.03310772]\n",
      "target: [0.03280076 0.03280076 0.03280076 0.03280076 0.03280076]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03184532 0.03184532 0.03184532 0.03184532 0.03184532]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03111878 0.03111878 0.03111878 0.03111878 0.03111878]\n",
      "target: [0.03147811 0.03147811 0.03147811 0.03147811 0.03147811]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03175393 0.03175393 0.03175393 0.03175393 0.03175393]\n",
      "target: [0.03202054 0.03202054 0.03202054 0.03202054 0.03202054]\n",
      "target: [0.0325049 0.0325049 0.0325049 0.0325049 0.0325049]\n",
      "target: [0.03098859 0.03098859 0.03098859 0.03098859 0.03098859]\n",
      "target: [0.03479872 0.03479872 0.03479872 0.03479872 0.03479872]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.03616863 0.03616863 0.03616863 0.03616863 0.03616863]\n",
      "target: [0.03175982 0.03175982 0.03175982 0.03175982 0.03175982]\n",
      "target: [0.03746993 0.03746993 0.03746993 0.03746993 0.03746993]\n",
      "target: [0.03599684 0.03599684 0.03599684 0.03599684 0.03599684]\n",
      "target: [0.03558582 0.03558582 0.03558582 0.03558582 0.03558582]\n",
      "target: [0.03353596 0.03353596 0.03353596 0.03353596 0.03353596]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03266284 0.03266284 0.03266284 0.03266284 0.03266284]\n",
      "target: [0.03192431 0.03192431 0.03192431 0.03192431 0.03192431]\n",
      "Training step 882\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.02995807 0.02995807 0.02995807 0.02995807 0.02995807]\n",
      "target: [0.03879506 0.03879506 0.03879506 0.03879506 0.03879506]\n",
      "target: [0.03275041 0.03275041 0.03275041 0.03275041 0.03275041]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.0364289 0.0364289 0.0364289 0.0364289 0.0364289]\n",
      "target: [0.0320365 0.0320365 0.0320365 0.0320365 0.0320365]\n",
      "target: [0.0351471 0.0351471 0.0351471 0.0351471 0.0351471]\n",
      "target: [0.03243252 0.03243252 0.03243252 0.03243252 0.03243252]\n",
      "target: [0.03134338 0.03134338 0.03134338 0.03134338 0.03134338]\n",
      "target: [0.02967565 0.02967565 0.02967565 0.02967565 0.02967565]\n",
      "target: [0.03280297 0.03280297 0.03280297 0.03280297 0.03280297]\n",
      "target: [0.03147327 0.03147327 0.03147327 0.03147327 0.03147327]\n",
      "target: [0.03319585 0.03319585 0.03319585 0.03319585 0.03319585]\n",
      "target: [0.03080648 0.03080648 0.03080648 0.03080648 0.03080648]\n",
      "target: [0.03074866 0.03074866 0.03074866 0.03074866 0.03074866]\n",
      "target: [0.03158367 0.03158367 0.03158367 0.03158367 0.03158367]\n",
      "target: [0.03036597 0.03036597 0.03036597 0.03036597 0.03036597]\n",
      "target: [0.0324551 0.0324551 0.0324551 0.0324551 0.0324551]\n",
      "target: [0.03300908 0.03300908 0.03300908 0.03300908 0.03300908]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03119602 0.03119602 0.03119602 0.03119602 0.03119602]\n",
      "target: [0.03338862 0.03338862 0.03338862 0.03338862 0.03338862]\n",
      "target: [0.03387205 0.03387205 0.03387205 0.03387205 0.03387205]\n",
      "target: [0.03115186 0.03115186 0.03115186 0.03115186 0.03115186]\n",
      "target: [0.03033768 0.03033768 0.03033768 0.03033768 0.03033768]\n",
      "target: [-0.96861412  0.03138588  0.03138588  0.03138588  0.03138588]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03194401 0.03194401 0.03194401 0.03194401 0.03194401]\n",
      "target: [0.03752721 0.03752721 0.03752721 0.03752721 0.03752721]\n",
      "target: [0.03723768 0.03723768 0.03723768 0.03723768 0.03723768]\n",
      "target: [0.03001422 0.03001422 0.03001422 0.03001422 0.03001422]\n",
      "target: [0.03659002 0.03659002 0.03659002 0.03659002 0.03659002]\n",
      "Training step 883\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "target: [0.03645497 0.03645497 0.03645497 0.03645497 0.03645497]\n",
      "target: [0.03153821 0.03153821 0.03153821 0.03153821 0.03153821]\n",
      "target: [0.03311276 0.03311276 0.03311276 0.03311276 0.03311276]\n",
      "target: [0.03757887 0.03757887 0.03757887 0.03757887 0.03757887]\n",
      "target: [0.03637801 0.03637801 0.03637801 0.03637801 0.03637801]\n",
      "target: [0.03310075 0.03310075 0.03310075 0.03310075 0.03310075]\n",
      "target: [-0.96833096  0.03166904  0.03166904  0.03166904  0.03166904]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03736176 0.03736176 0.03736176 0.03736176 0.03736176]\n",
      "target: [0.03200573 0.03200573 0.03200573 0.03200573 0.03200573]\n",
      "target: [0.03246567 0.03246567 0.03246567 0.03246567 0.03246567]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03114037 0.03114037 0.03114037 0.03114037 0.03114037]\n",
      "target: [0.03397091 0.03397091 0.03397091 0.03397091 0.03397091]\n",
      "target: [0.03230666 0.03230666 0.03230666 0.03230666 0.03230666]\n",
      "target: [0.03310459 0.03310459 0.03310459 0.03310459 0.03310459]\n",
      "target: [0.03806502 0.03806502 0.03806502 0.03806502 0.03806502]\n",
      "target: [0.03166878 0.03166878 0.03166878 0.03166878 0.03166878]\n",
      "target: [-0.96493174  0.03506826  0.03506826  0.03506826  0.03506826]\n",
      "target: [0.03077297 0.03077297 0.03077297 0.03077297 0.03077297]\n",
      "target: [0.03282296 0.03282296 0.03282296 0.03282296 0.03282296]\n",
      "target: [0.03116305 0.03116305 0.03116305 0.03116305 0.03116305]\n",
      "target: [0.03313059 0.03313059 0.03313059 0.03313059 0.03313059]\n",
      "target: [0.03104303 0.03104303 0.03104303 0.03104303 0.03104303]\n",
      "target: [0.03606211 0.03606211 0.03606211 0.03606211 0.03606211]\n",
      "target: [0.03331595 0.03331595 0.03331595 0.03331595 0.03331595]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n",
      "target: [0.03561852 0.03561852 0.03561852 0.03561852 0.03561852]\n",
      "target: [0.03337506 0.03337506 0.03337506 0.03337506 0.03337506]\n",
      "target: [0.03312442 0.03312442 0.03312442 0.03312442 0.03312442]\n",
      "target: [0.03257836 0.03257836 0.03257836 0.03257836 0.03257836]\n",
      "target: [0.03192203 0.03192203 0.03192203 0.03192203 0.03192203]\n",
      "Training step 884\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "target: [0.03585456 0.03585456 0.03585456 0.03585456 0.03585456]\n",
      "target: [0.03271632 0.03271632 0.03271632 0.03271632 0.03271632]\n",
      "target: [0.0320852 0.0320852 0.0320852 0.0320852 0.0320852]\n",
      "target: [0.03161601 0.03161601 0.03161601 0.03161601 0.03161601]\n",
      "target: [0.0308614 0.0308614 0.0308614 0.0308614 0.0308614]\n",
      "target: [0.03151607 0.03151607 0.03151607 0.03151607 0.03151607]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03147978 0.03147978 0.03147978 0.03147978 0.03147978]\n",
      "target: [0.03217456 0.03217456 0.03217456 0.03217456 0.03217456]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "target: [0.03345783 0.03345783 0.03345783 0.03345783 0.03345783]\n",
      "target: [0.03414637 0.03414637 0.03414637 0.03414637 0.03414637]\n",
      "target: [0.0309351 0.0309351 0.0309351 0.0309351 0.0309351]\n",
      "target: [0.03214237 0.03214237 0.03214237 0.03214237 0.03214237]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03096332 0.03096332 0.03096332 0.03096332 0.03096332]\n",
      "target: [0.03062582 0.03062582 0.03062582 0.03062582 0.03062582]\n",
      "target: [0.03233333 0.03233333 0.03233333 0.03233333 0.03233333]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03208751 0.03208751 0.03208751 0.03208751 0.03208751]\n",
      "target: [0.03627582 0.03627582 0.03627582 0.03627582 0.03627582]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03514371 0.03514371 0.03514371 0.03514371 0.03514371]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03003907 0.03003907 0.03003907 0.03003907 0.03003907]\n",
      "target: [0.03128738 0.03128738 0.03128738 0.03128738 0.03128738]\n",
      "target: [0.03123531 0.03123531 0.03123531 0.03123531 0.03123531]\n",
      "target: [0.03692581 0.03692581 0.03692581 0.03692581 0.03692581]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03709238 0.03709238 0.03709238 0.03709238 0.03709238]\n",
      "Training step 885\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0.03379399 0.03379399 0.03379399 0.03379399 0.03379399]\n",
      "target: [0.03676404 0.03676404 0.03676404 0.03676404 0.03676404]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03089986 0.03089986 0.03089986 0.03089986 0.03089986]\n",
      "target: [0.03107527 0.03107527 0.03107527 0.03107527 0.03107527]\n",
      "target: [0.03101314 0.03101314 0.03101314 0.03101314 0.03101314]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03269202 0.03269202 0.03269202 0.03269202 0.03269202]\n",
      "target: [0.02979456 0.02979456 0.02979456 0.02979456 0.02979456]\n",
      "target: [0.0333086 0.0333086 0.0333086 0.0333086 0.0333086]\n",
      "target: [0.04047681 0.04047681 0.04047681 0.04047681 0.04047681]\n",
      "target: [0.03176826 0.03176826 0.03176826 0.03176826 0.03176826]\n",
      "target: [0.03004622 0.03004622 0.03004622 0.03004622 0.03004622]\n",
      "target: [0.02872288 0.02872288 0.02872288 0.02872288 0.02872288]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03199896 0.03199896 0.03199896 0.03199896 0.03199896]\n",
      "target: [0.03307357 0.03307357 0.03307357 0.03307357 0.03307357]\n",
      "target: [0.0309065 0.0309065 0.0309065 0.0309065 0.0309065]\n",
      "target: [0.03571091 0.03571091 0.03571091 0.03571091 0.03571091]\n",
      "target: [0.03247626 0.03247626 0.03247626 0.03247626 0.03247626]\n",
      "target: [0.03375342 0.03375342 0.03375342 0.03375342 0.03375342]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03213668 0.03213668 0.03213668 0.03213668 0.03213668]\n",
      "target: [0.03778169 0.03778169 0.03778169 0.03778169 0.03778169]\n",
      "target: [0.03782923 0.03782923 0.03782923 0.03782923 0.03782923]\n",
      "target: [0.03180567 0.03180567 0.03180567 0.03180567 0.03180567]\n",
      "target: [0.03274113 0.03274113 0.03274113 0.03274113 0.03274113]\n",
      "target: [0.03352722 0.03352722 0.03352722 0.03352722 0.03352722]\n",
      "target: [0.03467072 0.03467072 0.03467072 0.03467072 0.03467072]\n",
      "target: [0.03177023 0.03177023 0.03177023 0.03177023 0.03177023]\n",
      "target: [0.03022076 0.03022076 0.03022076 0.03022076 0.03022076]\n",
      "target: [-0.96916902  0.03083098  0.03083098  0.03083098  0.03083098]\n",
      "Training step 886\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "target: [0.03066164 0.03066164 0.03066164 0.03066164 0.03066164]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03063383 0.03063383 0.03063383 0.03063383 0.03063383]\n",
      "target: [0.03045825 0.03045825 0.03045825 0.03045825 0.03045825]\n",
      "target: [0.0353088 0.0353088 0.0353088 0.0353088 0.0353088]\n",
      "target: [0.03116437 0.03116437 0.03116437 0.03116437 0.03116437]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03916252 0.03916252 0.03916252 0.03916252 0.03916252]\n",
      "target: [0.03549267 0.03549267 0.03549267 0.03549267 0.03549267]\n",
      "target: [0.03180115 0.03180115 0.03180115 0.03180115 0.03180115]\n",
      "target: [0.03350245 0.03350245 0.03350245 0.03350245 0.03350245]\n",
      "target: [0.03032627 0.03032627 0.03032627 0.03032627 0.03032627]\n",
      "target: [0.03497737 0.03497737 0.03497737 0.03497737 0.03497737]\n",
      "target: [0.0352369 0.0352369 0.0352369 0.0352369 0.0352369]\n",
      "target: [0.03100214 0.03100214 0.03100214 0.03100214 0.03100214]\n",
      "target: [-0.96926002  0.03073998  0.03073998  0.03073998  0.03073998]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03027735 0.03027735 0.03027735 0.03027735 0.03027735]\n",
      "target: [0.03479374 0.03479374 0.03479374 0.03479374 0.03479374]\n",
      "target: [0.03660777 0.03660777 0.03660777 0.03660777 0.03660777]\n",
      "target: [0.03254555 0.03254555 0.03254555 0.03254555 0.03254555]\n",
      "target: [0.03117901 0.03117901 0.03117901 0.03117901 0.03117901]\n",
      "target: [0.03342237 0.03342237 0.03342237 0.03342237 0.03342237]\n",
      "target: [0.02888454 0.02888454 0.02888454 0.02888454 0.02888454]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03526592 0.03526592 0.03526592 0.03526592 0.03526592]\n",
      "target: [0.03103764 0.03103764 0.03103764 0.03103764 0.03103764]\n",
      "target: [0.03546611 0.03546611 0.03546611 0.03546611 0.03546611]\n",
      "target: [0.03334675 0.03334675 0.03334675 0.03334675 0.03334675]\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.02840322 0.02840322 0.02840322 0.02840322 0.02840322]\n",
      "target: [0.03171276 0.03171276 0.03171276 0.03171276 0.03171276]\n",
      "Training step 887\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "target: [0. 0. 0. 0. 0.]\n",
      "target: [0.03130253 0.03130253 0.03130253 0.03130253 0.03130253]\n",
      "target: [0.03748225 0.03748225 0.03748225 0.03748225 0.03748225]\n",
      "target: [0.03241696 0.03241696 0.03241696 0.03241696 0.03241696]\n",
      "target: [0.03241709 0.03241709 0.03241709 0.03241709 0.03241709]\n",
      "target: [0.03270514 0.03270514 0.03270514 0.03270514 0.03270514]\n",
      "target: [0.03125645 0.03125645 0.03125645 0.03125645 0.03125645]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=0'>1</a>\u001b[0m agent\u001b[39m.\u001b[39;49mtrain_agent()\n",
      "\n",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 24\u001b[0m in \u001b[0;36mDoubleDQNAgent.train_agent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=141'>142</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember(state, action, reward, new_state, done) \n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=142'>143</a>\u001b[0m state \u001b[39m=\u001b[39m new_state\n",
      "\u001b[1;32m--> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=143'>144</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=144'>145</a>\u001b[0m \u001b[39m#self.step_counter += 1 # already updated in the self.train method\u001b[39;00m\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=145'>146</a>\u001b[0m \n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=146'>147</a>\u001b[0m \u001b[39m# update the target_network regularly\u001b[39;00m\n",
      "\u001b[0;32m    <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=147'>148</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_counter \u001b[39m%\u001b[39m SYNC_TARGET_FREQ \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\n",
      "\u001b[1;32mh:\\IUBH_Master_AI\\RL_playing_pong\\OpenAI Gym- Pong.ipynb Zelle 24\u001b[0m in \u001b[0;36mDoubleDQNAgent.train\u001b[1;34m(self, batch_size)\u001b[0m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=82'>83</a>\u001b[0m next_state_batch\u001b[39m.\u001b[39mappend(norm_next_state_array) \n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=84'>85</a>\u001b[0m \u001b[39m# Main QNet is used to find the next action\u001b[39;00m\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=85'>86</a>\u001b[0m q_vals \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_net(norm_state_array)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=86'>87</a>\u001b[0m \u001b[39m#print(f\"q_vals: {q_vals}\")\u001b[39;00m\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/IUBH_Master_AI/RL_playing_pong/OpenAI%20Gym-%20Pong.ipynb#ch0000021?line=87'>88</a>\u001b[0m next_action \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(q_vals, axis\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m# TODO: check for amax and argmax!!!\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\training.py:490\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    486\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n",
      "\u001b[0;32m    488\u001b[0m   layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n",
      "\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n",
      "\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n",
      "\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n",
      "\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n",
      "\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\sequential.py:374\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n",
      "\u001b[0;32m    372\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n",
      "\u001b[0;32m    373\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)\n",
      "\u001b[1;32m--> 374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Sequential, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcall(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "\u001b[0;32m    376\u001b[0m outputs \u001b[39m=\u001b[39m inputs  \u001b[39m# handle the corner case where self.layers is empty\u001b[39;00m\n",
      "\u001b[0;32m    377\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n",
      "\u001b[0;32m    378\u001b[0m   \u001b[39m# During each iteration, `inputs` are the inputs to `layer`, and `outputs`\u001b[39;00m\n",
      "\u001b[0;32m    379\u001b[0m   \u001b[39m# are the outputs of `layer` applied to `inputs`. At the end of each\u001b[39;00m\n",
      "\u001b[0;32m    380\u001b[0m   \u001b[39m# iteration `inputs` is set to `outputs` to prepare for the next layer.\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\functional.py:458\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n",
      "\u001b[0;32m    439\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n",
      "\u001b[0;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;32m    441\u001b[0m   \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n",
      "\u001b[0;32m    442\u001b[0m \n",
      "\u001b[0;32m    443\u001b[0m \u001b[39m  In this case `call` just reapplies\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    456\u001b[0m \u001b[39m      a list of tensors if there are more than one outputs.\u001b[39;00m\n",
      "\u001b[0;32m    457\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(\n",
      "\u001b[0;32m    459\u001b[0m       inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\functional.py:596\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n",
      "\u001b[0;32m    593\u001b[0m   \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n",
      "\u001b[0;32m    595\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n",
      "\u001b[1;32m--> 596\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mlayer(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    598\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n",
      "\u001b[0;32m    599\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)):\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n",
      "\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n",
      "\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n",
      "\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n",
      "\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n",
      "\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:269\u001b[0m, in \u001b[0;36mConv.call\u001b[1;34m(self, inputs)\u001b[0m\n",
      "\u001b[0;32m    266\u001b[0m       outputs \u001b[39m=\u001b[39m conv_utils\u001b[39m.\u001b[39msqueeze_batch_dims(\n",
      "\u001b[0;32m    267\u001b[0m           outputs, _apply_fn, inner_rank\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;32m    268\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 269\u001b[0m       outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mbias_add(\n",
      "\u001b[0;32m    270\u001b[0m           outputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tf_data_format)\n",
      "\u001b[0;32m    272\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mexecuting_eagerly():\n",
      "\u001b[0;32m    273\u001b[0m   \u001b[39m# Infer the static output shape:\u001b[39;00m\n",
      "\u001b[0;32m    274\u001b[0m   out_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_output_shape(input_shape)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n",
      "\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n",
      "\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n",
      "\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:3523\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n",
      "\u001b[0;32m   3520\u001b[0m   value \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(value, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;32m   3521\u001b[0m   bias \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(bias, dtype\u001b[39m=\u001b[39mvalue\u001b[39m.\u001b[39mdtype, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m-> 3523\u001b[0m \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mbias_add(value, bias, data_format\u001b[39m=\u001b[39;49mdata_format, name\u001b[39m=\u001b[39;49mname)\n",
      "\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\RL-gym\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:673\u001b[0m, in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n",
      "\u001b[0;32m    671\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n",
      "\u001b[0;32m    672\u001b[0m   \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 673\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n",
      "\u001b[0;32m    674\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mBiasAdd\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, value, bias, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_format)\n",
      "\u001b[0;32m    675\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n",
      "\u001b[0;32m    676\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    26\n",
       "0    22\n",
       "4    19\n",
       "5    17\n",
       "2    16\n",
       "Name: action, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.action.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_array = np.asarray(action_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, 4, 0, 5, 0, 3, 2, 0, 3, 0, 4, 5, 5, 0, 5, 3, 3, 4, 4, 3,\n",
       "       4, 0, 0, 5, 0, 5, 0, 2, 5, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "agent.epsilon_greedy(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State batch (32, 84, 84, 4)\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[[[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]]\n",
      "\n",
      "\n",
      " [[[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]]\n",
      "\n",
      "\n",
      " [[[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]]\n",
      "\n",
      "\n",
      " [[[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]]\n",
      "\n",
      "\n",
      " [[[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]\n",
      "\n",
      "  [[0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   ...\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]\n",
      "   [0.34117647 0.34117647 0.34117647 0.34117647]]]]\n",
      "(32, 84, 84, 4)\n"
     ]
    }
   ],
   "source": [
    "agent.train(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Replay Buffer to replay_buffer.pkl \n"
     ]
    }
   ],
   "source": [
    "agent.save_replay_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        [  0,   0,   0],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       [[109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        ...,\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43],\n",
       "        [109, 118,  43]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]],\n",
       "\n",
       "       [[ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        ...,\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24],\n",
       "        [ 53,  95,  24]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Replay Buffer to replay_buffer.pkl \n"
     ]
    }
   ],
   "source": [
    "outfile = open('replay_buffer.pkl','wb')\n",
    "pickle.dump(agent.replay_buffer,outfile)\n",
    "outfile.close()\n",
    "print(f\"Saved Replay Buffer to {'replay_buffer.pkl'} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frame(image, shape=(84,84)):\n",
    "    assert \n",
    "    image = image.astype(np.uint8) # required for cv2\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    cropped_image = image[34:34+160, :160] # remove scores\n",
    "    cropped_image = cv2.resize(cropped_image, shape, interpolation = cv2.INTER_NEAREST) # INTER_AREA\n",
    "    cropped_image= cropped_image.reshape((*shape, 1))\n",
    "    return cropped_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_buffer  = deque(maxlen=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "5\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "5\n",
      "2\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "4\n",
      "3\n",
      "3\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "0\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "0\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "3\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "0\n",
      "5\n",
      "3\n",
      "5\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#from argparse import Action\n",
    "\n",
    "\n",
    "env.seed(42)\n",
    "obs = env.reset()\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    #env.render('human')\n",
    "    #action = env.action_space.sample()\n",
    "    action = random.choice(useful_actions)\n",
    "    print(action)\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.render(mode='rgb_array')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('RL-gym')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6096440f97b05561066a0296712b8293b6970927bc60fc1fef032d4f0161f16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
